diff --git a/COMMON/README.md b/COMMON/README.md
deleted file mode 100644
index 42ae842..0000000
--- a/COMMON/README.md
+++ /dev/null
@@ -1,267 +0,0 @@
-# Graph Matching with Noisy Correspondence
-
-[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/graph-matching-with-bi-level-noisy/graph-matching-on-pascal-voc)](https://paperswithcode.com/sota/graph-matching-on-pascal-voc?p=graph-matching-with-bi-level-noisy)
-[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/graph-matching-with-bi-level-noisy/graph-matching-on-spair-71k)](https://paperswithcode.com/sota/graph-matching-on-spair-71k?p=graph-matching-with-bi-level-noisy)
-[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/graph-matching-with-bi-level-noisy/graph-matching-on-willow-object-class)](https://paperswithcode.com/sota/graph-matching-on-willow-object-class?p=graph-matching-with-bi-level-noisy)
-
-
-This repo contains the code and data of our ICCV'2023 paper. Our work has also been included by famous graph matching open-source projects [ThinkMatch](https://github.com/Thinklab-SJTU/ThinkMatch) 
-[![GitHub stars](https://img.shields.io/github/stars/Thinklab-SJTU/ThinkMatch.svg?style=social&label=Star&maxAge=8640)](https://GitHub.com/Thinklab-SJTU/ThinkMatch/). 
-> Yijie Lin, Mouxing Yang, Jun Yu, Peng Hu, Changqing Zhang, Xi Peng. Graph Matching with Bi-level Noisy Correspondence. ICCV, 2023.  [[paper]](https://arxiv.org/pdf/2212.04085.pdf) 
-
-
-
-
-
-## Background of Graph Matching
-Graph Matching (GM) is a fundamental yet challenging problem in computer vision, pattern recognition and data mining. GM aims to find node-to-node correspondence among multiple graphs, by solving an NP-hard combinatorial problem named Quadratic Assignment Problem (QAP).
-
-Graph matching techniques have been applied to the following applications:
-
-* [Image correspondence](https://arxiv.org/pdf/1911.11763.pdf)
-  
-  <img src="https://thinkmatch.readthedocs.io/en/latest/_images/superglue.png" alt="Superglue, CVPR 2020" width="45%">
-
-* [Molecules matching](https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Combinatorial_Learning_of_Graph_Edit_Distance_via_Dynamic_Embedding_CVPR_2021_paper.pdf)
-
-  <img src="https://thinkmatch.readthedocs.io/en/latest/_images/molecules.png" alt="Molecules matching, CVPR 2021" width="50%">
-
-* and more...
-
-## Introduction to Noisy Correspondence
-
-In this paper, we introduce a novel and widely existing problem in graph matching (GM) and focus on the scenario of visual image keypoint matching. 
-As shown below, the inaccurate annotations will inevitably lead to **Bi-level Noisy Correspondence (BNC)** problem. 
-Due to the poor recognizability and viewpoint differences between images, it is inevitable to inaccurately annotate some keypoints with offset and confusion, leading to the mismatch between two associated nodes (NNC). The noisy node-to-node correspondence will further contaminate the edge-to-edge correspondence (ENC).
-
-<img src="https://github.com/Lin-Yijie/Graph-Matching-Networks/blob/main/COMMON/docs/images/nc_example.png" alt="COMMON, ICCV 2023" width="80%">
-
-
-
-
-## Get Started
-
-### Docker (RECOMMENDED)
-
-Some of the module needs C++ supporting and we highly encouraged to directly use the docker environment. Get the recommended docker image by
-```bash
-docker pull runzhongwang/thinkmatch:torch1.10.0-cuda11.3-cudnn8-pyg2.0.3-pygmtools0.3.8
-docker run --gpus all --name thinkmatch -p 10000:22 -it runzhongwang/thinkmatch:torch1.10.0-cuda11.3-cudnn8-pyg2.0.3-pygmtools0.3.8
-pip install ortools==9.4.1874
-```
-
-Note we train our model on a single 3090 GPU. The training time is about 9 hours for Pascal VOC and 4 hours for Spair71k.
-
-
-### Manual configuration (for Ubuntu, NOT RECOMMENDED)
-The below python environment is provided by [ThinkMatch](https://github.com/Thinklab-SJTU/ThinkMatch) and we do not guarantee the integrity.
-
-1. Install and configure Pytorch 1.6 (with GPU support). 
-1. Install ninja-build: ``apt-get install ninja-build``
-1. Install python packages: 
-    ```bash
-    pip install tensorboardX scipy easydict pyyaml xlrd xlwt pynvml pygmtools
-   ```
-1. Install building tools for LPMP: 
-    ```bash
-    apt-get install -y findutils libhdf5-serial-dev git wget libssl-dev
-    
-    wget https://github.com/Kitware/CMake/releases/download/v3.19.1/cmake-3.19.1.tar.gz && tar zxvf cmake-3.19.1.tar.gz
-    cd cmake-3.19.1 && ./bootstrap && make && make install
-    ```
-
-1. Install and build LPMP:
-    ```bash
-   python -m pip install git+https://git@github.com/rogerwwww/lpmp.git
-   ```
-   You may need ``gcc-9`` to successfully build LPMP. Here we provide an example installing and configuring ``gcc-9``: 
-   ```bash
-   apt-get update
-   apt-get install -y software-properties-common
-   add-apt-repository ppa:ubuntu-toolchain-r/test
-   
-   apt-get install -y gcc-9 g++-9
-   update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-9 60 --slave /usr/bin/g++ g++ /usr/bin/g++-9
-   ```
-
-1. Install torch-geometric:
-    ```bash
-    export CUDA=cu101
-    export TORCH=1.6.0
-    /opt/conda/bin/pip install torch-scatter==2.0.5 -f https://pytorch-geometric.com/whl/torch-${TORCH}+${CUDA}.html
-    /opt/conda/bin/pip install torch-sparse==0.6.8 -f https://pytorch-geometric.com/whl/torch-${TORCH}+${CUDA}.html
-    /opt/conda/bin/pip install torch-cluster==1.5.8 -f https://pytorch-geometric.com/whl/torch-${TORCH}+${CUDA}.html
-    /opt/conda/bin/pip install torch-spline-conv==1.2.0 -f https://pytorch-geometric.com/whl/torch-${TORCH}+${CUDA}.html
-    /opt/conda/bin/pip install torch-geometric==1.6.3
-   ```
-
-1. If you have configured ``gcc-9`` to build LPMP, be sure to switch back to ``gcc-7`` because this code repository is based on ``gcc-7``. Here is also an example:
-
-    ```bash
-    update-alternatives --remove gcc /usr/bin/gcc-9
-   update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-7 60 --slave /usr/bin/g++ g++ /usr/bin/g++-7
-   ```
-
-### Available datasets
-
-Note: All following datasets can be automatically downloaded and unzipped by `pygmtools` in this code, but we recommend downloading the dataset yourself as it is much faster.
-
-1. PascalVOC-Keypoint
-
-    1. Download [VOC2011 dataset](http://host.robots.ox.ac.uk/pascal/VOC/voc2011/index.html) and make sure it looks like ``data/PascalVOC/TrainVal/VOCdevkit/VOC2011``
-    
-    1. Download keypoint annotation for VOC2011 from [Berkeley server](https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/shape/poselets/voc2011_keypoints_Feb2012.tgz) or [google drive](https://drive.google.com/open?id=1D5o8rmnY1-DaDrgAXSygnflX5c-JyUWR) and make sure it looks like ``data/PascalVOC/annotations``
-    
-    1. The train/test split is available in ``data/PascalVOC/voc2011_pairs.npz``. **This file must be added manually.**
-
-    Please cite the following papers if you use PascalVOC-Keypoint dataset:
-    ```
-    @article{EveringhamIJCV10,
-      title={The pascal visual object classes (voc) challenge},
-      author={Everingham, Mark and Van Gool, Luc and Williams, Christopher KI and Winn, John and Zisserman, Andrew},
-      journal={International Journal of Computer Vision},
-      volume={88},
-      pages={303–338},
-      year={2010}
-    }
-    
-    @inproceedings{BourdevICCV09,
-      title={Poselets: Body part detectors trained using 3d human pose annotations},
-      author={Bourdev, L. and Malik, J.},
-      booktitle={International Conference on Computer Vision},
-      pages={1365--1372},
-      year={2009},
-      organization={IEEE}
-    }
-    ```
-1. Willow-Object-Class
-   
-    1. Download [Willow-ObjectClass dataset](http://www.di.ens.fr/willow/research/graphlearning/WILLOW-ObjectClass_dataset.zip)
-    
-    1. Unzip the dataset and make sure it looks like ``data/WillowObject/WILLOW-ObjectClass``
-
-    Please cite the following paper if you use Willow-Object-Class dataset:
-    ```
-    @inproceedings{ChoICCV13,
-      author={Cho, Minsu and Alahari, Karteek and Ponce, Jean},
-      title = {Learning Graphs to Match},
-      booktitle = {International Conference on Computer Vision},
-      pages={25--32},
-      year={2013}
-    }
-    ```
-
-1. SPair-71k
-
-    1. Download [SPair-71k dataset](http://cvlab.postech.ac.kr/research/SPair-71k/)
-
-    1. Unzip the dataset and make sure it looks like ``data/SPair-71k``
-
-    Please cite the following papers if you use SPair-71k dataset:
-
-    ```
-    @article{min2019spair,
-       title={SPair-71k: A Large-scale Benchmark for Semantic Correspondence},
-       author={Juhong Min and Jongmin Lee and Jean Ponce and Minsu Cho},
-       journal={arXiv prepreint arXiv:1908.10543},
-       year={2019}
-    }
-    
-    @InProceedings{min2019hyperpixel, 
-       title={Hyperpixel Flow: Semantic Correspondence with Multi-layer Neural Features},
-       author={Juhong Min and Jongmin Lee and Jean Ponce and Minsu Cho},
-       booktitle={ICCV},
-       year={2019}
-    }
-    ```
-For more information, please see [pygmtools](https://pypi.org/project/pygmtools/).
-
-## Run the Experiment
-
-
-Run training and evaluation
-```bash
-python train_eval.py --cfg path/to/your/yaml
-```
-
-and replace ``path/to/your/yaml`` by path to your configuration file, e.g.
-```bash
-python train_eval.py --cfg experiments/vgg16_common_willow.yaml
-```
-
-Default configuration files are stored in``experiments/`` and you are welcomed to try your own configurations.
-
-### File Organization
-
-```
-├── experiments
-│   the hyperparameter setting of experiments
-├── models
-│     └── COMMON
-│         the module and training pipeline of COMMON
-│          ├── model.py
-│          │   the implementation of training/evaluation procedures of COMMON
-│          ├── model_config.py
-│          │   the declaration of model hyperparameters
-│          └── sconv_archs.py
-│              the implementation of spline convolution (SpilneCNN) operations, the same with BBGM
-├── src
-│  the source code of the Graph Matching, from ThinkMatch
-│      └── loss_func.py
-│          the implementation of loss functions 
-├── eval.py
-|   evlaution script
-└── train_eval.py
-    training script
-```
-
-
-
-
-## Pretrained Models
-We provides pretrained models. The model weights are available via [google drive](https://drive.google.com/drive/folders/1OdpCanr_aO5GxfC3gUXFqWXk8cZBM-nU?usp=share_link)
-
-To use the pretrained models, firstly download the weight files, then add the following line to your yaml file:
-```yaml
-PRETRAINED_PATH: path/to/your/pretrained/weights
-```
-
-
-
-## Results
-
-For benchmark results, please refer to https://paperswithcode.com/task/graph-matching and [ThinkMatch](https://github.com/Thinklab-SJTU/ThinkMatch).
-
-### PascalVOC
-
-| model                                                        | year | aero   | bike   | bird   | boat   | bottle | bus    | car    | cat    | chair  | cow    | table  | dog    | horse  | mbkie  | person | plant  | sheep  | sofa   | train  | tv     | mean   |
-| ------------------------------------------------------------ | ---- | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ |
-| [COMMON](https://arxiv.org/pdf/2212.04085.pdf) | 2023 | 0.6560 | 0.7520 | 0.8080 | 0.7950    |0.8930 | 0.9230 | 0.9010 | 0.8180 | 0.6160 | 0.8070| 0.9500 | 0.8200 |    0.8160    | 0.7950 | 0.6660 |    0.9890 | 0.7890 | 0.8090 | 0.9930 |    0.9380 | 0.8270 |  
-
-### Willow Object Class
-
-| model                                                        | year | remark          | Car    | Duck   | Face   | Motorbike | Winebottle | mean   |
-| ------------------------------------------------------------ | ---- | --------------- | ------ | ------ | ------ | --------- | ---------- | ------ |
-| [COMMON](https://arxiv.org/pdf/2212.04085.pdf) | 2023 | -             | 0.9760 | 0.9820 | 1.0000 | 1.0000 | 0.9960     | 0.9910 |
-
-### SPair-71k
-
-| model                                                        | year | aero   | bike   | bird   | boat   | bottle | bus    | car    | cat    | chair  | cow    | dog    | horse  | mtbike | person | plant  | sheep  | train  | tv     | mean   |
-| ------------------------------------------------------------ | ---- | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ |
-| [COMMON](https://arxiv.org/pdf/2212.04085.pdf)    | 2023 | 0.7730 | 0.6820 | 0.9200 | 0.7950 | 0.7040 | 0.9750 | 0.9160 | 0.8250 | 0.7220 | 0.8800 | 0.8000| 0.7410 | 0.8340 | 0.8280 | 0.9990 | 0.8440 | 0.9820 | 0.9980| 0.8450 |
-
-
-## Credits and Citation
-Please cite the following paper if you use this model in your research:
-```
-@inproceedings{lin2023graph,
-  title={Graph Matching with Bi-level Noisy Correspondence},
-  author={Lin, Yijie and Yang, Mouxing and Yu, Jun and Hu, Peng and Zhang, Changqing and Peng, Xi},
-  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
-  year={2023}
-}
-```
-
-## Acknowledgement
-This repo is built upon the framework of [ThinkMatch](https://github.com/Thinklab-SJTU/ThinkMatch) and the network structure of [BBGM](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123730409.pdf), thanks for their excellent work!
-
diff --git a/COMMON/data/PascalVOC/voc2011_pairs.npz b/COMMON/data/PascalVOC/voc2011_pairs.npz
deleted file mode 100644
index 72a4db8..0000000
Binary files a/COMMON/data/PascalVOC/voc2011_pairs.npz and /dev/null differ
diff --git a/COMMON/docs/images/nc_example.png b/COMMON/docs/images/nc_example.png
deleted file mode 100644
index 05e31c5..0000000
Binary files a/COMMON/docs/images/nc_example.png and /dev/null differ
diff --git a/COMMON/eval.py b/COMMON/eval.py
deleted file mode 100755
index 83e6c5f..0000000
--- a/COMMON/eval.py
+++ /dev/null
@@ -1,354 +0,0 @@
-import time
-from datetime import datetime
-from pathlib import Path
-import xlwt
-
-from src.dataset.data_loader import GMDataset, get_dataloader
-from src.evaluation_metric import *
-from src.parallel import DataParallel
-from src.utils.model_sl import load_model
-from src.utils.data_to_cuda import data_to_cuda
-from src.utils.timer import Timer
-
-from src.utils.config import cfg
-from pygmtools.benchmark import Benchmark
-
-
-def eval_model(model, classes, bm, last_epoch=True, verbose=False, xls_sheet=None):
-    print('Start evaluation...')
-    since = time.time()
-
-    device = next(model.parameters()).device
-
-    was_training = model.training
-    model.eval()
-    model.module.trainings = False
-
-    dataloaders = []
-
-    for cls in classes:
-        image_dataset = GMDataset(cfg.DATASET_FULL_NAME,
-                                  bm,
-                                  cfg.EVAL.SAMPLES,
-                                  cfg.PROBLEM.TEST_ALL_GRAPHS,
-                                  cls,
-                                  cfg.PROBLEM.TYPE)
-
-        torch.manual_seed(cfg.RANDOM_SEED)  # Fix fetched data in test-set to prevent variance
-
-        dataloader = get_dataloader(image_dataset, shuffle=True)
-        dataloaders.append(dataloader)
-
-    recalls = []
-    precisions = []
-    f1s = []
-    coverages = []
-    pred_time = []
-    objs = torch.zeros(len(classes), device=device)
-    cluster_acc = []
-    cluster_purity = []
-    cluster_ri = []
-
-    timer = Timer()
-
-    prediction = []
-
-    for i, cls in enumerate(classes):
-        running_ks_loss = 0.0
-        running_ks_error = 0
-        if verbose:
-            print('Evaluating class {}: {}/{}'.format(cls, i, len(classes)))
-
-        running_since = time.time()
-        iter_num = 0
-
-        pred_time_list = []
-        obj_total_num = torch.zeros(1, device=device)
-        cluster_acc_list = []
-        cluster_purity_list = []
-        cluster_ri_list = []
-        prediction_cls = []
-
-        for inputs in dataloaders[i]:
-            if iter_num >= cfg.EVAL.SAMPLES / inputs['batch_size']:
-                break
-            if model.module.device != torch.device('cpu'):
-                inputs = data_to_cuda(inputs)
-
-            batch_num = inputs['batch_size']
-
-            iter_num = iter_num + 1
-
-            with torch.set_grad_enabled(False):
-                timer.tick()
-                outputs = model(inputs)
-                pred_time_list.append(torch.full((batch_num,), timer.toc() / batch_num))
-
-            # Evaluate matching accuracy
-            if cfg.PROBLEM.TYPE == '2GM':
-                assert 'perm_mat' in outputs
-
-                for b in range(outputs['perm_mat'].shape[0]):
-                    perm_mat = outputs['perm_mat'][b, :outputs['ns'][0][b], :outputs['ns'][1][b]].cpu()
-                    perm_mat = perm_mat.numpy()
-                    eval_dict = dict()
-                    id_pair = inputs['id_list'][0][b], inputs['id_list'][1][b]
-                    eval_dict['ids'] = id_pair
-                    eval_dict['cls'] = cls
-                    eval_dict['perm_mat'] = perm_mat
-                    prediction.append(eval_dict)
-                    prediction_cls.append(eval_dict)
-
-                if 'aff_mat' in outputs:
-                    pred_obj_score = objective_score(outputs['perm_mat'], outputs['aff_mat'])
-                    gt_obj_score = objective_score(outputs['gt_perm_mat'], outputs['aff_mat'])
-                    objs[i] += torch.sum(pred_obj_score / gt_obj_score)
-                    obj_total_num += batch_num
-
-                if 'ks_loss' in outputs:
-                    ks_loss = outputs['ks_loss']
-                    ks_error = outputs['ks_error']
-
-            elif cfg.PROBLEM.TYPE in ['MGM', 'MGM3']:
-                assert 'graph_indices' in outputs
-                assert 'perm_mat_list' in outputs
-
-                ns = outputs['ns']
-                idx = -1
-                for x_pred, (idx_src, idx_tgt) in \
-                        zip(outputs['perm_mat_list'], outputs['graph_indices']):
-                    idx += 1
-                    for b in range(x_pred.shape[0]):
-                        perm_mat = x_pred[b, :ns[idx_src][b], :ns[idx_tgt][b]].cpu()
-                        perm_mat = perm_mat.numpy()
-                        eval_dict = dict()
-                        id_pair = inputs['id_list'][idx_src][b], inputs['id_list'][idx_tgt][b]
-                        eval_dict['ids'] = id_pair
-                        if cfg.PROBLEM.TYPE == 'MGM3':
-                            eval_dict['cls'] = bm.data_dict[id_pair[0]]['cls']
-                        else:
-                            eval_dict['cls'] = cls
-                        eval_dict['perm_mat'] = perm_mat
-                        prediction.append(eval_dict)
-                        prediction_cls.append(eval_dict)
-
-            else:
-                raise ValueError('Unknown problem type {}'.format(cfg.PROBLEM.TYPE))
-
-            # Evaluate clustering accuracy
-            if cfg.PROBLEM.TYPE == 'MGM3':
-                assert 'pred_cluster' in outputs
-                assert 'cls' in outputs
-
-                pred_cluster = outputs['pred_cluster']
-                cls_gt_transpose = [[] for _ in range(batch_num)]
-                for batched_cls in outputs['cls']:
-                    for b, _cls in enumerate(batched_cls):
-                        cls_gt_transpose[b].append(_cls)
-                cluster_acc_list.append(clustering_accuracy(pred_cluster, cls_gt_transpose))
-                cluster_purity_list.append(clustering_purity(pred_cluster, cls_gt_transpose))
-                cluster_ri_list.append(rand_index(pred_cluster, cls_gt_transpose))
-
-            if 'ks_loss' in outputs:
-                running_ks_loss += ks_loss * batch_num
-                running_ks_error += ks_error * batch_num
-
-            if iter_num % cfg.STATISTIC_STEP == 0 and verbose:
-                running_speed = cfg.STATISTIC_STEP * batch_num / (time.time() - running_since)
-                print('Class {:<8} Iteration {:<4} {:>4.2f}sample/s'.format(cls, iter_num, running_speed))
-                running_since = time.time()
-
-        if 'ks_loss' in outputs:
-            print('In class {}: Ks_Loss={:<8.4f} Ks_Error={:<8.4f}'
-                  .format(cls,
-                          running_ks_loss / cfg.EVAL.SAMPLES,
-                          running_ks_error / cfg.EVAL.SAMPLES))
-
-        objs[i] = objs[i] / obj_total_num
-        pred_time.append(torch.cat(pred_time_list))
-        if cfg.PROBLEM.TYPE == 'MGM3':
-            cluster_acc.append(torch.cat(cluster_acc_list))
-            cluster_purity.append(torch.cat(cluster_purity_list))
-            cluster_ri.append(torch.cat(cluster_ri_list))
-
-        if verbose:
-            if cfg.PROBLEM.TYPE != 'MGM3':
-                bm.eval_cls(prediction_cls, cls, verbose=verbose)
-            print('Class {} norm obj score = {:.4f}'.format(cls, objs[i]))
-            print('Class {} pred time = {}s'.format(cls, format_metric(pred_time[i])))
-            if cfg.PROBLEM.TYPE == 'MGM3':
-                print('Class {} cluster acc={}'.format(cls, format_metric(cluster_acc[i])))
-                print('Class {} cluster purity={}'.format(cls, format_metric(cluster_purity[i])))
-                print('Class {} cluster rand index={}'.format(cls, format_metric(cluster_ri[i])))
-
-    if cfg.PROBLEM.TYPE == 'MGM3':
-        result = bm.eval(prediction, classes[0], verbose=True)
-        for cls in classes[0]:
-            precision = result[cls]['precision']
-            recall = result[cls]['recall']
-            f1 = result[cls]['f1']
-            coverage = result[cls]['coverage']
-
-            recalls.append(recall)
-            precisions.append(precision)
-            f1s.append(f1)
-            coverages.append(coverage)
-    else:
-        result = bm.eval(prediction, classes, verbose=True)
-        for cls in classes:
-            precision = result[cls]['precision']
-            recall = result[cls]['recall']
-            f1 = result[cls]['f1']
-            coverage = result[cls]['coverage']
-
-            recalls.append(recall)
-            precisions.append(precision)
-            f1s.append(f1)
-            coverages.append(coverage)
-
-    time_elapsed = time.time() - since
-    print('Evaluation complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))
-
-    model.train(mode=was_training)
-
-    if xls_sheet:
-        for idx, cls in enumerate(classes):
-            xls_sheet.write(0, idx+1, cls)
-        xls_sheet.write(0, idx+2, 'mean')
-
-    xls_row = 1
-
-    # show result
-    if xls_sheet:
-        xls_sheet.write(xls_row, 0, 'precision')
-        xls_sheet.write(xls_row+1, 0, 'recall')
-        xls_sheet.write(xls_row+2, 0, 'f1')
-        xls_sheet.write(xls_row+3, 0, 'coverage')
-    for idx, (cls, cls_p, cls_r, cls_f1, cls_cvg) in enumerate(zip(classes, precisions, recalls, f1s, coverages)):
-        if xls_sheet:
-            xls_sheet.write(xls_row, idx+1, '{:.4f}'.format(cls_p)) #'{:.4f}'.format(torch.mean(cls_p)))
-            xls_sheet.write(xls_row+1, idx+1, '{:.4f}'.format(cls_r)) #'{:.4f}'.format(torch.mean(cls_r)))
-            xls_sheet.write(xls_row+2, idx+1, '{:.4f}'.format(cls_f1)) #'{:.4f}'.format(torch.mean(cls_f1)))
-            xls_sheet.write(xls_row+3, idx+1, '{:.4f}'.format(cls_cvg))
-    if xls_sheet:
-        xls_sheet.write(xls_row, idx+2, '{:.4f}'.format(result['mean']['precision'])) #'{:.4f}'.format(torch.mean(torch.cat(precisions))))
-        xls_sheet.write(xls_row+1, idx+2, '{:.4f}'.format(result['mean']['recall'])) #'{:.4f}'.format(torch.mean(torch.cat(recalls))))
-        xls_sheet.write(xls_row+2, idx+2, '{:.4f}'.format(result['mean']['f1'])) #'{:.4f}'.format(torch.mean(torch.cat(f1s))))
-        xls_row += 4
-
-    if not torch.any(torch.isnan(objs)):
-        print('Normalized objective score')
-        if xls_sheet: xls_sheet.write(xls_row, 0, 'norm objscore')
-        for idx, (cls, cls_obj) in enumerate(zip(classes, objs)):
-            print('{} = {:.4f}'.format(cls, cls_obj))
-            if xls_sheet: xls_sheet.write(xls_row, idx+1, cls_obj.item()) #'{:.4f}'.format(cls_obj))
-        print('average objscore = {:.4f}'.format(torch.mean(objs)))
-        if xls_sheet:
-            xls_sheet.write(xls_row, idx+2, torch.mean(objs).item()) #'{:.4f}'.format(torch.mean(objs)))
-            xls_row += 1
-
-    if cfg.PROBLEM.TYPE == 'MGM3':
-        print('Clustering accuracy')
-        if xls_sheet: xls_sheet.write(xls_row, 0, 'cluster acc')
-        for idx, (cls, cls_acc) in enumerate(zip(classes, cluster_acc)):
-            print('{} = {}'.format(cls, format_metric(cls_acc)))
-            if xls_sheet: xls_sheet.write(xls_row, idx+1, torch.mean(cls_acc).item()) #'{:.4f}'.format(torch.mean(cls_acc)))
-        print('average clustering accuracy = {}'.format(format_metric(torch.cat(cluster_acc))))
-        if xls_sheet:
-            xls_sheet.write(xls_row, idx+2, torch.mean(torch.cat(cluster_acc)).item()) #'{:.4f}'.format(torch.mean(torch.cat(cluster_acc))))
-            xls_row += 1
-
-        print('Clustering purity')
-        if xls_sheet: xls_sheet.write(xls_row, 0, 'cluster purity')
-        for idx, (cls, cls_acc) in enumerate(zip(classes, cluster_purity)):
-            print('{} = {}'.format(cls, format_metric(cls_acc)))
-            if xls_sheet: xls_sheet.write(xls_row, idx+1, torch.mean(cls_acc).item()) #'{:.4f}'.format(torch.mean(cls_acc)))
-        print('average clustering purity = {}'.format(format_metric(torch.cat(cluster_purity))))
-        if xls_sheet:
-            xls_sheet.write(xls_row, idx+2, torch.mean(torch.cat(cluster_purity)).item()) #'{:.4f}'.format(torch.mean(torch.cat(cluster_purity))))
-            xls_row += 1
-
-        print('Clustering rand index')
-        if xls_sheet: xls_sheet.write(xls_row, 0, 'rand index')
-        for idx, (cls, cls_acc) in enumerate(zip(classes, cluster_ri)):
-            print('{} = {}'.format(cls, format_metric(cls_acc)))
-            if xls_sheet: xls_sheet.write(xls_row, idx+1, torch.mean(cls_acc).item()) #'{:.4f}'.format(torch.mean(cls_acc)))
-        print('average rand index = {}'.format(format_metric(torch.cat(cluster_ri))))
-        if xls_sheet:
-            xls_sheet.write(xls_row, idx+2, torch.mean(torch.cat(cluster_ri)).item()) #'{:.4f}'.format(torch.mean(torch.cat(cluster_ri))))
-            xls_row += 1
-
-    print('Predict time')
-    if xls_sheet: xls_sheet.write(xls_row, 0, 'time')
-    for idx, (cls, cls_time) in enumerate(zip(classes, pred_time)):
-        print('{} = {}'.format(cls, format_metric(cls_time)))
-        if xls_sheet: xls_sheet.write(xls_row, idx + 1, torch.mean(cls_time).item()) #'{:.4f}'.format(torch.mean(cls_time)))
-    print('average time = {}'.format(format_metric(torch.cat(pred_time))))
-    if xls_sheet:
-        xls_sheet.write(xls_row, idx+2, torch.mean(torch.cat(pred_time)).item()) #'{:.4f}'.format(torch.mean(torch.cat(pred_time))))
-        xls_row += 1
-
-    bm.rm_gt_cache(last_epoch=last_epoch)
-
-    return torch.Tensor(recalls)
-
-
-if __name__ == '__main__':
-    from src.utils.dup_stdout_manager import DupStdoutFileManager
-    from src.utils.parse_args import parse_args
-    from src.utils.print_easydict import print_easydict
-
-    args = parse_args('Deep learning of graph matching evaluation code.')
-
-    import importlib
-    mod = importlib.import_module(cfg.MODULE)
-    Net = mod.Net
-
-    torch.manual_seed(cfg.RANDOM_SEED)
-    if torch.cuda.is_available():
-        torch.cuda.manual_seed(cfg.RANDOM_SEED)
-
-    ds_dict = cfg[cfg.DATASET_FULL_NAME] if ('DATASET_FULL_NAME' in cfg) and (cfg.DATASET_FULL_NAME in cfg) else {}
-    benchmark = Benchmark(name=cfg.DATASET_FULL_NAME,
-                          sets='test',
-                          problem=cfg.PROBLEM.TYPE,
-                          obj_resize=cfg.PROBLEM.RESCALE,
-                          filter=cfg.PROBLEM.FILTER,
-                          **ds_dict)
-
-    cls = None if cfg.EVAL.CLASS in ['none', 'all'] else cfg.EVAL.CLASS
-    if cls is None:
-        clss = benchmark.classes
-    else:
-        clss = [cls]
-
-    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
-
-    model = Net()
-    model = model.to(device)
-    model = DataParallel(model, device_ids=cfg.GPUS)
-
-    if not Path(cfg.OUTPUT_PATH).exists():
-        Path(cfg.OUTPUT_PATH).mkdir(parents=True)
-    now_time = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')
-    wb = xlwt.Workbook()
-    ws = wb.add_sheet('epoch{}'.format(cfg.EVAL.EPOCH))
-    with DupStdoutFileManager(str(Path(cfg.OUTPUT_PATH) / ('eval_log_' + now_time + '.log'))) as _:
-        print_easydict(cfg)
-
-        model_path = ''
-        if cfg.EVAL.EPOCH is not None and cfg.EVAL.EPOCH > 0:
-            model_path = str(Path(cfg.OUTPUT_PATH) / 'params' / 'params_{:04}.pt'.format(cfg.EVAL.EPOCH))
-        if len(cfg.PRETRAINED_PATH) > 0:
-            model_path = cfg.PRETRAINED_PATH
-        if len(model_path) > 0:
-            print('Loading model parameters from {}'.format(model_path))
-            load_model(model, model_path, False)
-
-        pcks = eval_model(
-            model, clss,
-            benchmark,
-            verbose=True,
-            xls_sheet=ws
-        )
-    wb.save(str(Path(cfg.OUTPUT_PATH) / ('eval_result_' + now_time + '.xls')))
diff --git a/COMMON/experiments/vgg16_common_spair71k.yaml b/COMMON/experiments/vgg16_common_spair71k.yaml
deleted file mode 100644
index e248b92..0000000
--- a/COMMON/experiments/vgg16_common_spair71k.yaml
+++ /dev/null
@@ -1,82 +0,0 @@
-MODEL_NAME: vgg16_common
-DATASET_NAME: spair71k
-
-DATASET_FULL_NAME: SPair71k
-
-MODULE: models.COMMON.model
-
-BACKBONE: VGG16_bn_final
-
-BATCH_SIZE: 8
-DATALOADER_NUM: 2
-FP16: False
-
-RANDOM_SEED: 4
-
-#PRETRAINED_PATH: ./output/vgg16_common_spair71k/params/params_0020.pt
-
-
-# available GPU ids
-GPUS:
-  - 0
-
-# Problem configuration
-PROBLEM:
-  TYPE: 2GM
-  RESCALE: # rescaled image size
-    - 256
-    - 256
-  FILTER: 'intersection'
-
-# Graph construction settings
-GRAPH:
-  SRC_GRAPH_CONSTRUCT: tri
-  TGT_GRAPH_CONSTRUCT: tri
-  SYM_ADJACENCY: True
-
-# Training settings
-TRAIN:
-  # start, end epochs
-  START_EPOCH: 0
-  NUM_EPOCHS: 20
-
-  #  LOSS_FUNC: hung
-  #  LOSS_FUNC: offset
-  #  LOSS_FUNC: perm
-  #  LOSS_FUNC: contrast
-  #  LOSS_FUNC: distill
-  LOSS_FUNC: custom
-
-  OPTIMIZER: Adam
-
-  # learning rate
-  LR: 3.e-4 # 2.e-3
-  SEPARATE_BACKBONE_LR: True
-  BACKBONE_LR: 2.e-5
-  MOMENTUM: 0.9
-  LR_DECAY: 0.5
-  LR_STEP: # (in epochs)
-    #    - 2
-    - 4
-    - 8
-    #    - 14
-    - 12
-    - 16
-
-  EPOCH_ITERS: 400 # iterations per epoch
-
-  CLASS: none
-
-# Evaluation settings
-EVAL:
-  EPOCH: 20  # epoch to be tested
-  SAMPLES: 1000  # number of tested pairs for each class
-#  CLASS: bottle
-
-# model parameters
-COMMON:
-  FEATURE_CHANNEL: 512
-  ALPHA: 0.4
-  DISTILL: True
-  WARMUP_STEP: 400
-  MOMENTUM: 0.995
\ No newline at end of file
diff --git a/COMMON/experiments/vgg16_common_voc.yaml b/COMMON/experiments/vgg16_common_voc.yaml
deleted file mode 100644
index f64f41a..0000000
--- a/COMMON/experiments/vgg16_common_voc.yaml
+++ /dev/null
@@ -1,75 +0,0 @@
-MODEL_NAME: vgg16_common
-DATASET_NAME: voc
-
-DATASET_FULL_NAME: PascalVOC
-
-MODULE: models.COMMON.model
-
-BACKBONE: VGG16_bn_final
-
-BATCH_SIZE: 8
-DATALOADER_NUM: 2
-FP16: False
-
-RANDOM_SEED: 66
-
-#PRETRAINED_PATH: ./output/vgg16_common_voc/params/params_0020.pt
-
-
-# available GPU ids
-GPUS:
-  - 0
-#  - 1
-
-# Problem configuration
-PROBLEM:
-  TYPE: 2GM
-  RESCALE:  # rescaled image size
-    - 256
-    - 256
-  FILTER: 'intersection'
-
-# Graph construction settings
-GRAPH:
-  SRC_GRAPH_CONSTRUCT: tri
-  TGT_GRAPH_CONSTRUCT: tri
-  SYM_ADJACENCY: True
-
-# Training settings
-TRAIN:
-  # start, end epochs
-  START_EPOCH: 0
-  NUM_EPOCHS: 20
-
-  LOSS_FUNC: custom
-  OPTIMIZER: Adam
-
-  # learning rate
-  LR: 3.e-4 # 2.e-3
-  SEPARATE_BACKBONE_LR: True
-  BACKBONE_LR: 2.e-5
-  MOMENTUM: 0.9
-  LR_DECAY: 0.5
-  LR_STEP:  # (in epochs)
-    - 2
-    - 4
-    - 6
-    - 8
-    - 10
-
-  EPOCH_ITERS: 2000  # iterations per epoch
-
-  CLASS: none
-
-# Evaluation settings
-EVAL:
-  EPOCH: 20  # epoch to be tested
-  SAMPLES: 1000  # number of tested pairs for each class
-
-# model parameters
-COMMON:
-  FEATURE_CHANNEL: 512
-  ALPHA: 0.4
-  DISTILL: True
-  WARMUP_STEP: 2000 # usually set to EPOCH_ITERS
-  MOMENTUM: 0.995
\ No newline at end of file
diff --git a/COMMON/experiments/vgg16_common_willow.yaml b/COMMON/experiments/vgg16_common_willow.yaml
deleted file mode 100644
index c1b43a6..0000000
--- a/COMMON/experiments/vgg16_common_willow.yaml
+++ /dev/null
@@ -1,77 +0,0 @@
-MODEL_NAME: vgg16_common
-DATASET_NAME: willow
-
-DATASET_FULL_NAME: WillowObject
-
-MODULE: models.COMMON.model
-
-BACKBONE: VGG16_bn_final
-
-BATCH_SIZE: 8
-DATALOADER_NUM: 2
-FP16: False
-
-RANDOM_SEED: 66
-
-#PRETRAINED_PATH: ./output/vgg16_common_willow/params/params_0005.pt
-
-
-# available GPU ids
-GPUS:
-  - 0
-
-# Problem configuration
-PROBLEM:
-  TYPE: 2GM
-  RESCALE: # rescaled image size
-    - 256
-    - 256
-  FILTER: 'intersection'
-
-# Graph construction settings
-GRAPH:
-  SRC_GRAPH_CONSTRUCT: tri
-  TGT_GRAPH_CONSTRUCT: tri
-  SYM_ADJACENCY: True
-
-# Willow object class dataset configuration
-WillowObject:
-  TRAIN_NUM: 20  # number of images for training set
-  SPLIT_OFFSET: 0  # the starting index of training set
-
-# Training settings
-TRAIN:
-  # start, end epochs
-  START_EPOCH: 0
-  NUM_EPOCHS: 10
-
-  LOSS_FUNC: custom
-
-
-  OPTIMIZER: Adam
-
-  # learning rate
-  LR: 2.e-3 # 2.5e-3
-  SEPARATE_BACKBONE_LR: True
-  BACKBONE_LR: 2.5e-5
-  MOMENTUM: 0.9
-  LR_DECAY: 0.5
-  LR_STEP: # (in epochs)
-    - 6
-
-  EPOCH_ITERS: 100  # iterations per epoch
-
-  CLASS: none
-
-# Evaluation settings
-EVAL:
-  EPOCH: 10  # epoch to be tested
-  SAMPLES: 100  # number of tested pairs for each class
-
-# model parameters
-COMMON:
-  FEATURE_CHANNEL: 512 # following BBGM
-  ALPHA: 0.4
-  DISTILL: True
-  WARMUP_STEP: 300 # as the training set of Willow is small, we use a large warmup step
-  MOMENTUM: 0.995
\ No newline at end of file
diff --git a/COMMON/models/COMMON/model.py b/COMMON/models/COMMON/model.py
deleted file mode 100644
index 736f32b..0000000
--- a/COMMON/models/COMMON/model.py
+++ /dev/null
@@ -1,223 +0,0 @@
-import torch
-import itertools
-import numpy as np
-
-from models.COMMON.sconv_archs import SiameseSConvOnNodes, SiameseNodeFeaturesToEdgeFeatures
-from src.feature_align import feature_align
-from src.factorize_graph_matching import construct_aff_mat
-from src.utils.pad_tensor import pad_tensor
-from src.lap_solvers.sinkhorn import Sinkhorn
-from src.lap_solvers.hungarian import hungarian
-
-from src.utils.config import cfg
-
-from src.backbone import *
-
-from src.loss_func import *
-
-CNN = eval(cfg.BACKBONE)
-
-
-def lexico_iter(lex):
-    return itertools.combinations(lex, 2)
-
-
-def normalize_over_channels(x):
-    channel_norms = torch.norm(x, dim=1, keepdim=True)
-    return x / channel_norms
-
-
-def concat_features(embeddings, num_vertices):
-    res = torch.cat([embedding[:, :num_v] for embedding, num_v in zip(embeddings, num_vertices)], dim=-1)
-    return res.transpose(0, 1)
-
-
-class InnerProduct(nn.Module):
-    def __init__(self, output_dim):
-        super(InnerProduct, self).__init__()
-        self.d = output_dim
-
-    def _forward(self, X, Y):
-        assert X.shape[1] == Y.shape[1] == self.d, (X.shape[1], Y.shape[1], self.d)
-        X = torch.nn.functional.normalize(X, dim=-1)
-        Y = torch.nn.functional.normalize(Y, dim=-1)
-        res = torch.matmul(X, Y.transpose(0, 1))
-        return res
-
-    def forward(self, Xs, Ys):
-        return [self._forward(X, Y) for X, Y in zip(Xs, Ys)]
-
-
-class Backbone(CNN):
-    def __init__(self):
-        super(Backbone, self).__init__()
-        self.message_pass_node_features = SiameseSConvOnNodes(input_node_dim=cfg.COMMON.FEATURE_CHANNEL * 2)
-        self.build_edge_features_from_node_features = SiameseNodeFeaturesToEdgeFeatures(
-            total_num_nodes=self.message_pass_node_features.num_node_features
-        )
-        self.vertex_affinity = InnerProduct(256)
-        self.rescale = cfg.PROBLEM.RESCALE
-        self.logit_scale = nn.Parameter(torch.ones([]) * np.log(1 / cfg.COMMON.SOFTMAXTEMP))
-
-        self.projection = nn.Sequential(
-            nn.Linear(1024, 1024, bias=True),
-            nn.BatchNorm1d(1024),
-            nn.ReLU(),
-            nn.Linear(1024, 256, bias=True),
-            nn.BatchNorm1d(256),
-            nn.ReLU()
-        )
-
-    def forward(self, data_dict, online=True):
-        with torch.no_grad():
-            self.logit_scale.clamp_(0, 4.6052)  # clamp temperature to be between 0.01 and 1
-
-        images = data_dict['images']
-        points = data_dict['Ps']
-        n_points = data_dict['ns']
-        graphs = data_dict['pyg_graphs']
-        batch_size = data_dict['batch_size']
-        num_graphs = len(images)
-        orig_graph_list = []
-
-        for image, p, n_p, graph in zip(images, points, n_points, graphs):
-            # extract feature
-            nodes = self.node_layers(image)
-            edges = self.edge_layers(nodes)
-
-            nodes = normalize_over_channels(nodes)
-            edges = normalize_over_channels(edges)
-
-            # arrange features, following BBGM
-            U = feature_align(nodes, p, n_p, self.rescale)
-            F = feature_align(edges, p, n_p, self.rescale)
-            U = concat_features(U, n_p)
-            F = concat_features(F, n_p)
-            node_features = torch.cat((U, F), dim=1)
-
-            # GNN
-            graph.x = node_features
-            graph = self.message_pass_node_features(graph)
-            orig_graph = self.build_edge_features_from_node_features(graph)
-            orig_graph_list.append(orig_graph)
-
-        unary_affs_list = [
-            self.vertex_affinity([self.projection(item.x) for item in g_1], [self.projection(item.x) for item in g_2])
-            for (g_1, g_2) in lexico_iter(orig_graph_list)
-        ]
-
-        # prepare aligned node features for computing contrastive loss
-        keypoint_number_list = []  # the number of keypoints in each image pair
-        node_feature_list = []  # node features for computing contrastive loss
-
-        node_feature_graph1 = torch.zeros([batch_size, data_dict['gt_perm_mat'].shape[1], node_features.shape[1]],
-                                         device=node_features.device)
-        node_feature_graph2 = torch.zeros([batch_size, data_dict['gt_perm_mat'].shape[2], node_features.shape[1]],
-                                         device=node_features.device)
-        # count the available keypoints in number list
-        for index in range(batch_size):
-            node_feature_graph1[index, :orig_graph_list[0][index].x.shape[0]] = orig_graph_list[0][index].x
-            node_feature_graph2[index, :orig_graph_list[1][index].x.shape[0]] = orig_graph_list[1][index].x
-            keypoint_number_list.append(torch.sum(data_dict['gt_perm_mat'][index]))
-        number = int(sum(keypoint_number_list))  # calculate the number of correspondence
-
-        # pre-align the keypoints for further computing the contrastive loss
-        node_feature_graph2 = torch.bmm(data_dict['gt_perm_mat'], node_feature_graph2)
-        final_node_feature_graph1 = torch.zeros([number, node_features.shape[1]], device=node_features.device)
-        final_node_feature_graph2 = torch.zeros([number, node_features.shape[1]], device=node_features.device)
-        count = 0
-        for index in range(batch_size):
-            final_node_feature_graph1[count: count + int(keypoint_number_list[index])] \
-                = node_feature_graph1[index, :int(keypoint_number_list[index])]
-            final_node_feature_graph2[count: count + int(keypoint_number_list[index])] \
-                = node_feature_graph2[index, :int(keypoint_number_list[index])]
-            count += int(keypoint_number_list[index])
-        node_feature_list.append(self.projection(final_node_feature_graph1))
-        node_feature_list.append(self.projection(final_node_feature_graph2))
-
-        if online == False:
-            # output of the momentum network
-            return node_feature_list
-        elif online == True:
-            # output of the online network
-            x_list = []
-            for unary_affs, (idx1, idx2) in zip(unary_affs_list, lexico_iter(range(num_graphs))):
-                Kp = torch.stack(pad_tensor(unary_affs), dim=0)
-                # conduct hungarian matching to get the permutation matrix for evaluation
-                x = hungarian(Kp, n_points[idx1], n_points[idx2])
-                x_list.append(x)
-            return node_feature_list, x_list
-
-
-class Net(nn.Module):
-    def __init__(self):
-        super(Net, self).__init__()
-        self.onlineNet = Backbone()
-        self.momentumNet = Backbone()  # initialize the online network and momentum network
-        self.momentum = cfg.COMMON.MOMENTUM  # momentum parameter for the momentum network
-        self.backbone_params = list(self.onlineNet.backbone_params) # used in train_eval.py
-        self.warmup_step = cfg.COMMON.WARMUP_STEP  # warmup steps for the distillation
-        self.epoch_iters = cfg.TRAIN.EPOCH_ITERS  # iterations for one epoch, specified by the training dataset
-
-        self.model_pairs = [[self.onlineNet, self.momentumNet]]
-        self.copy_params()  # initialize the momentum network
-
-        assert cfg.PROBLEM.TYPE == '2GM'  # only support 2GM problem currently
-
-    def forward(self, data_dict, training=False, iter_num=0, epoch=0):
-        # calculate the distillation weight alpha
-        if epoch * self.epoch_iters + iter_num >= self.warmup_step:
-            alpha = cfg.COMMON.ALPHA
-        else:
-            alpha = cfg.COMMON.ALPHA * min(1, (epoch * self.epoch_iters + iter_num) / self.warmup_step)
-
-        # output of the online network
-        node_feature_list, x_list = self.onlineNet(data_dict)
-
-        if training == True:
-            # the momentum network is only using for training
-            assert cfg.COMMON.DISTILL == True
-
-            # obtain output of the momentum network
-            with torch.no_grad():
-                self._momentum_update()
-                node_feature_m_list = self.momentumNet(data_dict, online=False)
-            # loss function
-            contrastloss = Distill_InfoNCE()
-            loss = contrastloss(node_feature_list, node_feature_m_list, alpha,
-                                self.onlineNet.logit_scale, self.momentumNet.logit_scale)
-            crossloss = Distill_QuadraticContrast()
-            loss = loss + crossloss(node_feature_list, node_feature_m_list,
-                                    self.onlineNet.logit_scale, self.momentumNet.logit_scale)
-
-            if cfg.PROBLEM.TYPE == '2GM':
-                data_dict.update({
-                    'perm_mat': x_list[0],
-                    'loss': loss,
-                    'ds_mat': None,
-                })
-        else:
-            # directly output the results
-            if cfg.PROBLEM.TYPE == '2GM':
-                data_dict.update({
-                    'perm_mat': x_list[0],
-                    'ds_mat': None,
-                })
-        return data_dict
-
-    @property
-    def device(self):
-        return next(self.parameters()).device
-
-    @torch.no_grad()
-    def copy_params(self):
-        for model_pair in self.model_pairs:
-            for param, param_m in zip(model_pair[0].parameters(), model_pair[1].parameters()):
-                param_m.data.copy_(param.data)  # initialize
-                param_m.requires_grad = False  # not update by gradient
-
-    @torch.no_grad()
-    def _momentum_update(self):
-        for model_pair in self.model_pairs:
-            for param, param_m in zip(model_pair[0].parameters(), model_pair[1].parameters()):
-                param_m.data = param_m.data * self.momentum + param.data * (1. - self.momentum)
diff --git a/COMMON/models/COMMON/model_config.py b/COMMON/models/COMMON/model_config.py
deleted file mode 100644
index 9d72422..0000000
--- a/COMMON/models/COMMON/model_config.py
+++ /dev/null
@@ -1,14 +0,0 @@
-from easydict import EasyDict as edict
-
-__C = edict()
-
-model_cfg = __C
-
-# COMMON model options.
-__C.COMMON = edict()
-__C.COMMON.FEATURE_CHANNEL = 512
-__C.COMMON.ALPHA = 0.4
-__C.COMMON.DISTILL = True
-__C.COMMON.WARMUP_STEP = 0
-__C.COMMON.MOMENTUM = 0.995
-__C.COMMON.SOFTMAXTEMP = 0.07
diff --git a/COMMON/models/COMMON/sconv_archs.py b/COMMON/models/COMMON/sconv_archs.py
deleted file mode 100644
index 0193112..0000000
--- a/COMMON/models/COMMON/sconv_archs.py
+++ /dev/null
@@ -1,96 +0,0 @@
-import torch.nn
-import torch
-import torch.nn.functional as F
-from torch_geometric.nn import SplineConv
-
-
-class SConv(torch.nn.Module):
-    def __init__(self, input_features, output_features):
-        super(SConv, self).__init__()
-
-        self.in_channels = input_features
-        self.num_layers = 2
-        self.convs = torch.nn.ModuleList()
-
-        for _ in range(self.num_layers):
-            conv = SplineConv(input_features, output_features, dim=2, kernel_size=5, aggr="max")
-            self.convs.append(conv)
-            input_features = output_features
-
-        input_features = output_features
-        self.out_channels = input_features
-        self.reset_parameters()
-
-    def reset_parameters(self):
-        for conv in self.convs:
-            conv.reset_parameters()
-
-    def forward(self, data):
-        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr
-        xs = [x]
-
-        for conv in self.convs[:-1]:
-            xs += [F.relu(conv(xs[-1], edge_index, edge_attr))]
-
-        xs += [self.convs[-1](xs[-1], edge_index, edge_attr)]
-        return xs[-1]
-
-
-class SiameseSConvOnNodes(torch.nn.Module):
-    def __init__(self, input_node_dim):
-        super(SiameseSConvOnNodes, self).__init__()
-        self.num_node_features = input_node_dim
-        self.mp_network = SConv(input_features=self.num_node_features, output_features=self.num_node_features)
-
-    def forward(self, graph):
-        old_features = graph.x
-        result = self.mp_network(graph)
-        graph.x = old_features + 0.1 * result
-        return graph
-
-
-class SiameseNodeFeaturesToEdgeFeatures(torch.nn.Module):
-    def __init__(self, total_num_nodes):
-        super(SiameseNodeFeaturesToEdgeFeatures, self).__init__()
-        self.num_edge_features = total_num_nodes
-
-    def forward(self, graph, hyperedge=False):
-        orig_graphs = graph.to_data_list()
-        orig_graphs = [self.vertex_attr_to_edge_attr(graph) for graph in orig_graphs]
-        if hyperedge:
-            orig_graphs = [self.vertex_attr_to_hyperedge_attr(graph) for graph in orig_graphs]
-        return orig_graphs
-
-    def vertex_attr_to_edge_attr(self, graph):
-        """Assigns the difference of node features to each edge"""
-        flat_edges = graph.edge_index.transpose(0, 1).reshape(-1)
-        vertex_attrs = torch.index_select(graph.x, dim=0, index=flat_edges)
-
-        new_shape = (graph.edge_index.shape[1], 2, vertex_attrs.shape[1])
-        vertex_attrs_reshaped = vertex_attrs.reshape(new_shape).transpose(0, 1)
-        new_edge_attrs = vertex_attrs_reshaped[0] - vertex_attrs_reshaped[1]
-        graph.edge_attr = new_edge_attrs
-        return graph
-
-    def vertex_attr_to_hyperedge_attr(self, graph):
-        """Assigns the angle of node features to each hyperedge.
-           graph.hyperedge_index is the incidence matrix."""
-        flat_edges = graph.hyperedge_index.transpose(0, 1).reshape(-1)
-        vertex_attrs = torch.index_select(graph.x, dim=0, index=flat_edges)
-
-        new_shape = (graph.hyperedge_index.shape[1], 3, vertex_attrs.shape[1])
-
-        vertex_attrs_reshaped = vertex_attrs.reshape(new_shape).transpose(0, 1)
-        v01 = vertex_attrs_reshaped[0] - vertex_attrs_reshaped[1]
-        v02 = vertex_attrs_reshaped[0] - vertex_attrs_reshaped[2]
-        v12 = vertex_attrs_reshaped[1] - vertex_attrs_reshaped[2]
-        nv01 = torch.norm(v01, p=2, dim=-1)
-        nv02 = torch.norm(v02, p=2, dim=-1)
-        nv12 = torch.norm(v12, p=2, dim=-1)
-
-        cos1 = torch.sum(v01 * v02, dim=-1) / (nv01 * nv02)
-        cos2 = torch.sum(-v01 * v12, dim=-1) / (nv01 * nv12)
-        cos3 = torch.sum(-v12 * -v02, dim=-1) / (nv12 * nv02)
-
-        graph.hyperedge_attr = torch.stack((cos1, cos2, cos3), dim=-1)
-        return graph
diff --git a/COMMON/src/__init__.py b/COMMON/src/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/COMMON/src/backbone.py b/COMMON/src/backbone.py
deleted file mode 100644
index 466605f..0000000
--- a/COMMON/src/backbone.py
+++ /dev/null
@@ -1,114 +0,0 @@
-import torch
-import torch.nn as nn
-from torchvision import models
-
-
-class VGG16_base(nn.Module):
-    r"""
-    The base class of VGG16. It downloads the pretrained weight by torchvision API, and maintain the layers needed for
-    deep graph matching models.
-    """
-    def __init__(self, batch_norm=True, final_layers=False):
-        super(VGG16_base, self).__init__()
-        self.node_layers, self.edge_layers, self.final_layers = self.get_backbone(batch_norm)
-        if not final_layers: self.final_layers = None
-        self.backbone_params = list(self.parameters())
-
-    def forward(self, *input):
-        raise NotImplementedError
-
-    @property
-    def device(self):
-        return next(self.parameters()).device
-
-    @staticmethod
-    def get_backbone(batch_norm):
-        """
-        Get pretrained VGG16 models for feature extraction.
-
-        :return: feature sequence
-        """
-        if batch_norm:
-            model = models.vgg16_bn(pretrained=True)
-        else:
-            model = models.vgg16(pretrained=True)
-
-        conv_layers = nn.Sequential(*list(model.features.children()))
-
-        conv_list = node_list = edge_list = []
-
-        # get the output of relu4_2(node features) and relu5_1(edge features)
-        cnt_m, cnt_r = 1, 0
-        for layer, module in enumerate(conv_layers):
-            if isinstance(module, nn.Conv2d):
-                cnt_r += 1
-            if isinstance(module, nn.MaxPool2d):
-                cnt_r = 0
-                cnt_m += 1
-            conv_list += [module]
-
-            #if cnt_m == 4 and cnt_r == 2 and isinstance(module, nn.ReLU):
-            if cnt_m == 4 and cnt_r == 3 and isinstance(module, nn.Conv2d):
-                node_list = conv_list
-                conv_list = []
-            #elif cnt_m == 5 and cnt_r == 1 and isinstance(module, nn.ReLU):
-            elif cnt_m == 5 and cnt_r == 2 and isinstance(module, nn.Conv2d):
-                edge_list = conv_list
-                conv_list = []
-
-        assert len(node_list) > 0 and len(edge_list) > 0
-
-        # Set the layers as a nn.Sequential module
-        node_layers = nn.Sequential(*node_list)
-        edge_layers = nn.Sequential(*edge_list)
-        final_layers = nn.Sequential(*conv_list, nn.AdaptiveMaxPool2d((1, 1), return_indices=False)) # this final layer follows Rolink et al. ECCV20
-
-        return node_layers, edge_layers, final_layers
-    
-
-class VGG16_bn_final(VGG16_base):
-    r"""
-    VGG16 with batch normalization and final layers.
-    """
-    def __init__(self):
-        super(VGG16_bn_final, self).__init__(True, True)
-
-
-class VGG16_bn(VGG16_base):
-    r"""
-    VGG16 with batch normalization, without final layers.
-    """
-    def __init__(self):
-        super(VGG16_bn, self).__init__(True, False)
-
-
-class VGG16_final(VGG16_base):
-    r"""
-    VGG16 without batch normalization, with final layers.
-    """
-    def __init__(self):
-        super(VGG16_final, self).__init__(False, True)
-
-
-class VGG16(VGG16_base):
-    r"""
-    VGG16 without batch normalization or final layers.
-    """
-    def __init__(self):
-        super(VGG16, self).__init__(False, False)
-
-
-class NoBackbone(nn.Module):
-    r"""
-    A model with no CNN backbone for non-image data.
-    """
-    def __init__(self, *args, **kwargs):
-        super(NoBackbone, self).__init__()
-        self.node_layers, self.edge_layers = None, None
-
-    def forward(self, *input):
-        raise NotImplementedError
-
-    @property
-    def device(self):
-        return next(self.parameters()).device
diff --git a/COMMON/src/backbone_gcan.py b/COMMON/src/backbone_gcan.py
deleted file mode 100644
index c580c0d..0000000
--- a/COMMON/src/backbone_gcan.py
+++ /dev/null
@@ -1,114 +0,0 @@
-import torch
-import torch.nn as nn
-from torchvision import models
-
-
-class VGG16_base(nn.Module):
-    r"""
-    The base class of VGG16. It downloads the pretrained weight by torchvision API, and maintain the layers needed for
-    deep graph matching models.
-    """
-    def __init__(self, batch_norm=True, final_layers=False):
-        super(VGG16_base, self).__init__()
-        self.node_layers, self.edge_layers, self.final_layers_max,  self.final_layers_avg= self.get_backbone(batch_norm)
-        if not final_layers: self.final_layers = None
-        self.backbone_params = list(self.parameters())
-
-    def forward(self, *input):
-        raise NotImplementedError
-
-    @property
-    def device(self):
-        return next(self.parameters()).device
-
-    @staticmethod
-    def get_backbone(batch_norm):
-        """
-        Get pretrained VGG16 models for feature extraction.
-
-        :return: feature sequence
-        """
-        if batch_norm:
-            model = models.vgg16_bn(pretrained=True)
-        else:
-            model = models.vgg16(pretrained=True)
-
-        conv_layers = nn.Sequential(*list(model.features.children()))
-
-        conv_list = node_list = edge_list = []
-
-        # get the output of relu4_2(node features) and relu5_1(edge features)
-        cnt_m, cnt_r = 1, 0
-        for layer, module in enumerate(conv_layers):
-            if isinstance(module, nn.Conv2d):
-                cnt_r += 1
-            if isinstance(module, nn.MaxPool2d):
-                cnt_r = 0
-                cnt_m += 1
-            conv_list += [module]
-
-            # if cnt_m == 4 and cnt_r == 2 and isinstance(module, nn.ReLU):
-            if cnt_m == 4 and cnt_r == 3 and isinstance(module, nn.Conv2d):
-                node_list = conv_list
-                conv_list = []
-            # elif cnt_m == 5 and cnt_r == 1 and isinstance(module, nn.ReLU):
-            elif cnt_m == 5 and cnt_r == 2 and isinstance(module, nn.Conv2d):
-                edge_list = conv_list
-                conv_list = []
-
-        assert len(node_list) > 0 and len(edge_list) > 0
-
-        # Set the layers as a nn.Sequential module
-        node_layers = nn.Sequential(*node_list)
-        edge_layers = nn.Sequential(*edge_list)
-        final_layers_max = nn.Sequential(*conv_list, nn.AdaptiveMaxPool2d((1, 1), return_indices=False)) # this final layer follows Rolink et al. ECCV20
-        final_layers_avg = nn.Sequential(*conv_list, nn.AdaptiveAvgPool2d((1, 1)))
-        return node_layers, edge_layers, final_layers_max,final_layers_avg
-    
-
-class VGG16_bn_final(VGG16_base):
-    r"""
-    VGG16 with batch normalization and final layers.
-    """
-    def __init__(self):
-        super(VGG16_bn_final, self).__init__(True, True)
-
-
-class VGG16_bn(VGG16_base):
-    r"""
-    VGG16 with batch normalization, without final layers.
-    """
-    def __init__(self):
-        super(VGG16_bn, self).__init__(True, False)
-
-
-class VGG16_final(VGG16_base):
-    r"""
-    VGG16 without batch normalization, with final layers.
-    """
-    def __init__(self):
-        super(VGG16_final, self).__init__(False, True)
-
-
-class VGG16(VGG16_base):
-    r"""
-    VGG16 without batch normalization or final layers.
-    """
-    def __init__(self):
-        super(VGG16, self).__init__(False, False)
-
-
-class NoBackbone(nn.Module):
-    r"""
-    A model with no CNN backbone for non-image data.
-    """
-    def __init__(self, *args, **kwargs):
-        super(NoBackbone, self).__init__()
-        self.node_layers, self.edge_layers = None, None
-
-    def forward(self, *input):
-        raise NotImplementedError
-
-    @property
-    def device(self):
-        return next(self.parameters()).device
diff --git a/COMMON/src/build_graphs.py b/COMMON/src/build_graphs.py
deleted file mode 100644
index 14d05fa..0000000
--- a/COMMON/src/build_graphs.py
+++ /dev/null
@@ -1,171 +0,0 @@
-import torch
-from torch import Tensor
-from scipy.spatial import Delaunay
-from scipy.spatial.qhull import QhullError
-
-import itertools
-import numpy as np
-
-from typing import Tuple
-
-
-def build_graphs(P_np: np.ndarray, n: int, n_pad: int=None, edge_pad: int=None, stg: str='fc', sym: bool=True,
-                 thre: int=0) -> Tuple[np.ndarray, np.ndarray, np.ndarray, int]:
-    r"""
-    Build graph matrix :math:`\mathbf G, \mathbf H` from point set :math:`\mathbf P`.
-    This function supports only cpu operations in numpy.
-    :math:`\mathbf G, \mathbf H` are constructed from adjacency matrix :math:`\mathbf A`:
-    :math:`\mathbf A = \mathbf G \cdot \mathbf H^\top`
-
-    :param P_np: :math:`(n\times 2)` point set containing point coordinates
-    :param n: number of exact points in the point set
-    :param n_pad: padded node length
-    :param edge_pad: padded edge length
-    :param stg: strategy to build graphs. Options: ``fc``, ``near``, ``tri``
-    :param sym: True for a symmetric adjacency, False for half adjacency (A contains only the upper half)
-    :param thre: The threshold value of 'near' strategy
-    :return: :math:`A`, :math:`G`, :math:`H`, edge_num
-
-    The possible options for ``stg``:
-    ::
-
-        'fc'(default): construct a fully-connected graph
-        'near': construct a fully-connected graph, but edges longer than ``thre`` are removed
-        'tri': apply Delaunay triangulation
-
-    An illustration of :math:`\mathbf G, \mathbf H` with their connections to the graph, the adjacency matrix,
-    the incident matrix is
-
-    .. image:: ../../images/build_graphs_GH.png
-    """
-
-    assert stg in ('fc', 'tri', 'near'), 'No strategy named {} found.'.format(stg)
-
-    if stg == 'tri':
-        A = delaunay_triangulate(P_np[0:n, :])
-    elif stg == 'near':
-        A = fully_connect(P_np[0:n, :], thre=thre)
-    else:
-        A = fully_connect(P_np[0:n, :])
-    edge_num = int(np.sum(A, axis=(0, 1)))
-    assert n > 0 and edge_num > 0, 'Error in n = {} and edge_num = {}'.format(n, edge_num)
-
-    if n_pad is None:
-        n_pad = n
-    if edge_pad is None:
-        edge_pad = edge_num
-    assert n_pad >= n
-    assert edge_pad >= edge_num
-
-    G = np.zeros((n_pad, edge_pad), dtype=np.float32)
-    H = np.zeros((n_pad, edge_pad), dtype=np.float32)
-    edge_idx = 0
-    for i in range(n):
-        if sym:
-            range_j = range(n)
-        else:
-            range_j = range(i, n)
-        for j in range_j:
-            if A[i, j] == 1:
-                G[i, edge_idx] = 1
-                H[j, edge_idx] = 1
-                edge_idx += 1
-
-    return A, G, H, edge_num
-
-
-def delaunay_triangulate(P: np.ndarray) -> np.ndarray:
-    r"""
-    Perform delaunay triangulation on point set P.
-
-    :param P: :math:`(n\times 2)` point set
-    :return: adjacency matrix :math:`A`
-    """
-    n = P.shape[0]
-    if n < 3:
-        A = fully_connect(P)
-    else:
-        try:
-            d = Delaunay(P)
-            #assert d.coplanar.size == 0, 'Delaunay triangulation omits points.'
-            A = np.zeros((n, n))
-            for simplex in d.simplices:
-                for pair in itertools.permutations(simplex, 2):
-                    A[pair] = 1
-        except QhullError as err:
-            print('Delaunay triangulation error detected. Return fully-connected graph.')
-            print('Traceback:')
-            print(err)
-            A = fully_connect(P)
-    return A
-
-
-def fully_connect(P: np.ndarray, thre=None) -> np.ndarray:
-    r"""
-    Return the adjacency matrix of a fully-connected graph.
-
-    :param P: :math:`(n\times 2)` point set
-    :param thre: edges that are longer than this threshold will be removed
-    :return: adjacency matrix :math:`A`
-    """
-    n = P.shape[0]
-    A = np.ones((n, n)) - np.eye(n)
-    if thre is not None:
-        for i in range(n):
-            for j in range(i):
-                if np.linalg.norm(P[i] - P[j]) > thre:
-                    A[i, j] = 0
-                    A[j, i] = 0
-    return A
-
-
-def make_grids(start, stop, num) -> np.ndarray:
-    r"""
-    Make grids.
-
-    This function supports only cpu operations in numpy.
-
-    :param start: start index in all dimensions
-    :param stop: stop index in all dimensions
-    :param num: number of grids in each dimension
-    :return: point set P
-    """
-    length = np.prod(num)
-    P = np.zeros((length, len(num)), dtype=np.float32)
-    assert len(start) == len(stop) == len(num)
-    for i, (begin, end, n) in enumerate(zip(start, stop, num)):
-        g = np.linspace(begin, end, n + 1)
-        g -= (g[1] - g[0]) / 2
-        g = g[1:]
-        P[:, i] = np.reshape(np.repeat([g], length / n, axis=i), length)
-    return P
-
-
-def reshape_edge_feature(F: Tensor, G: Tensor, H: Tensor, device=None) -> Tensor:
-    r"""
-    Given point-level features extracted from images, reshape it into edge feature matrix :math:`X`,
-    where features are arranged by the order of :math:`G`, :math:`H`.
-
-    .. math::
-        \mathbf{X}_{e_{ij}} = concat(\mathbf{F}_i, \mathbf{F}_j)
-
-    where :math:`e_{ij}` means an edge connecting nodes :math:`i, j`
-
-    :param F: :math:`(b\times d \times n)` extracted point-level feature matrix.
-     :math:`b`: batch size. :math:`d`: feature dimension. :math:`n`: number of nodes.
-    :param G: :math:`(b\times n \times e)` factorized adjacency matrix, where :math:`\mathbf A = \mathbf G \cdot \mathbf H^\top`. :math:`e`: number of edges.
-    :param H: :math:`(b\times n \times e)` factorized adjacency matrix, where :math:`\mathbf A = \mathbf G \cdot \mathbf H^\top`
-    :param device: device. If not specified, it will be the same as the input
-    :return: edge feature matrix X :math:`(b \times 2d \times e)`
-    """
-    if device is None:
-        device = F.device
-
-    batch_num = F.shape[0]
-    feat_dim = F.shape[1]
-    point_num, edge_num = G.shape[1:3]
-    X = torch.zeros(batch_num, 2 * feat_dim, edge_num, dtype=torch.float32, device=device)
-    X[:, 0:feat_dim, :] = torch.matmul(F, G)
-    X[:, feat_dim:2*feat_dim, :] = torch.matmul(F, H)
-
-    return X
diff --git a/COMMON/src/dataset/__init__.py b/COMMON/src/dataset/__init__.py
deleted file mode 100644
index 2f59780..0000000
--- a/COMMON/src/dataset/__init__.py
+++ /dev/null
@@ -1,2 +0,0 @@
-from .qaplib import QAPLIB
-from .dataset_config import dataset_cfg
diff --git a/COMMON/src/dataset/base_dataset.py b/COMMON/src/dataset/base_dataset.py
deleted file mode 100644
index ac22702..0000000
--- a/COMMON/src/dataset/base_dataset.py
+++ /dev/null
@@ -1,6 +0,0 @@
-class BaseDataset:
-    def __init__(self):
-        pass
-
-    def get_pair(self, cls, shuffle):
-        raise NotImplementedError
diff --git a/COMMON/src/dataset/data_loader.py b/COMMON/src/dataset/data_loader.py
deleted file mode 100644
index e09d2ea..0000000
--- a/COMMON/src/dataset/data_loader.py
+++ /dev/null
@@ -1,454 +0,0 @@
-import torch
-import torch.nn.functional as F
-from torch.utils.data import Dataset
-from torchvision import transforms
-import torch_geometric as pyg
-import numpy as np
-import random
-from src.build_graphs import build_graphs
-from src.factorize_graph_matching import kronecker_sparse, kronecker_torch
-from src.sparse_torch import CSRMatrix3d, CSCMatrix3d
-from src.dataset import *
-
-from src.utils.config import cfg
-
-from itertools import combinations, product
-
-
-class GMDataset(Dataset):
-    def __init__(self, name, bm, length, using_all_graphs=False, cls=None, problem='2GM'):
-        self.name = name
-        self.bm = bm
-        self.using_all_graphs = using_all_graphs
-        self.obj_size = self.bm.obj_resize
-        self.test = True if self.bm.sets == 'test' else False
-        self.cls = None if cls in ['none', 'all'] else cls
-
-        if self.cls is None:
-            if problem == 'MGM3':
-                self.classes = list(combinations(self.bm.classes, cfg.PROBLEM.NUM_CLUSTERS))
-            else:
-                self.classes = self.bm.classes
-        else:
-            self.classes = [self.cls]
-
-        self.problem_type = problem
-        if problem != 'MGM3':
-            self.img_num_list = self.bm.compute_img_num(self.classes)
-        else:
-            self.img_num_list = self.bm.compute_img_num(self.classes[0])
-
-        if self.problem_type == '2GM':
-            self.id_combination, self.length = self.bm.get_id_combination(self.cls)
-            self.length_list = []
-            for cls in self.classes:
-                cls_length = self.bm.compute_length(cls)
-                self.length_list.append(cls_length)
-        else:
-            self.length = length
-
-    def __len__(self):
-        return self.length
-
-    def __getitem__(self, idx):
-        if self.problem_type == '2GM':
-            return self.get_pair(idx, self.cls)
-        elif self.problem_type == 'MGM':
-            return self.get_multi(idx, self.cls)
-        elif self.problem_type == 'MGM3':
-            return self.get_multi_cluster(idx)
-        else:
-            raise NameError("Unknown problem type: {}".format(self.problem_type))
-
-    @staticmethod
-    def to_pyg_graph(A, P):
-        rescale = max(cfg.PROBLEM.RESCALE)
-
-        edge_feat = 0.5 * (np.expand_dims(P, axis=1) - np.expand_dims(P, axis=0)) / rescale + 0.5  # from Rolink's paper
-        edge_index = np.nonzero(A)
-        edge_attr = edge_feat[edge_index]
-
-        edge_attr = np.clip(edge_attr, 0, 1)
-        assert (edge_attr > -1e-5).all(), P
-
-        o3_A = np.expand_dims(A, axis=0) * np.expand_dims(A, axis=1) * np.expand_dims(A, axis=2)
-        hyperedge_index = np.nonzero(o3_A)
-
-        pyg_graph = pyg.data.Data(
-            x=torch.tensor(P / rescale).to(torch.float32),
-            edge_index=torch.tensor(np.array(edge_index), dtype=torch.long),
-            edge_attr=torch.tensor(edge_attr).to(torch.float32),
-            hyperedge_index=torch.tensor(np.array(hyperedge_index), dtype=torch.long),
-        )
-        return pyg_graph
-
-    def get_pair(self, idx, cls):
-        #anno_pair, perm_mat = self.bm.get_pair(self.cls if self.cls is not None else
-        #                                       (idx % (cfg.BATCH_SIZE * len(self.classes))) // cfg.BATCH_SIZE)
-        cls_num = random.randrange(0, len(self.classes))
-        ids = list(self.id_combination[cls_num][idx % self.length_list[cls_num]])
-        anno_pair, perm_mat_, id_list = self.bm.get_data(ids)
-        perm_mat = perm_mat_[(0, 1)].toarray()
-        while min(perm_mat.shape[0], perm_mat.shape[1]) <= 2 or perm_mat.size >= cfg.PROBLEM.MAX_PROB_SIZE > 0 or perm_mat.sum() == 0:
-            anno_pair, perm_mat_, id_list = self.bm.rand_get_data(cls)
-            perm_mat = perm_mat_[(0, 1)].toarray()
-        if cfg.MODEL_NAME == 'vgg16_gcan_varied':
-            perm_mat_dummy = np.zeros([perm_mat.shape[0] + 1, perm_mat.shape[1] + 1], dtype=np.float32)
-            perm_mat_dummy[0: perm_mat.shape[0], 0: perm_mat.shape[1]] = perm_mat
-            perm_mat_dummy[-1, perm_mat_dummy.sum(axis=0) == 0] = 1
-            perm_mat_dummy[perm_mat_dummy.sum(axis=1) == 0, -1] = 1
-            perm_mat = perm_mat_dummy
-
-        cls = [anno['cls'] for anno in anno_pair]
-        P1 = [(kp['x'], kp['y']) for kp in anno_pair[0]['kpts']]
-        P2 = [(kp['x'], kp['y']) for kp in anno_pair[1]['kpts']]
-
-        n1, n2 = len(P1), len(P2)
-        univ_size = [anno['univ_size'] for anno in anno_pair]
-
-        P1 = np.array(P1)
-        P2 = np.array(P2)
-
-        A1, G1, H1, e1 = build_graphs(P1, n1, stg=cfg.GRAPH.SRC_GRAPH_CONSTRUCT, sym=cfg.GRAPH.SYM_ADJACENCY)
-        if cfg.GRAPH.TGT_GRAPH_CONSTRUCT == 'same':
-            G2 = perm_mat.transpose().dot(G1)
-            H2 = perm_mat.transpose().dot(H1)
-            A2 = G2.dot(H2.transpose())
-            e2 = e1
-        else:
-            A2, G2, H2, e2 = build_graphs(P2, n2, stg=cfg.GRAPH.TGT_GRAPH_CONSTRUCT, sym=cfg.GRAPH.SYM_ADJACENCY)
-
-        pyg_graph1 = self.to_pyg_graph(A1, P1)
-        pyg_graph2 = self.to_pyg_graph(A2, P2)
-
-        ret_dict = {'Ps': [torch.Tensor(x) for x in [P1, P2]],
-                    'ns': [torch.tensor(x) for x in [n1, n2]],
-                    'es': [torch.tensor(x) for x in [e1, e2]],
-                    'gt_perm_mat': perm_mat,
-                    'Gs': [torch.Tensor(x) for x in [G1, G2]],
-                    'Hs': [torch.Tensor(x) for x in [H1, H2]],
-                    'As': [torch.Tensor(x) for x in [A1, A2]],
-                    'pyg_graphs': [pyg_graph1, pyg_graph2],
-                    'cls': [str(x) for x in cls],
-                    'id_list': id_list,
-                    'univ_size': [torch.tensor(int(x)) for x in univ_size],
-                    }
-
-        imgs = [anno['img'] for anno in anno_pair]
-        if imgs[0] is not None:
-            trans = transforms.Compose([
-                    transforms.ToTensor(),
-                    transforms.Normalize(cfg.NORM_MEANS, cfg.NORM_STD)
-                    ])
-            imgs = [trans(img) for img in imgs]
-            ret_dict['images'] = imgs
-        elif 'feat' in anno_pair[0]['kpts'][0]:
-            feat1 = np.stack([kp['feat'] for kp in anno_pair[0]['kpts']], axis=-1)
-            feat2 = np.stack([kp['feat'] for kp in anno_pair[1]['kpts']], axis=-1)
-            ret_dict['features'] = [torch.Tensor(x) for x in [feat1, feat2]]
-
-        return ret_dict
-
-    def get_multi(self, idx, cls):
-        if self.problem_type == 'MGM' and self.using_all_graphs:
-            if cls == None:
-                cls = random.randrange(0, len(self.classes))
-                num_graphs = self.img_num_list[cls]
-                cls = self.classes[cls]
-            elif type(cls) == str:
-                cls_num = self.classes.index(cls)
-                num_graphs = self.img_num_list[cls_num]
-            else:
-                num_graphs = self.img_num_list[cls]
-                cls = self.classes[cls]
-
-        elif self.problem_type == 'MGM3' and self.using_all_graphs:
-            if cls == None:
-                cls = random.randrange(0, len(self.classes[0]))
-                num_graphs = self.img_num_list[cls]
-                cls = self.classes[cls]
-            elif type(cls) == str:
-                cls_num = self.classes[0].index(cls)
-                num_graphs = self.img_num_list[cls_num]
-            else:
-                num_graphs = self.img_num_list[cls]
-                cls = self.classes[cls]
-        else:
-            num_graphs = cfg.PROBLEM.NUM_GRAPHS
-
-        refetch = True
-        while refetch:
-            refetch = False
-            anno_list, perm_mat_dict, id_list = self.bm.rand_get_data(cls, num=num_graphs)
-            perm_mat_dict = {key: val.toarray() for key, val in perm_mat_dict.items()}
-            for pm in perm_mat_dict.values():
-                if pm.shape[0] <= 2 or pm.shape[1] <= 2 or pm.size >= cfg.PROBLEM.MAX_PROB_SIZE > 0 or pm.sum() == 0:
-                    refetch = True
-                    break
-
-        cls = [anno['cls'] for anno in anno_list]
-        Ps = [[(kp['x'], kp['y']) for kp in anno_dict['kpts']] for anno_dict in anno_list]
-
-        ns = [len(P) for P in Ps]
-        univ_size = [anno['univ_size'] for anno in anno_list]
-
-        Ps = [np.array(P) for P in Ps]
-
-        As = []
-        Gs = []
-        Hs = []
-        As_tgt = []
-        Gs_tgt = []
-        Hs_tgt = []
-        for P, n in zip(Ps, ns):
-            # In multi-graph matching (MGM), when a graph is regarded as target graph, its topology may be different
-            # from when it is regarded as source graph. These are represented by suffix "tgt".
-            A, G, H, _ = build_graphs(P, n, stg=cfg.GRAPH.SRC_GRAPH_CONSTRUCT)
-            A_tgt, G_tgt, H_tgt, _ = build_graphs(P, n, stg=cfg.GRAPH.TGT_GRAPH_CONSTRUCT)
-            As.append(A)
-            Gs.append(G)
-            Hs.append(H)
-            As_tgt.append(A_tgt)
-            Gs_tgt.append(G_tgt)
-            Hs_tgt.append(H_tgt)
-
-        pyg_graphs = [self.to_pyg_graph(A, P) for A, P in zip(As, Ps)]
-        pyg_graphs_tgt = [self.to_pyg_graph(A, P) for A, P in zip(As_tgt, Ps)]
-
-        ret_dict = {
-            'Ps': [torch.Tensor(x) for x in Ps],
-            'ns': [torch.tensor(x) for x in ns],
-            'gt_perm_mat': perm_mat_dict,
-            'Gs': [torch.Tensor(x) for x in Gs],
-            'Hs': [torch.Tensor(x) for x in Hs],
-            'As': [torch.Tensor(x) for x in As],
-            'Gs_tgt': [torch.Tensor(x) for x in Gs_tgt],
-            'Hs_tgt': [torch.Tensor(x) for x in Hs_tgt],
-            'As_tgt': [torch.Tensor(x) for x in As_tgt],
-            'pyg_graphs': pyg_graphs,
-            'pyg_graphs_tgt': pyg_graphs_tgt,
-            'cls': [str(x) for x in cls],
-            'id_list': id_list,
-            'univ_size': [torch.tensor(int(x)) for x in univ_size],
-        }
-
-        imgs = [anno['img'] for anno in anno_list]
-        if imgs[0] is not None:
-            trans = transforms.Compose([
-                transforms.ToTensor(),
-                transforms.Normalize(cfg.NORM_MEANS, cfg.NORM_STD)
-            ])
-            imgs = [trans(img) for img in imgs]
-            ret_dict['images'] = imgs
-        elif 'feat' in anno_list[0]['kpts'][0]:
-            feats = [np.stack([kp['feat'] for kp in anno_dict['kpts']], axis=-1) for anno_dict in anno_list]
-            ret_dict['features'] = [torch.Tensor(x) for x in feats]
-
-        return ret_dict
-
-    def get_multi_cluster(self, idx):
-        dicts = []
-        if self.cls is None or self.cls == 'none':
-            cls_iterator = random.choice(self.classes)
-        else:
-            cls_iterator = self.cls
-        for cls in cls_iterator:
-            dicts.append(self.get_multi(idx, cls))
-        ret_dict = {}
-        for key in dicts[0]:
-            ret_dict[key] = []
-            for dic in dicts:
-                ret_dict[key] += dic[key]
-        return ret_dict
-
-
-class QAPDataset(Dataset):
-    def __init__(self, name, length, cls=None, **args):
-        self.name = name
-        self.ds = eval(self.name)(**args, cls=cls)
-        self.classes = self.ds.classes
-        self.cls = None if cls == 'none' else cls
-        self.length = length
-
-    def __len__(self):
-        #return len(self.ds.data_list)
-        return self.length
-
-    def __getitem__(self, idx):
-        Fi, Fj, perm_mat, sol, name = self.ds.get_pair(idx % len(self.ds.data_list))
-        if perm_mat.size <= 2 * 2 or perm_mat.size >= cfg.PROBLEM.MAX_PROB_SIZE > 0:
-            return self.__getitem__(random.randint(0, len(self) - 1))
-
-        #if np.max(ori_aff_mat) > 0:
-        #    norm_aff_mat = ori_aff_mat / np.mean(ori_aff_mat)
-        #else:
-        #    norm_aff_mat = ori_aff_mat
-
-        ret_dict = {'Fi': Fi,
-                    'Fj': Fj,
-                    'gt_perm_mat': perm_mat,
-                    'ns': [torch.tensor(x) for x in perm_mat.shape],
-                    'solution': torch.tensor(sol),
-                    'name': name,
-                    'univ_size': [torch.tensor(x) for x in perm_mat.shape],}
-
-        return ret_dict
-
-
-def collate_fn(data: list):
-    """
-    Create mini-batch data for training.
-    :param data: data dict
-    :return: mini-batch
-    """
-    def pad_tensor(inp):
-        assert type(inp[0]) == torch.Tensor
-        it = iter(inp)
-        t = next(it)
-        max_shape = list(t.shape)
-        while True:
-            try:
-                t = next(it)
-                for i in range(len(max_shape)):
-                    max_shape[i] = int(max(max_shape[i], t.shape[i]))
-            except StopIteration:
-                break
-        max_shape = np.array(max_shape)
-
-        padded_ts = []
-        for t in inp:
-            pad_pattern = np.zeros(2 * len(max_shape), dtype=np.int64)
-            pad_pattern[::-2] = max_shape - np.array(t.shape)
-            #pad_pattern = torch.from_numpy(np.asfortranarray(pad_pattern))
-            pad_pattern = tuple(pad_pattern.tolist())
-            padded_ts.append(F.pad(t, pad_pattern, 'constant', 0))
-
-        return padded_ts
-
-    def stack(inp):
-        if type(inp[0]) == list:
-            ret = []
-            for vs in zip(*inp):
-                ret.append(stack(vs))
-        elif type(inp[0]) == dict:
-            ret = {}
-            for kvs in zip(*[x.items() for x in inp]):
-                ks, vs = zip(*kvs)
-                for k in ks:
-                    assert k == ks[0], "Keys mismatch."
-                ret[k] = stack(vs)
-        elif type(inp[0]) == torch.Tensor:
-            new_t = pad_tensor(inp)
-            ret = torch.stack(new_t, 0)
-        elif type(inp[0]) == np.ndarray:
-            new_t = pad_tensor([torch.from_numpy(x) for x in inp])
-            ret = torch.stack(new_t, 0)
-        elif type(inp[0]) == pyg.data.Data:
-            ret = pyg.data.Batch.from_data_list(inp)
-        elif type(inp[0]) == str:
-            ret = inp
-        elif type(inp[0]) == tuple:
-            ret = inp
-
-        else:
-            raise ValueError('Cannot handle type {}'.format(type(inp[0])))
-        return ret
-
-    ret = stack(data)
-
-    # compute CPU-intensive Kronecker product here to leverage multi-processing nature of dataloader
-    if 'Gs' in ret and 'Hs' in ret:
-        if cfg.PROBLEM.TYPE == '2GM' and len(ret['Gs']) == 2 and len(ret['Hs']) == 2:
-            G1, G2 = ret['Gs']
-            H1, H2 = ret['Hs']
-            if cfg.FP16:
-                sparse_dtype = np.float16
-            else:
-                sparse_dtype = np.float32
-            if G1.shape[0] > 1:
-                KGHs_sparse = []
-                for b in range(G1.shape[0]):
-                    K1G = [kronecker_sparse(x, y).astype(sparse_dtype) for x, y in
-                           zip(G2[b].unsqueeze(0), G1[b].unsqueeze(0))]  # 1 as source graph, 2 as target graph
-                    K1H = [kronecker_sparse(x, y).astype(sparse_dtype) for x, y in zip(H2[b].unsqueeze(0), H1[b].unsqueeze(0))]
-
-                    # if 'NGM' in cfg and cfg.NGM.SPARSE_MODEL:
-                    K1G_sparse = CSCMatrix3d(K1G)
-                    K1H_sparse = CSCMatrix3d(K1H).transpose()
-                    KGHs_sparse.append((K1G_sparse.indices, K1H_sparse.indices))
-                ret['KGHs_sparse'] = KGHs_sparse
-            else:
-                K1G = [kronecker_sparse(x, y).astype(sparse_dtype) for x, y in zip(G2, G1)]  # 1 as source graph, 2 as target graph
-                K1H = [kronecker_sparse(x, y).astype(sparse_dtype) for x, y in zip(H2, H1)]
-
-                # if 'NGM' in cfg and cfg.NGM.SPARSE_MODEL:
-                K1G_sparse = CSCMatrix3d(K1G)
-                K1H_sparse = CSCMatrix3d(K1H).transpose()
-                ret['KGHs_sparse'] = [(K1G_sparse.indices, K1H_sparse.indices)]
-            # else:
-            K1G = [kronecker_sparse(x, y).astype(sparse_dtype) for x, y in
-                   zip(G2, G1)]  # 1 as source graph, 2 as target graph
-            K1H = [kronecker_sparse(x, y).astype(sparse_dtype) for x, y in zip(H2, H1)]
-
-            K1G = CSRMatrix3d(K1G)
-            K1H = CSRMatrix3d(K1H).transpose()
-            ret['KGHs'] = K1G, K1H
-        elif cfg.PROBLEM.TYPE in ['MGM', 'MGM3'] and 'Gs_tgt' in ret and 'Hs_tgt' in ret:
-            ret['KGHs'] = dict()
-            for idx_1, idx_2 in product(range(len(ret['Gs'])), repeat=2):
-                # 1 as source graph, 2 as target graph
-                G1 = ret['Gs'][idx_1]
-                H1 = ret['Hs'][idx_1]
-                G2 = ret['Gs_tgt'][idx_2]
-                H2 = ret['Hs_tgt'][idx_2]
-                if cfg.FP16:
-                    sparse_dtype = np.float16
-                else:
-                    sparse_dtype = np.float32
-                KG = [kronecker_sparse(x, y).astype(sparse_dtype) for x, y in zip(G2, G1)]
-                KH = [kronecker_sparse(x, y).astype(sparse_dtype) for x, y in zip(H2, H1)]
-                KG = CSRMatrix3d(KG)
-                KH = CSRMatrix3d(KH).transpose()
-                ret['KGHs']['{},{}'.format(idx_1, idx_2)] = KG, KH
-        else:
-            raise ValueError('Data type not understood.')
-
-    if 'Fi' in ret and 'Fj' in ret:
-        Fi = ret['Fi']
-        Fj = ret['Fj']
-        aff_mat = kronecker_torch(Fj, Fi)
-        ret['aff_mat'] = aff_mat
-
-    ret['batch_size'] = len(data)
-    ret['univ_size'] = torch.tensor([max(*[item[b] for item in ret['univ_size']]) for b in range(ret['batch_size'])])
-
-    for v in ret.values():
-        if type(v) is list:
-            ret['num_graphs'] = len(v)
-            break
-
-    return ret
-
-
-def worker_init_fix(worker_id):
-    """
-    Init dataloader workers with fixed seed.
-    """
-    random.seed(cfg.RANDOM_SEED + worker_id)
-    np.random.seed(cfg.RANDOM_SEED + worker_id)
-
-
-def worker_init_rand(worker_id):
-    """
-    Init dataloader workers with torch.initial_seed().
-    torch.initial_seed() returns different seeds when called from different dataloader threads.
-    """
-    random.seed(torch.initial_seed())
-    np.random.seed(torch.initial_seed() % 2 ** 32)
-
-
-def get_dataloader(dataset, fix_seed=True, shuffle=False):
-    return torch.utils.data.DataLoader(
-        dataset, batch_size=cfg.BATCH_SIZE, shuffle=shuffle, num_workers=cfg.DATALOADER_NUM, collate_fn=collate_fn,
-        pin_memory=False, worker_init_fn=worker_init_fix if fix_seed else worker_init_rand
-    )
diff --git a/COMMON/src/dataset/dataset_config.py b/COMMON/src/dataset/dataset_config.py
deleted file mode 100644
index 2bc532f..0000000
--- a/COMMON/src/dataset/dataset_config.py
+++ /dev/null
@@ -1,13 +0,0 @@
-from easydict import EasyDict as edict
-
-__C = edict()
-
-dataset_cfg = __C
-
-# QAPLIB dataset
-__C.QAPLIB = edict()
-__C.QAPLIB.DIR = 'data/qapdata'
-__C.QAPLIB.FEED_TYPE = 'affmat' # 'affmat' (affinity matrix) or 'adj' (adjacency matrix)
-__C.QAPLIB.ONLINE_REPO = 'http://anjos.mgi.polymtl.ca/qaplib/'
-__C.QAPLIB.MAX_TRAIN_SIZE = 200
-__C.QAPLIB.MAX_TEST_SIZE = 100
diff --git a/COMMON/src/dataset/qaplib.py b/COMMON/src/dataset/qaplib.py
deleted file mode 100644
index dba0262..0000000
--- a/COMMON/src/dataset/qaplib.py
+++ /dev/null
@@ -1,157 +0,0 @@
-import numpy as np
-from src.utils.config import cfg
-from pathlib import Path
-from src.dataset.base_dataset import BaseDataset
-import re
-import urllib
-
-
-cls_list = ['bur', 'chr', 'els', 'esc', 'had', 'kra', 'lipa', 'nug', 'rou', 'scr', 'sko', 'ste', 'tai', 'tho', 'wil']
-
-class QAPLIB(BaseDataset):
-    def __init__(self, sets, cls, fetch_online=False):
-        super(QAPLIB, self).__init__()
-        self.classes = ['qaplib']
-        self.sets = sets
-
-        if cls is not None and cls != 'none':
-            idx = cls_list.index(cls)
-            self.cls_list = [cls_list[idx]]
-        else:
-            self.cls_list = cls_list
-
-        self.data_list = []
-        self.qap_path = Path(cfg.QAPLIB.DIR)
-        for inst in self.cls_list:
-            for dat_path in self.qap_path.glob(inst + '*.dat'):
-                name = dat_path.name[:-4]
-                prob_size = int(re.findall(r"\d+", name)[0])
-                if (self.sets == 'test' and prob_size > cfg.QAPLIB.MAX_TEST_SIZE) \
-                    or (self.sets == 'train' and prob_size > cfg.QAPLIB.MAX_TRAIN_SIZE):
-                    continue
-                self.data_list.append(name)
-
-        # remove trivial instance esc16f
-        if 'esc16f' in self.data_list:
-            self.data_list.remove('esc16f')
-
-        # define compare function
-        def name_cmp(a, b):
-            a = re.findall(r'[0-9]+|[a-z]+', a)
-            b = re.findall(r'[0-9]+|[a-z]+', b)
-            for _a, _b in zip(a, b):
-                if _a.isdigit() and _b.isdigit():
-                    _a = int(_a)
-                    _b = int(_b)
-                cmp = (_a > _b) - (_a < _b)
-                if cmp != 0:
-                    return cmp
-            if len(a) > len(b):
-                return -1
-            elif len(a) < len(b):
-                return 1
-            else:
-                return 0
-
-        def cmp_to_key(mycmp):
-            'Convert a cmp= function into a key= function'
-            class K:
-                def __init__(self, obj, *args):
-                    self.obj = obj
-                def __lt__(self, other):
-                    return mycmp(self.obj, other.obj) < 0
-                def __gt__(self, other):
-                    return mycmp(self.obj, other.obj) > 0
-                def __eq__(self, other):
-                    return mycmp(self.obj, other.obj) == 0
-                def __le__(self, other):
-                    return mycmp(self.obj, other.obj) <= 0
-                def __ge__(self, other):
-                    return mycmp(self.obj, other.obj) >= 0
-                def __ne__(self, other):
-                    return mycmp(self.obj, other.obj) != 0
-            return K
-
-        # sort data list according to the names
-        self.data_list.sort(key=cmp_to_key(name_cmp))
-
-        fetched_flag = self.qap_path / 'fetched_online'
-
-        if fetch_online or not fetched_flag.exists():
-            self.__fetch_online()
-            fetched_flag.touch()
-
-    def get_pair(self, idx, shuffle=None):
-        """
-        Get QAP data by index
-        :param idx: dataset index
-        :param shuffle: no use here
-        :return: (pair of data, groundtruth permutation matrix)
-        """
-        name = self.data_list[idx]
-
-        dat_path = self.qap_path / (name + '.dat')
-        sln_path = self.qap_path / (name + '.sln')
-        dat_file = dat_path.open()
-        sln_file = sln_path.open()
-
-        def split_line(x):
-            for _ in re.split(r'[,\s]', x.rstrip('\n')):
-                if _ == "":
-                    continue
-                else:
-                    yield int(_)
-
-        dat_list = [[_ for _ in split_line(line)] for line in dat_file]
-        sln_list = [[_ for _ in split_line(line)] for line in sln_file]
-
-        prob_size = dat_list[0][0]
-
-        # read data
-        r = 0
-        c = 0
-        Fi = [[]]
-        Fj = [[]]
-        F = Fi
-        for l in dat_list[1:]:
-            F[r] += l
-            c += len(l)
-            assert c <= prob_size
-            if c == prob_size:
-                r += 1
-                if r < prob_size:
-                    F.append([])
-                    c = 0
-                else:
-                    F = Fj
-                    r = 0
-                    c = 0
-        Fi = np.array(Fi, dtype=np.float32)
-        Fj = np.array(Fj, dtype=np.float32)
-        assert Fi.shape == Fj.shape == (prob_size, prob_size)
-        #K = np.kron(Fj, Fi)
-
-        # read solution
-        sol = sln_list[0][1]
-        perm_list = []
-        for _ in sln_list[1:]:
-            perm_list += _
-        assert len(perm_list) == prob_size
-        perm_mat = np.zeros((prob_size, prob_size), dtype=np.float32)
-        for r, c in enumerate(perm_list):
-            perm_mat[r, c - 1] = 1
-
-        return Fi, Fj, perm_mat, sol, name
-
-    def __fetch_online(self):
-        """
-        Fetch from online QAPLIB data
-        """
-        for name in self.data_list:
-            dat_content = urllib.request.urlopen(cfg.QAPLIB.ONLINE_REPO + 'data.d/{}.dat'.format(name)).read()
-            sln_content = urllib.request.urlopen(cfg.QAPLIB.ONLINE_REPO + 'soln.d/{}.sln'.format(name)).read()
-
-            dat_file = (self.qap_path / (name + '.dat')).open('wb')
-            dat_file.write(dat_content)
-            sln_file = (self.qap_path / (name + '.sln')).open('wb')
-            sln_file.write(sln_content)
diff --git a/COMMON/src/displacement_layer.py b/COMMON/src/displacement_layer.py
deleted file mode 100644
index 0c34c41..0000000
--- a/COMMON/src/displacement_layer.py
+++ /dev/null
@@ -1,48 +0,0 @@
-import torch
-import torch.nn as nn
-from torch import Tensor
-
-
-class Displacement(nn.Module):
-    r"""
-    Displacement Layer computes the displacement vector for each point in the source image, with its corresponding point
-    (or points) in target image.
-
-    The output is a displacement matrix constructed from all displacement vectors.
-    This metric measures the shift from source point to predicted target point, and can be applied for matching
-    accuracy.
-
-    Together with displacement matrix d, this function will also return a grad_mask, which helps to filter out dummy
-    nodes in practice.
-
-    .. math::
-        \mathbf{d}_i = \sum_{j \in V_2} \left( \mathbf{S}_{i, j} P_{2j} \right)- P_{1i}
-
-    Proposed by `"Zanfir et al. Deep Learning of Graph Matching. CVPR 2018."
-    <http://openaccess.thecvf.com/content_cvpr_2018/html/Zanfir_Deep_Learning_of_CVPR_2018_paper.html>`_
-    """
-    def __init__(self):
-        super(Displacement, self).__init__()
-
-    def forward(self, s: Tensor, P_src: Tensor, P_tgt: Tensor, ns_gt: Tensor=None):
-        r"""
-        :param s: :math:`(b\times n_1 \times n_2)` permutation or doubly stochastic matrix. :math:`b`: batch size.
-         :math:`n_1`: number of nodes in source image. :math:`n_2`: number of nodes in target image
-        :param P_src: :math:`(b\times n_1 \times 2)` point set on source image
-        :param P_tgt: :math:`(b\times n_2 \times 2)` point set on target image
-        :param ns_gt: :math:`(b)` number of exact pairs. We support batched instances with different number of nodes,
-         therefore ``ns_gt`` is required to specify the exact number of nodes of each instance in the batch.
-        :return: displacement matrix d,
-            mask for dummy nodes grad_mask. If ``ns_gt=None``, it will not be calculated and None is returned.
-        """
-        if ns_gt is None:
-            max_n = s.shape[1]
-            P_src = P_src[:, 0:max_n, :]
-            grad_mask = None
-        else:
-            grad_mask = torch.zeros_like(P_src)
-            for b, n in enumerate(ns_gt):
-                grad_mask[b, 0:n] = 1
-
-        d = torch.matmul(s, P_tgt) - P_src
-        return d, grad_mask
\ No newline at end of file
diff --git a/COMMON/src/evaluation_metric.py b/COMMON/src/evaluation_metric.py
deleted file mode 100644
index 7f578b9..0000000
--- a/COMMON/src/evaluation_metric.py
+++ /dev/null
@@ -1,422 +0,0 @@
-import torch
-from torch import Tensor
-from itertools import combinations
-from src.utils.config import cfg
-
-
-def pck(x: Tensor, x_gt: Tensor, perm_mat: Tensor, dist_threshs: Tensor, ns: Tensor) -> Tensor:
-    r"""
-    Percentage of Correct Keypoints (PCK) evaluation metric.
-
-    If the distance between predicted keypoint and the ground truth keypoint is smaller than a given threshold, than it
-    is regraded as a correct matching.
-
-    This is the evaluation metric used by `"Zanfir et al. Deep Learning of Graph Matching. CVPR 2018."
-    <http://openaccess.thecvf.com/content_cvpr_2018/html/Zanfir_Deep_Learning_of_CVPR_2018_paper.html>`_
-
-    :param x: :math:`(b\times n \times 2)` candidate coordinates. :math:`n`: number of nodes in input graph
-    :param x_gt: :math:`(b\times n_{gt} \times 2)` ground truth coordinates. :math:`n_{gt}`: number of nodes in ground
-     truth graph
-    :param perm_mat: :math:`(b\times n \times n_{gt})` permutation matrix or doubly-stochastic matrix indicating
-     node-to-node correspondence
-    :param dist_threshs: :math:`(b\times m)` a tensor contains thresholds in pixel. :math:`m`: number of thresholds for
-     each batch
-    :param ns: :math:`(b)` number of exact pairs. We support batched instances with different number of nodes, and
-     ``ns`` is required to specify the exact number of nodes of each instance in the batch.
-    :return: :math:`(m)` the PCK values of this batch
-
-    .. note::
-        An example of ``dist_threshs`` for 4 batches and 2 thresholds:
-        ::
-
-            [[10, 20],
-             [10, 20],
-             [10, 20],
-             [10, 20]]
-    """
-    device = x.device
-    batch_num = x.shape[0]
-    thresh_num = dist_threshs.shape[1]
-
-    indices = torch.argmax(perm_mat, dim=-1)
-
-    dist = torch.zeros(batch_num, x_gt.shape[1], device=device)
-    for b in range(batch_num):
-        x_correspond = x[b, indices[b], :]
-        dist[b, 0:ns[b]] = torch.norm(x_correspond - x_gt[b], p=2, dim=-1)[0:ns[b]]
-
-    match_num = torch.zeros(thresh_num, device=device)
-    total_num = torch.zeros(thresh_num, device=device)
-    for b in range(batch_num):
-        for idx in range(thresh_num):
-            matches = (dist[b] < dist_threshs[b, idx])[0:ns[b]]
-            match_num[idx] += torch.sum(matches).to(match_num.dtype)
-            total_num[idx] += ns[b].to(total_num.dtype)
-
-    return match_num / total_num
-
-
-def matching_recall(pmat_pred: Tensor, pmat_gt: Tensor, ns: Tensor) -> Tensor:
-    r"""
-    Matching Recall between predicted permutation matrix and ground truth permutation matrix.
-
-    .. math::
-        \text{matching recall} = \frac{tr(\mathbf{X}\cdot {\mathbf{X}^{gt}}^\top)}{\sum \mathbf{X}^{gt}}
-
-    :param pmat_pred: :math:`(b\times n_1 \times n_2)` predicted permutation matrix :math:`(\mathbf{X})`
-    :param pmat_gt: :math:`(b\times n_1 \times n_2)` ground truth permutation matrix :math:`(\mathbf{X}^{gt})`
-    :param ns: :math:`(b)` number of exact pairs. We support batched instances with different number of nodes, and
-     ``ns`` is required to specify the exact number of nodes of each instance in the batch.
-    :return: :math:`(b)` matching recall
-
-    .. note::
-        This function is equivalent to "matching accuracy" if the matching problem has no outliers.
-    """
-    device = pmat_pred.device
-    batch_num = pmat_pred.shape[0]
-
-    pmat_gt = pmat_gt.to(device)
-
-    assert torch.all((pmat_pred == 0) + (pmat_pred == 1)), 'pmat_pred can only contain 0/1 elements.'
-    assert torch.all((pmat_gt == 0) + (pmat_gt == 1)), 'pmat_gt should only contain 0/1 elements.'
-    assert torch.all(torch.sum(pmat_pred, dim=-1) <= 1) and torch.all(torch.sum(pmat_pred, dim=-2) <= 1)
-    assert torch.all(torch.sum(pmat_gt, dim=-1) <= 1) and torch.all(torch.sum(pmat_gt, dim=-2) <= 1)
-
-    acc = torch.zeros(batch_num, device=device)
-    for b in range(batch_num):
-        acc[b] = torch.sum(pmat_pred[b, :ns[b]] * pmat_gt[b, :ns[b]]) / torch.sum(pmat_gt[b, :ns[b]])
-
-    acc[torch.isnan(acc)] = 1
-
-    return acc
-
-
-def matching_precision(pmat_pred: Tensor, pmat_gt: Tensor, ns: Tensor) -> Tensor:
-    r"""
-    Matching Precision between predicted permutation matrix and ground truth permutation matrix.
-
-    .. math::
-        \text{matching precision} = \frac{tr(\mathbf{X}\cdot {\mathbf{X}^{gt}}^\top)}{\sum \mathbf{X}}
-
-    :param pmat_pred: :math:`(b\times n_1 \times n_2)` predicted permutation matrix :math:`(\mathbf{X})`
-    :param pmat_gt: :math:`(b\times n_1 \times n_2)` ground truth permutation matrix :math:`(\mathbf{X}^{gt})`
-    :param ns: :math:`(b)` number of exact pairs. We support batched instances with different number of nodes, and
-     ``ns`` is required to specify the exact number of nodes of each instance in the batch.
-    :return: :math:`(b)` matching precision
-
-    .. note::
-        This function is equivalent to "matching accuracy" if the matching problem has no outliers.
-    """
-    device = pmat_pred.device
-    batch_num = pmat_pred.shape[0]
-
-    pmat_gt = pmat_gt.to(device)
-
-    assert torch.all((pmat_pred == 0) + (pmat_pred == 1)), 'pmat_pred can only contain 0/1 elements.'
-    assert torch.all((pmat_gt == 0) + (pmat_gt == 1)), 'pmat_gt should only contain 0/1 elements.'
-    assert torch.all(torch.sum(pmat_pred, dim=-1) <= 1) and torch.all(torch.sum(pmat_pred, dim=-2) <= 1)
-    assert torch.all(torch.sum(pmat_gt, dim=-1) <= 1) and torch.all(torch.sum(pmat_gt, dim=-2) <= 1)
-
-    precision = torch.zeros(batch_num, device=device)
-    for b in range(batch_num):
-        precision[b] = torch.sum(pmat_pred[b, :ns[b]] * pmat_gt[b, :ns[b]]) / torch.sum(pmat_pred[b, :ns[b]])
-
-    precision[torch.isnan(precision)] = 1
-
-    return precision
-
-
-def matching_recall_varied(pmat_pred: Tensor, pmat_gt: Tensor, ns: Tensor) -> Tensor:
-    r"""
-    Matching Recall between predicted permutation matrix and ground truth permutation matrix.
-
-    .. math::
-        \text{matching recall} = \frac{tr(\mathbf{X}\cdot {\mathbf{X}^{gt}}^\top)}{\sum \mathbf{X}^{gt}}
-
-    :param pmat_pred: :math:`(b\times n_1 \times n_2)` predicted permutation matrix :math:`(\mathbf{X})`
-    :param pmat_gt: :math:`(b\times n_1 \times n_2)` ground truth permutation matrix :math:`(\mathbf{X}^{gt})`
-    :param ns: :math:`(b\times 2)` number of nodes in all pairs. We support batched instances with different number of nodes, and
-     ``ns`` is required to specify the exact number of nodes of each instance in the batch.
-    :return: :math:`(b)` matching recall
-
-    """
-    device = pmat_pred.device
-    batch_num = pmat_pred.shape[0]
-
-    pmat_gt = pmat_gt.to(device)
-
-    assert torch.all((pmat_pred == 0) + (pmat_pred == 1)), 'pmat_pred can only contain 0/1 elements.'
-    assert torch.all((pmat_gt == 0) + (pmat_gt == 1)), 'pmat_gt should only contain 0/1 elements.'
-
-    acc = torch.zeros(batch_num, device=device)
-    for b in range(batch_num):
-        mask = torch.zeros((pmat_pred[b].shape[0],pmat_gt[b].shape[1]),device=pmat_pred.device)
-        mask[:ns[0][b]+1,:ns[1][b]+1]=1
-        mask[ns[0][b], ns[1][b]]=0
-        acc[b] = torch.sum(pmat_pred[b] * pmat_gt[b] * mask) / torch.sum(pmat_gt[b] * mask)
-        # acc[b] = torch.sum(pmat_pred[b, :ns[0][b], :ns[1][b]] * pmat_gt[b, :ns[0][b], :ns[1][b]]) / torch.sum(
-        #     pmat_gt[b, :ns[0][b], :ns[1][b]])
-
-    acc[torch.isnan(acc)] = 0
-
-    return acc
-
-
-def matching_precision_varied(pmat_pred: Tensor, pmat_gt: Tensor, ns: Tensor) -> Tensor:
-    r"""
-    Matching Precision between predicted permutation matrix and ground truth permutation matrix.
-
-    .. math::
-        \text{matching precision} = \frac{tr(\mathbf{X}\cdot {\mathbf{X}^{gt}}^\top)}{\sum \mathbf{X}}
-
-    :param pmat_pred: :math:`(b\times n_1 \times n_2)` predicted permutation matrix :math:`(\mathbf{X})`
-    :param pmat_gt: :math:`(b\times n_1 \times n_2)` ground truth permutation matrix :math:`(\mathbf{X}^{gt})`
-    :param ns: :math:`(b\times 2)` number of nodes in all pairs. We support batched instances with different number of nodes, and
-     ``ns`` is required to specify the exact number of nodes of each instance in the batch.
-    :return: :math:`(b)` matching precision
-
-    """
-    device = pmat_pred.device
-    batch_num = pmat_pred.shape[0]
-
-    pmat_gt = pmat_gt.to(device)
-
-    assert torch.all((pmat_pred == 0) + (pmat_pred == 1)), 'pmat_pred can only contain 0/1 elements.'
-    assert torch.all((pmat_gt == 0) + (pmat_gt == 1)), 'pmat_gt should only contain 0/1 elements.'
-
-    precision = torch.zeros(batch_num, device=device)
-    for b in range(batch_num):
-        mask = torch.zeros((pmat_pred[b].shape[0],pmat_gt[b].shape[1]),device=pmat_pred.device)
-        mask[:ns[0][b]+1,:ns[1][b]+1]=1
-        mask[ns[0][b], ns[1][b]]=0
-        precision[b] = torch.sum(pmat_pred[b] * pmat_gt[b] * mask) / torch.sum(pmat_pred[b] * mask)
-        # precision[b] = torch.sum(pmat_pred[b, :ns[0][b]+1, :ns[1][b]+1] *
-        #                          pmat_gt[b, :ns[0][b]+1, :ns[1][b]+1]) / torch.sum(pmat_pred[b, :ns[0][b]+1, :ns[1][b]+1])
-
-    precision[torch.isnan(precision)] = 0
-
-    return precision
-
-
-def matching_accuracy(pmat_pred: Tensor, pmat_gt: Tensor, ns: Tensor, idx: int) -> Tensor:
-    r"""
-    Matching Accuracy between predicted permutation matrix and ground truth permutation matrix.
-
-    .. math::
-        \text{matching recall} = \frac{tr(\mathbf{X}\cdot {\mathbf{X}^{gt}}^\top)}{\sum \mathbf{X}^{gt}}
-
-    This function is a wrapper of ``matching_recall``.
-
-    :param pmat_pred: :math:`(b\times n_1 \times n_2)` predicted permutation matrix :math:`(\mathbf{X})`
-    :param pmat_gt: :math:`(b\times n_1 \times n_2)` ground truth permutation matrix :math:`(\mathbf{X}^{gt})`
-    :param ns: :math:`(b\times g)` number of nodes in graphs, where :math:`g=2` for 2GM, and :math:`g>2` for MGM. We support batched instances with different number of nodes, and
-     ``ns`` is required to specify the exact number of nodes of each instance in the batch.
-    :param idx: :math:`(int)` index of source graph in the graph pair.
-
-    :return: :math:`(b)` matching accuracy
-
-    .. note::
-        If the graph matching problem has no outliers, it is proper to use this metric and papers call it "matching
-        accuracy". If there are outliers, it is better to use ``matching_precision`` and ``matching_recall``.
-    """
-    if 'gcan' in cfg.MODEL_NAME and 'afat' not in cfg.MODEL_NAME:
-        return matching_recall_varied(pmat_pred, pmat_gt, ns)
-    else:
-        return matching_recall(pmat_pred, pmat_gt, ns[idx])
-
-
-def format_accuracy_metric(ps: Tensor, rs: Tensor, f1s: Tensor) -> str:
-    r"""
-    Helper function for formatting precision, recall and f1 score metric
-
-    :param ps: tensor containing precisions
-    :param rs: tensor containing recalls
-    :param f1s: tensor containing f1 scores
-    :return: a formatted string with mean and variance of precision, recall and f1 score
-
-    Example output:
-    ::
-
-        p = 0.7837±0.2799, r = 0.7837±0.2799, f1 = 0.7837±0.2799
-    """
-    return 'p = {:.4f}±{:.4f}, r = {:.4f}±{:.4f}, f1 = {:.4f}±{:.4f}' \
-        .format(torch.mean(ps), torch.std(ps), torch.mean(rs), torch.std(rs), torch.mean(f1s), torch.std(f1s))
-
-def format_metric(ms: Tensor) -> str:
-    r"""
-    Helping function for formatting single metric.
-
-    :param ms: tensor containing metric
-    :return: a formatted string containing mean and variance
-    """
-    return '{:.4f}±{:.4f}'.format(torch.mean(ms), torch.std(ms))
-
-
-def objective_score(pmat_pred: Tensor, affmtx: Tensor) -> Tensor:
-    r"""
-    Objective score given predicted permutation matrix and affinity matrix from the problem.
-
-    .. math::
-        \text{objective score} = \mathrm{vec}(\mathbf{X})^\top \mathbf{K} \mathrm{vec}(\mathbf{X})
-
-    where :math:`\mathrm{vec}(\cdot)` means column-wise vectorization.
-
-    :param pmat_pred: predicted permutation matrix :math:`(\mathbf{X})`
-    :param affmtx: affinity matrix of the quadratic assignment problem :math:`(\mathbf{K})`
-    :return: objective scores
-
-    .. note::
-        The most general mathematical form of graph matching is known as Quadratic Assignment Problem (QAP), which is an
-        NP-hard combinatorial optimization problem. Objective score reflects the power of the graph matching/QAP solver
-        concerning the objective score of the QAP.
-    """
-    batch_num = pmat_pred.shape[0]
-
-    p_vec = pmat_pred.transpose(1, 2).contiguous().view(batch_num, -1, 1)
-    obj_score = torch.matmul(torch.matmul(p_vec.transpose(1, 2), affmtx), p_vec).view(-1)
-
-    return obj_score
-
-def clustering_accuracy(pred_clusters: Tensor, gt_classes: Tensor) -> Tensor:
-    r"""
-    Clustering accuracy for clusters.
-
-    :math:`\mathcal{A}, \mathcal{B}, ...` are ground truth classes and :math:`\mathcal{A}^\prime, \mathcal{B}^\prime,
-    ...` are predicted classes and :math:`k` is the number of classes:
-
-    .. math::
-        \text{clustering accuracy} = 1 - \frac{1}{k} \left(\sum_{\mathcal{A}} \sum_{\mathcal{A}^\prime \neq \mathcal{B}^\prime}
-         \frac{|\mathcal{A}^\prime \cap \mathcal{A}| |\mathcal{B}^\prime \cap \mathcal{A}|}{|\mathcal{A}| |\mathcal{A}|} +
-         \sum_{\mathcal{A}^\prime} \sum_{\mathcal{A} \neq \mathcal{B}}
-         \frac{|\mathcal{A}^\prime \cap \mathcal{A}| |\mathcal{A}^\prime \cap \mathcal{B}|}{|\mathcal{A}| |\mathcal{B}|} \right)
-
-    This metric is proposed by `"Wang et al. Clustering-aware Multiple Graph Matching via Decayed Pairwise Matching
-    Composition. AAAI 2020." <https://ojs.aaai.org/index.php/AAAI/article/view/5528/5384>`_
-
-    :param pred_clusters: :math:`(b\times n)` predicted clusters. :math:`n`: number of instances.
-        ::
-
-            e.g. [[0,0,1,2,1,2]
-                  [0,1,2,2,1,0]]
-    :param gt_classes: :math:`(b\times n)` ground truth classes
-        ::
-
-            e.g. [['car','car','bike','bike','person','person'],
-                  ['bus','bus','cat', 'sofa',  'cat',  'sofa' ]]
-    :return: :math:`(b)` clustering accuracy
-    """
-    num_clusters = torch.max(pred_clusters, dim=-1).values + 1
-    batch_num = pred_clusters.shape[0]
-
-    gt_classes_t = []
-
-    for b in range(batch_num):
-        gt_classes_b_set = list(set(gt_classes[b]))
-        gt_classes_t.append([])
-        assert len(gt_classes_b_set) == num_clusters[b]
-        for i in range(len(gt_classes[b])):
-            gt_classes_t[b].append(gt_classes_b_set.index(gt_classes[b][i]))
-    gt_clusters = torch.tensor(gt_classes_t).to(dtype=pred_clusters.dtype, device=pred_clusters.device)
-
-    cluster_acc = torch.zeros(batch_num, device=pred_clusters.device)
-    for b in range(batch_num):
-        sum = 0
-        for i in range(num_clusters[b]):
-            for j, k in combinations(range(num_clusters[b]), 2):
-                pred_i = (pred_clusters[b] == i).to(dtype=torch.float)
-                gt_j = (gt_clusters[b] == j).to(dtype=torch.float)
-                gt_k = (gt_clusters[b] == k).to(dtype=torch.float)
-                sum += (torch.sum(pred_i * gt_j) * torch.sum(pred_i * gt_k)) / torch.sum(pred_i) ** 2
-        for i in range(num_clusters[b]):
-            for j, k in combinations(range(num_clusters[b]), 2):
-                gt_i = (gt_clusters[b] == i).to(dtype=torch.float)
-                pred_j = (pred_clusters[b] == j).to(dtype=torch.float)
-                pred_k = (pred_clusters[b] == k).to(dtype=torch.float)
-                sum += (torch.sum(gt_i * pred_j) * torch.sum(gt_i * pred_k)) / (torch.sum(pred_j) * torch.sum(pred_k))
-
-        cluster_acc[b] = 1 - sum / num_clusters[b].to(dtype=torch.float)
-
-    return cluster_acc
-
-def clustering_purity(pred_clusters: Tensor, gt_classes: Tensor) -> Tensor:
-    r"""
-    Clustering purity for clusters.
-
-    :math:`n` is the number of instances,
-    :math:`\mathcal{C}_i` represent the predicted class :math:`i` and :math:`\mathcal{C}^{gt}_j` is ground truth class :math:`j`:
-
-    .. math::
-        \text{clustering purity} = \frac{1}{n} \sum_{i=1}^{k} \max_{j\in\{1,...,k\}} |\mathcal{C}_i \cap \mathcal{C}^{gt}_{j}|
-
-    :param pred_clusters: :math:`(b\times n)` predicted clusters. :math:`n`: number of instances.
-        ::
-
-            e.g. [[0,0,1,2,1,2]
-                  [0,1,2,2,1,0]]
-    :param gt_classes: :math:`(b\times n)` ground truth classes
-        ::
-
-            e.g. [['car','car','bike','bike','person','person'],
-                  ['bus','bus','cat', 'sofa',  'cat',  'sofa' ]]
-    :return: :math:`(b)` clustering purity
-    """
-    num_clusters = torch.max(pred_clusters, dim=-1).values + 1
-    num_instances = pred_clusters.shape[1]
-    batch_num = pred_clusters.shape[0]
-    gt_classes_t = []
-    for b in range(batch_num):
-        gt_classes_b_set = list(set(gt_classes[b]))
-        gt_classes_t.append([])
-        assert len(gt_classes_b_set) == num_clusters[b]
-        for i in range(len(gt_classes[b])):
-            gt_classes_t[b].append(gt_classes_b_set.index(gt_classes[b][i]))
-    gt_clusters = torch.tensor(gt_classes_t).to(dtype=pred_clusters.dtype, device=pred_clusters.device)
-
-    cluster_purity = torch.zeros(batch_num, device=pred_clusters.device)
-    for b in range(batch_num):
-        for i in range(num_clusters[b]):
-            max_counts = torch.max(torch.unique(gt_clusters[b][pred_clusters[b] == i], return_counts=True)[-1]).to(dtype=torch.float)
-            cluster_purity[b] += max_counts / num_instances
-
-    return cluster_purity
-
-
-def rand_index(pred_clusters: Tensor, gt_classes: Tensor) -> Tensor:
-    r"""
-    Rand index measurement for clusters.
-
-    Rand index is computed by the number of instances predicted in the same class with the same label :math:`n_{11}` and
-    the number of instances predicted in separate classes and with different labels :math:`n_{00}`, normalized by the total
-    number of instances pairs :math:`n(n-1)`:
-
-    .. math::
-        \text{rand index} = \frac{n_{11} + n_{00}}{n(n-1)}
-
-    :param pred_clusters: :math:`(b\times n)` predicted clusters. :math:`n`: number of instances.
-        ::
-
-            e.g. [[0,0,1,2,1,2]
-                  [0,1,2,2,1,0]]
-    :param gt_classes: :math:`(b\times n)` ground truth classes
-        ::
-
-            e.g. [['car','car','bike','bike','person','person'],
-                  ['bus','bus','cat', 'sofa',  'cat',  'sofa' ]]
-    :return: :math:`(b)` clustering purity
-    """
-    num_clusters = torch.max(pred_clusters, dim=-1).values + 1
-    num_instances = pred_clusters.shape[1]
-    batch_num = pred_clusters.shape[0]
-    gt_classes_t = []
-    for b in range(batch_num):
-        gt_classes_b_set = list(set(gt_classes[b]))
-        gt_classes_t.append([])
-        assert len(gt_classes_b_set) == num_clusters[b]
-        for i in range(len(gt_classes[b])):
-            gt_classes_t[b].append(gt_classes_b_set.index(gt_classes[b][i]))
-    gt_clusters = torch.tensor(gt_classes_t).to(dtype=pred_clusters.dtype, device=pred_clusters.device)
-    pred_pairs = pred_clusters.unsqueeze(-1) == pred_clusters.unsqueeze(-2)
-    gt_pairs = gt_clusters.unsqueeze(-1) == gt_clusters.unsqueeze(-2)
-    unmatched_pairs = torch.logical_xor(pred_pairs, gt_pairs).to(dtype=torch.float)
-    rand_index = 1 - torch.sum(unmatched_pairs, dim=(-1,-2)) / (num_instances * (num_instances - 1))
-    return rand_index
diff --git a/COMMON/src/extension/bilinear_diag/bilinear_diag.cpp b/COMMON/src/extension/bilinear_diag/bilinear_diag.cpp
deleted file mode 100644
index d951452..0000000
--- a/COMMON/src/extension/bilinear_diag/bilinear_diag.cpp
+++ /dev/null
@@ -1,326 +0,0 @@
-#include <torch/torch.h>
-#include <utility>
-
-#include <iostream>
-
-/* CUDA Declaration */
-
-at::Tensor bilinear_diag_csc_cuda(
-    at::Tensor t1_indices,
-    at::Tensor t1_indptr,
-    at::Tensor t1_data,
-    at::Tensor t2,
-    at::Tensor t3_indices,
-    at::Tensor t3_indptr,
-    at::Tensor t3_data,
-    int64_t batch_size,
-    int64_t xlen);
-
-
-#define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x " must be a CUDA tensor")
-#define CHECK_CPU(x) AT_ASSERTM(!x.type().is_cuda(), #x " must be a CPU tensor")
-#define CHECK_CONTIGUOUS(x) AT_ASSERTM(x.is_contiguous(), #x " must be contiguous")
-#define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)
-
-
-/* Dense Implementation */
-
-at::Tensor bilinear_diag_dense(
-    at::Tensor t1,
-    at::Tensor t2,
-    at::Tensor t3
-){
-    auto sizes = t1.sizes();
-    auto batch_size = sizes[0];
-    auto xlen = sizes[1];
-    auto outp = at::empty({batch_size, xlen}, t2.type());
-    for(int64_t i = 0; i < xlen; i++)
-    {
-        auto _t1 = at::slice(t1, 1, i, i+1);
-        auto tmp = at::bmm(_t1, t2);
-        auto _t3 = at::slice(t3, 2, i, i+1);
-        auto _outp = at::bmm(tmp, _t3).view(-1);
-        for(int64_t j = 0; j < batch_size; j++)
-            outp[j][i] = _outp[j];
-    }
-    return outp;
-}
-
-
-/* COO Sparse Implementation */
-
-bool sort_smaller_than(int64_t main1, int64_t main2, int64_t minor1, int64_t minor2)
-{
-    if (main1 < main2)
-        return true;
-    else if (main1 > main2)
-        return false;
-    else if (minor1 < minor2)
-        return true;
-    else
-        return false;
-}
-
-
-void sort_sparse_helper(at::Tensor main,
-                        at::Tensor minor,
-                        std::vector<at::Tensor> others,
-                        int64_t begin,
-                        int64_t end)
-{
-    if (begin >= end)
-        return;
-
-    auto head = begin;
-    auto tail = end;
-    auto reverse = true;
-    auto main_access = main.accessor<int64_t, 1>();
-    auto minor_access = minor.accessor<int64_t, 1>();
-    while (head != tail)
-    {
-        if (sort_smaller_than(main_access[tail], main_access[head], minor_access[tail], minor_access[head]))
-        {
-            //swap
-            std::swap(main_access[head], main_access[tail]);
-            std::swap(minor_access[head], minor_access[tail]);
-            for (auto iter = others.cbegin(); iter != others.cend(); iter++)
-            {
-                if (iter->dtype() == at::ScalarType::Float)
-                {
-                    auto others_access = iter->accessor<float ,1>();
-                    std::swap(others_access[head], others_access[tail]);
-                }
-                else if (iter->dtype() == at::ScalarType::Double)
-                {
-                    auto others_access = iter->accessor<double, 1>();
-                    std::swap(others_access[head], others_access[tail]);
-                }
-                else
-                {
-                    auto others_access = iter->accessor<int64_t, 1>();
-                    std::swap(others_access[head], others_access[tail]);
-                }
-            }
-            reverse = !reverse;
-        }
-        else
-        {
-            if (reverse)
-                tail--;
-            else
-                head++;
-        }
-    }
-
-    auto split = head;
-    sort_sparse_helper(main, minor, others, begin, split - 1);
-    sort_sparse_helper(main, minor, others, split + 1, end);
-}
-
-
-at::Tensor sort_sparse(at::Tensor ts, int64_t main_dim, int64_t minor_dim)
-{
-    assert(ts.is_sparse());
-    auto max_dim = ts.dim();
-
-    if (main_dim < 0)
-        main_dim += max_dim;
-    if (minor_dim < 0)
-        minor_dim += max_dim;
-    assert(0 <= main_dim && main_dim < max_dim);
-    assert(0 <= minor_dim && minor_dim < max_dim);
-    assert(main_dim != minor_dim);
-
-    auto ind = ts._indices();
-    auto data = ts._values();
-
-    auto ind_sizes = ind.sizes();
-    auto dim_len = ind_sizes[1];
-
-    std::vector<at::Tensor> others;
-    for (int64_t i = 0; i < max_dim; i++)
-        if ((i != main_dim) && (i != minor_dim))
-            others.push_back(ind[i]);
-
-    others.push_back(data);
-
-    sort_sparse_helper(ind[main_dim], ind[minor_dim], others, 0, dim_len - 1);
-
-    return ts;
-}
-
-
-void split_sorted_coo(at::Tensor t, int64_t xlen_indices[], int64_t xlen_dim)
-{
-    auto indices = t._indices();
-    auto t_nnz = t._nnz();
-    auto indices_access = indices.accessor<int64_t, 2>();
-
-    int64_t cur_batch = 0;
-    int64_t cur_xlen = 0;
-    int64_t xlen_offset = 0;
-    for (int64_t i = 0; i < t_nnz;)
-    {
-        if (indices_access[xlen_dim][i] != cur_xlen)
-        {
-            xlen_indices[xlen_offset + ++cur_xlen] = i;
-        }
-        if (indices_access[0][i] != cur_batch)
-        {
-            xlen_offset = cur_xlen;
-            cur_xlen = 0;
-        }
-        if ((indices_access[xlen_dim][i] == cur_xlen) && (indices_access[0][i] == cur_batch))
-            i++;
-    }
-    xlen_indices[xlen_offset + ++cur_xlen] = t_nnz;
-}
-
-
-at::Tensor bilinear_diag_coo(
-    at::Tensor t1,
-    at::Tensor t2,
-    at::Tensor t3
-){
-    auto t1_sizes = t1.sizes();
-    auto batch_size = t1_sizes[0];
-    auto xlen = t1_sizes[1];
-    auto feat_size = t1_sizes[2];
-    auto outp = at::zeros({batch_size, xlen}, t2.type());
-
-    auto t1_indices = t1._indices();
-    auto t1_values = t1._values();
-    auto t3_indices = t3._indices();
-    auto t3_values = t3._values();
-
-    int64_t t1_xlen_indices[xlen * batch_size + 1] = {0};
-    int64_t t3_xlen_indices[xlen * batch_size + 1] = {0};
-
-    auto t1_idx_access = t1_indices.accessor<int64_t, 2>();
-    auto t3_idx_access = t3_indices.accessor<int64_t, 2>();
-
-    split_sorted_coo(t1, t1_xlen_indices, 1);
-    split_sorted_coo(t3, t3_xlen_indices, 2);
-
-    for (int64_t b = 0; b < batch_size; b++)
-    {
-        for (int64_t i = 0; i < xlen; i++)
-        {
-            auto t1_start = t1_xlen_indices[b * xlen + i];
-            auto t1_stop = t1_xlen_indices[b * xlen + i + 1];
-            auto t3_start = t3_xlen_indices[b * xlen + i];
-            auto t3_stop = t3_xlen_indices[b * xlen + i + 1];
-
-            for (auto t1_idx = t1_start; t1_idx < t1_stop; t1_idx++)
-            {
-                for (auto t3_idx = t3_start; t3_idx < t3_stop; t3_idx++)
-                {
-                    outp[b][i] += t2[b][t1_idx_access[2][t1_idx]][t3_idx_access[1][t3_idx]]
-                                  * t1_values[t1_idx] * t3_values[t3_idx];
-                }
-            }
-
-        }
-    }
-    return outp;
-}
-
-
-/* CSC Sparse Implementation */
-
-at::Tensor bilinear_diag_csc_cpu(
-    at::Tensor t1_indices,
-    at::Tensor t1_indptr,
-    at::Tensor t1_data,
-    at::Tensor t2,
-    at::Tensor t3_indices,
-    at::Tensor t3_indptr,
-    at::Tensor t3_data,
-    int64_t batch_size,
-    int64_t xlen
-){
-    CHECK_CPU(t1_indices);
-    CHECK_CPU(t1_indptr);
-    CHECK_CPU(t1_data);
-    CHECK_CPU(t2);
-    CHECK_CPU(t3_indices);
-    CHECK_CPU(t3_indptr);
-    CHECK_CPU(t3_data);
-
-    auto outp = at::zeros({batch_size, xlen}, t2.type());
-    auto t1_indptr_acc = t1_indptr.accessor<int64_t, 1>();
-    auto t3_indptr_acc = t3_indptr.accessor<int64_t, 1>();
-
-    for (int64_t b = 0; b < batch_size; b++)
-    {
-        for (int64_t i = 0; i < xlen; i++)
-        {
-            int64_t t1_start = t1_indptr_acc[b * xlen + i];
-            int64_t t1_stop = t1_indptr_acc[b * xlen + i + 1];
-            int64_t t3_start = t3_indptr_acc[b * xlen + i];
-            int64_t t3_stop = t3_indptr_acc[b * xlen + i + 1];
-
-            for (auto t1_idx = t1_start; t1_idx < t1_stop; t1_idx++)
-            {
-                for (auto t3_idx = t3_start; t3_idx < t3_stop; t3_idx++)
-                {
-                    outp[b][i] += t2[b][t1_indices[t1_idx]][t3_indices[t3_idx]]
-                                  * t1_data[t1_idx] * t3_data[t3_idx];
-                }
-            }
-
-        }
-    }
-    return outp;
-}
-
-
-at::Tensor bilinear_diag_csc_cuda_wrapper(
-    at::Tensor t1_indices,
-    at::Tensor t1_indptr,
-    at::Tensor t1_data,
-    at::Tensor t2,
-    at::Tensor t3_indices,
-    at::Tensor t3_indptr,
-    at::Tensor t3_data,
-    int64_t batch_size,
-    int64_t xlen
-){
-    CHECK_INPUT(t1_indices);
-    CHECK_INPUT(t1_indptr);
-    CHECK_INPUT(t1_data);
-    CHECK_INPUT(t2);
-    CHECK_INPUT(t3_indices);
-    CHECK_INPUT(t3_indptr);
-    CHECK_INPUT(t3_data);
-    return bilinear_diag_csc_cuda(t1_indices, t1_indptr, t1_data,
-                                  t2,
-                                  t3_indices, t3_indptr, t3_data,
-                                  batch_size, xlen);
-}
-
-
-at::Tensor bilinear_diag_csc(
-    at::Tensor t1_indices,
-    at::Tensor t1_indptr,
-    at::Tensor t1_data,
-    at::Tensor t2,
-    at::Tensor t3_indices,
-    at::Tensor t3_indptr,
-    at::Tensor t3_data,
-    int64_t batch_size,
-    int64_t xlen
-)
-{
-    if (t1_indices.type().is_cuda())
-        return bilinear_diag_csc_cuda_wrapper(t1_indices, t1_indptr, t1_data, t2, t3_indices, t3_indptr, t3_data, batch_size, xlen);
-
-    else
-        return bilinear_diag_csc_cpu(t1_indices, t1_indptr, t1_data, t2, t3_indices, t3_indptr, t3_data, batch_size, xlen);
-}
-
-/* PyBind Interface */
-
-PYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {
-  m.def("bilinear_diag", &bilinear_diag_csc, "bilinear diagonal");
-}
diff --git a/COMMON/src/extension/bilinear_diag/bilinear_diag_cuda.cu b/COMMON/src/extension/bilinear_diag/bilinear_diag_cuda.cu
deleted file mode 100644
index 4d82128..0000000
--- a/COMMON/src/extension/bilinear_diag/bilinear_diag_cuda.cu
+++ /dev/null
@@ -1,79 +0,0 @@
-#include <ATen/ATen.h>
-
-#include <cuda.h>
-#include <cuda_runtime.h>
-
-
-template <typename scalar_t>
-__global__ void bilinear_diag_csc_cuda_kernel(
-    const int64_t* __restrict__ t1_indices,
-    const int64_t* __restrict__ t1_indptr,
-    const scalar_t* __restrict__ t1_data,
-    const scalar_t* __restrict__ t2,
-    const int64_t* __restrict__ t3_indices,
-    const int64_t* __restrict__ t3_indptr,
-    const scalar_t* __restrict__ t3_data,
-    scalar_t* __restrict__ outp,
-    const int64_t xlen,
-    const int64_t feat_size
-)
-{
-    const int64_t i = blockIdx.x * blockDim.x + threadIdx.x;
-    const int64_t b = blockIdx.y;
-
-    if (i < xlen)
-    {
-        const int64_t ptr_idx = b * xlen + i;
-        const int64_t t1_start = t1_indptr[ptr_idx];
-        const int64_t t1_stop = t1_indptr[ptr_idx + 1];
-        const int64_t t3_start = t3_indptr[ptr_idx];
-        const int64_t t3_stop = t3_indptr[ptr_idx + 1];
-
-        scalar_t _outp = 0;
-
-        for (int64_t t1_idx = t1_start; t1_idx < t1_stop; t1_idx++)
-        {
-            for (int64_t t3_idx = t3_start; t3_idx < t3_stop; t3_idx++)
-            {
-                _outp += t2[b * feat_size * feat_size + t1_indices[t1_idx] * feat_size + t3_indices[t3_idx]]
-                         * t1_data[t1_idx] * t3_data[t3_idx];
-            }
-        }
-        outp[b * xlen + i] = _outp;
-    }
-}
-
-
-at::Tensor bilinear_diag_csc_cuda(
-    at::Tensor t1_indices,
-    at::Tensor t1_indptr,
-    at::Tensor t1_data,
-    at::Tensor t2,
-    at::Tensor t3_indices,
-    at::Tensor t3_indptr,
-    at::Tensor t3_data,
-    int64_t batch_size,
-    int64_t xlen
-){
-    auto outp = at::zeros({batch_size, xlen}, t2.type());
-    auto feat_size = t2.size(1);
-
-    const int threads = 1024;
-    const dim3 blocks((xlen + threads - 1) / threads, batch_size);
-
-    AT_DISPATCH_FLOATING_TYPES_AND_HALF(t2.type(), "bilinear_diag_csc_cuda", ([&] {
-    bilinear_diag_csc_cuda_kernel<scalar_t><<<blocks, threads>>>(
-        t1_indices.data<int64_t>(),
-        t1_indptr.data<int64_t>(),
-        t1_data.data<scalar_t>(),
-        t2.data<scalar_t>(),
-        t3_indices.data<int64_t>(),
-        t3_indptr.data<int64_t>(),
-        t3_data.data<scalar_t>(),
-        outp.data<scalar_t>(),
-        xlen,
-        feat_size);
-    }));
-
-    return outp;
-}
diff --git a/COMMON/src/extension/sparse_dot/csr_dot_csc_cuda.cu b/COMMON/src/extension/sparse_dot/csr_dot_csc_cuda.cu
deleted file mode 100644
index 6061c71..0000000
--- a/COMMON/src/extension/sparse_dot/csr_dot_csc_cuda.cu
+++ /dev/null
@@ -1,87 +0,0 @@
-#include <ATen/ATen.h>
-
-#include <cuda.h>
-#include <cuda_runtime.h>
-
-
-template <typename scalar_t>
-__global__ void csr_dot_csc_cuda_kernel(
-    const int64_t* __restrict__ t1_indices,
-    const int64_t* __restrict__ t1_indptr,
-    const scalar_t* __restrict__ t1_data,
-    const int64_t* __restrict__ t2_indices,
-    const int64_t* __restrict__ t2_indptr,
-    const scalar_t* __restrict__ t2_data,
-    scalar_t* __restrict__ out_dense,
-    const int64_t out_h,
-    const int64_t out_w
-)
-{
-    const int64_t ij = blockIdx.x * blockDim.x + threadIdx.x;
-    const int64_t b = blockIdx.y;
-
-    if (ij < out_h * out_w)
-    {
-        const int64_t i = ij / out_w;
-        const int64_t j = ij % out_w;
-
-        const int64_t t1_start = t1_indptr[b * out_h + i];
-        const int64_t t1_stop = t1_indptr[b * out_h + i + 1];
-
-        const int64_t t2_start = t2_indptr[b * out_w + j];
-        const int64_t t2_stop = t2_indptr[b * out_w + j + 1];
-
-        scalar_t outp = 0;
-        int64_t t1_ptr_idx = t1_start;
-        int64_t t2_ptr_idx = t2_start;
-
-        while (t1_ptr_idx < t1_stop && t2_ptr_idx < t2_stop)
-        {
-            int64_t t1_cur_indice = t1_indices[t1_ptr_idx];
-            int64_t t2_cur_indice = t2_indices[t2_ptr_idx];
-            if (t1_cur_indice == t2_cur_indice)
-            {
-                outp += t1_data[t1_ptr_idx] * t2_data[t2_ptr_idx];
-                t1_ptr_idx++;
-                t2_ptr_idx++;
-            }
-            else if (t1_cur_indice < t2_cur_indice)
-                t1_ptr_idx++;
-            else
-                t2_ptr_idx++;
-        }
-        out_dense[b * out_w * out_h + i * out_w + j] = outp;
-    }
-}
-
-
-at::Tensor csr_dot_csc_cuda(
-    at::Tensor t1_indices,
-    at::Tensor t1_indptr,
-    at::Tensor t1_data,
-    at::Tensor t2_indices,
-    at::Tensor t2_indptr,
-    at::Tensor t2_data,
-    int64_t batch_size,
-    int64_t out_h,
-    int64_t out_w
-){
-    auto out_dense = at::zeros({batch_size, out_h, out_w}, t1_data.type());
-
-    const int threads = 1024;
-    const dim3 blocks((out_h * out_w + threads - 1) / threads, batch_size);
-
-    AT_DISPATCH_FLOATING_TYPES_AND_HALF(t1_data.type(), "csr_dot_csc_cuda", ([&] {
-    csr_dot_csc_cuda_kernel<scalar_t><<<blocks, threads>>>(
-        t1_indices.data<int64_t>(),
-        t1_indptr.data<int64_t>(),
-        t1_data.data<scalar_t>(),
-        t2_indices.data<int64_t>(),
-        t2_indptr.data<int64_t>(),
-        t2_data.data<scalar_t>(),
-        out_dense.data<scalar_t>(),
-        out_h,
-        out_w);
-    }));
-    return out_dense;
-}
diff --git a/COMMON/src/extension/sparse_dot/csr_dot_diag_cuda.cu b/COMMON/src/extension/sparse_dot/csr_dot_diag_cuda.cu
deleted file mode 100644
index 89a792b..0000000
--- a/COMMON/src/extension/sparse_dot/csr_dot_diag_cuda.cu
+++ /dev/null
@@ -1,65 +0,0 @@
-#include <ATen/ATen.h>
-
-#include <cuda.h>
-#include <cuda_runtime.h>
-
-#include <iostream>
-
-
-template <typename scalar_t>
-__global__ void csr_dot_diag_cuda_kernel(
-    const int64_t* __restrict__ t1_indices,
-    const int64_t* __restrict__ t1_indptr,
-    const scalar_t* __restrict__ t1_data,
-    const scalar_t* __restrict__ t2,
-    scalar_t* __restrict__ outp_data,
-    const int64_t out_h,
-    const int64_t out_w
-)
-{
-    const int64_t i = blockIdx.x * blockDim.x + threadIdx.x;
-    const int64_t b = blockIdx.y;
-
-    if (i < out_h)
-    {
-        const int64_t start = t1_indptr[b * out_h + i];
-        const int64_t stop = t1_indptr[b * out_h + i + 1];
-
-        for (int64_t data_idx = start; data_idx < stop; data_idx++)
-        {
-            int64_t row_idx = t1_indices[data_idx];
-            outp_data[data_idx] = t1_data[data_idx] * t2[b * out_w + row_idx];
-        }
-    }
-}
-
-
-std::vector<at::Tensor> csr_dot_diag_cuda(
-    at::Tensor t1_indices,
-    at::Tensor t1_indptr,
-    at::Tensor t1_data,
-    at::Tensor t2,
-    int64_t batch_size,
-    int64_t out_h,
-    int64_t out_w
-){
-    auto outp_indices = at::clone(t1_indices);
-    auto outp_indptr = at::clone(t1_indptr);
-    auto outp_data = at::zeros_like(t1_data);
-
-    const int threads = 1024;
-    const dim3 blocks((out_h + threads - 1) / threads, batch_size);
-
-    AT_DISPATCH_FLOATING_TYPES_AND_HALF(t1_data.type(), "csr_dot_diag_cuda", ([&] {
-    csr_dot_diag_cuda_kernel<scalar_t><<<blocks, threads>>>(
-        t1_indices.data<int64_t>(),
-        t1_indptr.data<int64_t>(),
-        t1_data.data<scalar_t>(),
-        t2.data<scalar_t>(),
-        outp_data.data<scalar_t>(),
-        out_h,
-        out_w);
-    }));
-
-    return {outp_indices, outp_indptr, outp_data};
-}
diff --git a/COMMON/src/extension/sparse_dot/sparse_dot.cpp b/COMMON/src/extension/sparse_dot/sparse_dot.cpp
deleted file mode 100644
index 4ec1ecd..0000000
--- a/COMMON/src/extension/sparse_dot/sparse_dot.cpp
+++ /dev/null
@@ -1,275 +0,0 @@
-#include <torch/torch.h>
-#include <utility>
-
-/* CUDA Declaration */
-
-at::Tensor csr_dot_csc_cuda(
-    at::Tensor t1_indices,
-    at::Tensor t1_indptr,
-    at::Tensor t1_data,
-    at::Tensor t2_indices,
-    at::Tensor t2_indptr,
-    at::Tensor t2_data,
-    int64_t batch_size,
-    int64_t out_h,
-    int64_t out_w
-);
-
-
-std::vector<at::Tensor> csr_dot_diag_cuda(
-    at::Tensor t1_indices,
-    at::Tensor t1_indptr,
-    at::Tensor t1_data,
-    at::Tensor t2,
-    int64_t batch_size,
-    int64_t out_h,
-    int64_t out_w
-);
-
-
-#define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x " must be a CUDA tensor")
-#define CHECK_CPU(x) AT_ASSERTM(!x.type().is_cuda(), #x " must be a CPU tensor")
-#define CHECK_CONTIGUOUS(x) AT_ASSERTM(x.is_contiguous(), #x " must be contiguous")
-#define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)
-
-
-/* CSR dot CSC Implementation */
-
-std::vector<at::Tensor> csr_dot_csc_cpu(
-    at::Tensor t1_indices,
-    at::Tensor t1_indptr,
-    at::Tensor t1_data,
-    at::Tensor t2_indices,
-    at::Tensor t2_indptr,
-    at::Tensor t2_data,
-    int64_t batch_size,
-    int64_t out_h,
-    int64_t out_w
-){
-    CHECK_CPU(t1_indices);
-    CHECK_CPU(t1_indptr);
-    CHECK_CPU(t1_data);
-    CHECK_CPU(t2_indices);
-    CHECK_CPU(t2_indptr);
-    CHECK_CPU(t2_data);
-
-    std::list<int64_t> out_indices_list[batch_size * out_h];
-    std::list<float> out_data_list[batch_size * out_h];
-    auto out_indptr = at::zeros({batch_size * out_h + 1}, t1_indptr.type());
-    auto t1_indptr_acc = t1_indptr.accessor<int64_t, 1>();
-    auto t2_indptr_acc = t2_indptr.accessor<int64_t, 1>();
-    auto t1_indices_acc = t1_indices.accessor<int64_t, 1>();
-    auto t2_indices_acc = t2_indices.accessor<int64_t, 1>();
-
-    for (int64_t b = 0; b < batch_size; b++)
-    {
-        for (int64_t i = 0; i < out_h; i++)
-        {
-            int64_t t1_start = t1_indptr_acc[b * out_h + i];
-            int64_t t1_stop = t1_indptr_acc[b * out_h + i + 1];
-            int64_t row_nnz = 0;
-
-            for (int64_t j = 0; j < out_w; j++)
-            {
-                int64_t t2_start = t2_indptr_acc[b * out_w + j];
-                int64_t t2_stop = t2_indptr_acc[b * out_w + j + 1];
-
-                float outp = 0;//at::zeros({}, t1_data.type());
-                int64_t t1_ptr_idx = t1_start;
-                int64_t t2_ptr_idx = t2_start;
-
-                while (t1_ptr_idx < t1_stop && t2_ptr_idx < t2_stop)
-                {
-                    int64_t t1_cur_indice = t1_indices_acc[t1_ptr_idx];
-                    int64_t t2_cur_indice = t2_indices_acc[t2_ptr_idx];
-                    if (t1_cur_indice == t2_cur_indice)
-                    {
-                        auto tmp = t1_data[t1_ptr_idx] * t2_data[t2_ptr_idx];
-                        auto tmp_acc = tmp.accessor<float, 1>();
-                        outp += tmp_acc[0];
-                        t1_ptr_idx++;
-                        t2_ptr_idx++;
-                    }
-                    else if (t1_cur_indice < t2_cur_indice)
-                        t1_ptr_idx++;
-                    else
-                        t2_ptr_idx++;
-                }
-                if (outp != 0)
-                {
-                    out_data_list[b * out_h + i].push_back(outp);
-                    out_indices_list[b * out_h + i].push_back(j);
-                    row_nnz++;
-                }
-            }
-            out_indptr[b * out_h + i + 1] = out_indptr[b * out_h + i] + row_nnz;
-        }
-    }
-
-    auto out_indptr_acc = out_indptr.accessor<int64_t, 1>();
-    int64_t nnz = out_indptr_acc[-1];
-    auto out_indices = at::zeros({nnz}, t1_indices.type());
-    auto out_data = at::zeros({nnz}, t1_data.type());
-    int64_t idx = 0;
-    for (int64_t b = 0; b < batch_size; b++)
-    {
-        for (int64_t i = 0; i < out_h; i++)
-        {
-            auto * tmp_indices_list = &out_indices_list[b * out_h + i];
-            auto * tmp_data_list = &out_data_list[b * out_h + i];
-            while (!tmp_indices_list->empty() && !tmp_data_list->empty())
-            {
-                out_indices[idx] = tmp_indices_list->front();
-                tmp_indices_list->pop_front();
-                out_data[idx] = tmp_data_list->front();
-                tmp_data_list->pop_front();
-                idx++;
-            }
-        }
-    }
-
-    return {out_indices, out_indptr, out_data};
-}
-
-
-at::Tensor csr_dot_csc_dense_cuda_wrapper(
-    at::Tensor t1_indices,
-    at::Tensor t1_indptr,
-    at::Tensor t1_data,
-    at::Tensor t2_indices,
-    at::Tensor t2_indptr,
-    at::Tensor t2_data,
-    int64_t batch_size,
-    int64_t out_h,
-    int64_t out_w
-){
-    CHECK_INPUT(t1_indices);
-    CHECK_INPUT(t1_indptr);
-    CHECK_INPUT(t1_data);
-    CHECK_INPUT(t2_indices);
-    CHECK_INPUT(t2_indptr);
-    CHECK_INPUT(t2_data);
-    return csr_dot_csc_cuda(t1_indices, t1_indptr, t1_data,
-                            t2_indices, t2_indptr, t2_data,
-                            batch_size, out_h, out_w);
-}
-
-
-std::vector<at::Tensor> csr_dot_csc(
-    at::Tensor t1_indices,
-    at::Tensor t1_indptr,
-    at::Tensor t1_data,
-    at::Tensor t2_indices,
-    at::Tensor t2_indptr,
-    at::Tensor t2_data,
-    int64_t batch_size,
-    int64_t out_h,
-    int64_t out_w
-)
-{
-    if (t1_indices.type().is_cuda())
-        throw std::runtime_error("Unexpected cuda tensor in sparse dot sparse -> sparse computation.");
-    else
-        return csr_dot_csc_cpu(t1_indices, t1_indptr, t1_data, t2_indices, t2_indptr, t2_data, batch_size, out_h, out_w);
-}
-
-at::Tensor csr_dot_csc_dense_cuda(
-    at::Tensor t1_indices,
-    at::Tensor t1_indptr,
-    at::Tensor t1_data,
-    at::Tensor t2_indices,
-    at::Tensor t2_indptr,
-    at::Tensor t2_data,
-    int64_t batch_size,
-    int64_t out_h,
-    int64_t out_w
-)
-{
-    return csr_dot_csc_dense_cuda_wrapper(t1_indices, t1_indptr, t1_data, t2_indices, t2_indptr, t2_data,
-                                          batch_size, out_h, out_w);
-}
-
-
-/* CSR dot diag implementation */
-
-std::vector<at::Tensor> csr_dot_diag_cpu(
-    at::Tensor t1_indices,
-    at::Tensor t1_indptr,
-    at::Tensor t1_data,
-    at::Tensor t2,
-    int64_t batch_size,
-    int64_t out_h,
-    int64_t out_w
-)
-{
-    CHECK_CPU(t1_indices);
-    CHECK_CPU(t1_indptr);
-    CHECK_CPU(t1_data);
-    CHECK_CPU(t2);
-    auto outp_indices = at::clone(t1_indices);
-    auto outp_indptr = at::clone(t1_indptr);
-    auto outp_data = at::zeros_like(t1_data);
-
-    auto t1_indptr_acc = t1_indptr.accessor<int64_t, 1>();
-    auto t1_indices_acc = t1_indices.accessor<int64_t, 1>();
-
-    for (int64_t b = 0; b < batch_size; b++)
-    {
-        for (int64_t i = 0; i < out_h; i++)
-        {
-            int64_t start = t1_indptr_acc[b * out_h + i];
-            int64_t stop = t1_indptr_acc[b * out_h + i + 1];
-            for (int64_t data_idx = start; data_idx < stop; data_idx++)
-            {
-                int64_t row_idx = t1_indices_acc[data_idx];
-                outp_data[data_idx] = t1_data[data_idx] * t2[b][row_idx];
-            }
-        }
-    }
-    return {outp_indices, outp_indptr, outp_data};
-}
-
-
-std::vector<at::Tensor> csr_dot_diag_cuda_wrapper(
-    at::Tensor t1_indices,
-    at::Tensor t1_indptr,
-    at::Tensor t1_data,
-    at::Tensor t2,
-    int64_t batch_size,
-    int64_t out_h,
-    int64_t out_w
-)
-{
-    CHECK_INPUT(t1_indices);
-    CHECK_INPUT(t1_indptr);
-    CHECK_INPUT(t1_data);
-    CHECK_INPUT(t2);
-    return csr_dot_diag_cuda(t1_indices, t1_indptr, t1_data, t2, batch_size, out_h, out_w);
-}
-
-
-std::vector<at::Tensor> csr_dot_diag(
-    at::Tensor t1_indices,
-    at::Tensor t1_indptr,
-    at::Tensor t1_data,
-    at::Tensor t2,
-    int64_t batch_size,
-    int64_t out_h,
-    int64_t out_w
-)
-{
-    if (t1_indices.type().is_cuda())
-        return csr_dot_diag_cuda_wrapper(t1_indices, t1_indptr, t1_data, t2, batch_size, out_h, out_w);
-    else
-        return csr_dot_diag_cpu(t1_indices, t1_indptr, t1_data, t2, batch_size, out_h, out_w);
-
-}
-
-/* PyBind Interface */
-
-PYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {
-  m.def("csr_dot_csc", &csr_dot_csc, "csr sparse matrix dot csc sparse matrix");
-  m.def("csr_dot_csc_dense_cuda", &csr_dot_csc_dense_cuda,
-        "cuda implementation of csr sparse matrix dot csc sparse matrix, result is dense");
-  m.def("csr_dot_diag", &csr_dot_diag, "csr sparse matrix dot a diagonal of dense vector");
-}
diff --git a/COMMON/src/factorize_graph_matching.py b/COMMON/src/factorize_graph_matching.py
deleted file mode 100644
index 2632658..0000000
--- a/COMMON/src/factorize_graph_matching.py
+++ /dev/null
@@ -1,186 +0,0 @@
-import torch
-from torch import Tensor
-from torch.autograd import Function
-from src.utils.sparse import bilinear_diag_torch
-from src.sparse_torch import CSRMatrix3d, CSCMatrix3d
-import scipy.sparse as ssp
-import numpy as np
-
-
-def construct_aff_mat(Ke: Tensor, Kp: Tensor, KroG: CSRMatrix3d, KroH: CSCMatrix3d,
-                      KroGt: CSRMatrix3d=None, KroHt: CSCMatrix3d=None) -> Tensor:
-    r"""
-    Construct the complete affinity matrix with edge-wise affinity matrix :math:`\mathbf{K}_e`, node-wise matrix
-    :math:`\mathbf{K}_p` and graph connectivity matrices :math:`\mathbf{G}_1, \mathbf{H}_1, \mathbf{G}_2, \mathbf{H}_2`
-
-    .. math ::
-        \mathbf{K}=\mathrm{diag}(\mathrm{vec}(\mathbf{K}_p)) +
-        (\mathbf{G}_2 \otimes_{\mathcal{K}} \mathbf{G}_1) \mathrm{diag}(\mathrm{vec}(\mathbf{K}_e))
-        (\mathbf{H}_2 \otimes_{\mathcal{K}} \mathbf{H}_1)^\top
-
-    where :math:`\mathrm{diag}(\cdot)` means building a diagonal matrix based on the given vector,
-    and :math:`\mathrm{vec}(\cdot)` means column-wise vectorization.
-    :math:`\otimes_{\mathcal{K}}` denotes Kronecker product.
-
-    This function supports batched operations. This formulation is developed by `"F. Zhou and F. Torre. Factorized
-    Graph Matching. TPAMI 2015." <http://www.f-zhou.com/gm/2015_PAMI_FGM_Draft.pdf>`_
-
-    :param Ke: :math:`(b\times n_{e_1}\times n_{e_2})` edge-wise affinity matrix.
-     :math:`n_{e_1}`: number of edges in graph 1, :math:`n_{e_2}`: number of edges in graph 2
-    :param Kp: :math:`(b\times n_1\times n_2)` node-wise affinity matrix.
-     :math:`n_1`: number of nodes in graph 1, :math:`n_2`: number of nodes in graph 2
-    :param KroG: :math:`(b\times n_1n_2 \times n_{e_1}n_{e_2})` kronecker product of
-     :math:`\mathbf{G}_2 (b\times n_2 \times n_{e_2})`, :math:`\mathbf{G}_1 (b\times n_1 \times n_{e_1})`
-    :param KroH: :math:`(b\times n_1n_2 \times n_{e_1}n_{e_2})` kronecker product of
-     :math:`\mathbf{H}_2 (b\times n_2 \times n_{e_2})`, :math:`\mathbf{H}_1 (b\times n_1 \times n_{e_1})`
-    :param KroGt: transpose of KroG (should be CSR, optional)
-    :param KroHt: transpose of KroH (should be CSC, optional)
-    :return: affinity matrix :math:`\mathbf K`
-
-    .. note ::
-        This function is optimized with sparse CSR and CSC matrices with GPU support for both forward and backward
-        computation with PyTorch. To use this function, you need to install ``ninja-build``, ``gcc-7``, ``nvcc`` (which
-        comes along with CUDA development tools) to successfully compile our customized CUDA code for CSR and CSC
-        matrices. The compiler is automatically called upon requirement.
-
-    For a graph matching problem with 5 nodes and 4 nodes,
-    the connection of :math:`\mathbf K` and :math:`\mathbf{K}_p, \mathbf{K}_e` is illustrated as
-
-    .. image :: ../../images/factorized_graph_matching.png
-
-    where :math:`\mathbf K (20 \times 20)` is the complete affinity matrix, :math:`\mathbf{K}_p (5 \times 4)` is the
-    node-wise affinity matrix, :math:`\mathbf{K}_e(16 \times 10)` is the edge-wise affinity matrix.
-    """
-    return RebuildFGM.apply(Ke, Kp, KroG, KroH, KroGt, KroHt)
-
-
-def construct_sparse_aff_mat(Ke: Tensor, Kp: Tensor, row_idx: Tensor, col_idx: Tensor):
-    r"""
-    Construct sparse affinity matrix with edge-wise affinity matrix :math:`\mathbf{K}_e`, node-wise matrix
-    :math:`\mathbf{K}_p` and graph connectivity matrices :math:`\mathbf{G}_1, \mathbf{H}_1, \mathbf{G}_2, \mathbf{H}_2`
-
-    .. math ::
-        \mathbf{K}=\mathrm{diag}(\mathrm{vec}(\mathbf{K}_p)) +
-        (\mathbf{G}_2 \otimes_{\mathcal{K}} \mathbf{G}_1) \mathrm{diag}(\mathrm{vec}(\mathbf{K}_e))
-        (\mathbf{H}_2 \otimes_{\mathcal{K}} \mathbf{H}_1)^\top
-
-    where :math:`\mathrm{diag}(\cdot)` means building a diagonal matrix based on the given vector,
-    and :math:`\mathrm{vec}(\cdot)` means column-wise vectorization.
-    :math:`\otimes_{\mathcal{K}}` denotes Kronecker product.
-
-    This function does not supports batched operations. This formulation is developed by `"F. Zhou and F. Torre. Factorized
-    Graph Matching. TPAMI 2015." <http://www.f-zhou.com/gm/2015_PAMI_FGM_Draft.pdf>`_
-
-    :param Ke: :math:`(1\times n_e)` non-zero elements in edge-wise affinity matrix Ke.
-     :math:`n_e`: number of non-zero elements in dense Ke
-    :param Kp: :math:`(1\times n_1 n_2)` non-zero elements in node-wise affinity matrix Kp.
-     :math:`n_1`: number of nodes in graph 1, :math:`n_2`: number of nodes in graph 2
-    :param row_idx: :math:`(1\times n_e)` row indices of the non-zero elements in edge-wise affinity matrix Ke
-    :param col_idx: :math:`(1\times n_e)` column indices of the non-zero elements in edge-wise affinity matrix Ke
-    :return: none-zero values in the affinity matrix :math:`\mathbf K`, and their row/column indices (value, row-idx, col-idx)
-
-    For a graph matching problem with 5 nodes and 4 nodes,
-    the connection of :math:`\mathbf K` and :math:`\mathbf{K}_p, \mathbf{K}_e` is illustrated as
-
-    .. image :: ../../images/factorized_graph_matching.png
-
-    where :math:`\mathbf K (20 \times 20)` is the complete affinity matrix, :math:`\mathbf{K}_p (5 \times 4)` is the
-    node-wise affinity matrix, :math:`\mathbf{K}_e(16 \times 10)` is the edge-wise affinity matrix.
-    """
-    edge_value = torch.flatten(Ke)
-    point_value = torch.flatten(Kp)
-    K_value = torch.cat((edge_value, point_value), dim=0)
-    row_idx = torch.cat((row_idx, torch.linspace(0, point_value.shape[0] - 1, point_value.shape[0], device=row_idx.device)), dim=0)
-    col_idx = torch.cat((col_idx, torch.linspace(0, point_value.shape[0] - 1, point_value.shape[0], device=row_idx.device)), dim=0)
-    return K_value, row_idx, col_idx
-
-
-def kronecker_torch(t1: Tensor, t2: Tensor) -> Tensor:
-    r"""
-    Compute the kronecker product of :math:`\mathbf{T}_1` and :math:`\mathbf{T}_2`.
-    This function is implemented in torch API and is not efficient for sparse {0, 1} matrix.
-
-    :param t1: input tensor 1
-    :param t2: input tensor 2
-    :return: kronecker product of :math:`\mathbf{T}_1` and :math:`\mathbf{T}_2`
-    """
-    batch_num = t1.shape[0]
-    t1dim1, t1dim2 = t1.shape[1], t1.shape[2]
-    t2dim1, t2dim2 = t2.shape[1], t2.shape[2]
-    if t1.is_sparse and t2.is_sparse:
-        tt_idx = torch.stack(t1._indices()[0, :] * t2dim1, t1._indices()[1, :] * t2dim2)
-        tt_idx = torch.repeat_interleave(tt_idx, t2._nnz(), dim=1) + t2._indices().repeat(1, t1._nnz())
-        tt_val = torch.repeat_interleave(t1._values(), t2._nnz(), dim=1) * t2._values().repeat(1, t1._nnz())
-        tt = torch.sparse.FloatTensor(tt_idx, tt_val, torch.Size(t1dim1 * t2dim1, t1dim2 * t2dim2))
-    else:
-        t1 = t1.reshape(batch_num, -1, 1)
-        t2 = t2.reshape(batch_num, 1, -1)
-        tt = torch.bmm(t1, t2)
-        tt = tt.reshape(batch_num, t1dim1, t1dim2, t2dim1, t2dim2)
-        tt = tt.permute([0, 1, 3, 2, 4])
-        tt = tt.reshape(batch_num, t1dim1 * t2dim1, t1dim2 * t2dim2)
-    return tt
-
-
-def kronecker_sparse(arr1: np.ndarray, arr2: np.ndarray) -> np.ndarray:
-    r"""
-    Compute the kronecker product of :math:`\mathbf{T}_1` and :math:`\mathbf{T}_2`.
-    This function is implemented in scipy.sparse API and runs on cpu.
-
-    :param arr1: input array 1
-    :param arr2: input array 2
-    :return: kronecker product of :math:`\mathbf{T}_1` and :math:`\mathbf{T}_2`
-    """
-    s1 = ssp.coo_matrix(arr1)
-    s2 = ssp.coo_matrix(arr2)
-    ss = ssp.kron(s1, s2)
-    return ss
-
-
-class RebuildFGM(Function):
-    r"""
-    Rebuild sparse affinity matrix in the formula of the paper `"Factorized Graph Matching, in
-    TPAMI 2015" <http://www.f-zhou.com/gm/2015_PAMI_FGM_Draft.pdf>`_
-
-    See :func:`~src.factorize_graph_matching.construct_aff_mat` for detailed reference.
-    """
-    @staticmethod
-    def forward(ctx, Ke: Tensor, Kp: Tensor, Kro1: CSRMatrix3d, Kro2: CSCMatrix3d,
-                Kro1T: CSRMatrix3d=None, Kro2T: CSCMatrix3d=None) -> Tensor:
-        """
-        Forward function to compute the affinity matrix :math:`\mathbf K`.
-        """
-        ctx.save_for_backward(Ke, Kp)
-        if Kro1T is not None and Kro2T is not None:
-            ctx.K = Kro1T, Kro2T
-        else:
-            ctx.K = Kro1.transpose(keep_type=True), Kro2.transpose(keep_type=True)
-        batch_num = Ke.shape[0]
-
-        Kro1Ke = Kro1.dotdiag(Ke.transpose(1, 2).contiguous().view(batch_num, -1))
-        Kro1KeKro2 = Kro1Ke.dot(Kro2, dense=True)
-
-        K = torch.empty_like(Kro1KeKro2)
-        for b in range(batch_num):
-            K[b] = Kro1KeKro2[b] + torch.diag(Kp[b].transpose(0, 1).contiguous().view(-1))
-
-        return K
-
-    @staticmethod
-    def backward(ctx, dK):
-        r"""
-        Backward function from the affinity matrix :math:`\mathbf K` to node-wise affinity matrix :math:`\mathbf K_e`
-        and edge-wize affinity matrix :math:`\mathbf K_e`.
-        """
-        device = dK.device
-        Ke, Kp = ctx.saved_tensors
-        Kro1t, Kro2t = ctx.K
-        dKe = dKp = None
-        if ctx.needs_input_grad[0]:
-            dKe = bilinear_diag_torch(Kro1t, dK.contiguous(), Kro2t)
-            dKe = dKe.view(Ke.shape[0], Ke.shape[2], Ke.shape[1]).transpose(1, 2)
-        if ctx.needs_input_grad[1]:
-            dKp = torch.diagonal(dK, dim1=-2, dim2=-1)
-            dKp = dKp.view(Kp.shape[0], Kp.shape[2], Kp.shape[1]).transpose(1, 2)
-
-        return dKe, dKp, None, None, None, None
diff --git a/COMMON/src/feature_align.py b/COMMON/src/feature_align.py
deleted file mode 100644
index 19792bc..0000000
--- a/COMMON/src/feature_align.py
+++ /dev/null
@@ -1,126 +0,0 @@
-import torch
-from torch import Tensor
-
-
-def feature_align(raw_feature: Tensor, P: Tensor, ns_t: Tensor, ori_size: tuple, device=None) -> Tensor:
-    r"""
-    Perform feature align on the image feature map.
-
-    Feature align performs bi-linear interpolation on the image feature map. This operation is inspired by "ROIAlign"
-    in `Mask R-CNN <https://arxiv.org/abs/1703.06870>`_.
-
-    :param raw_feature: :math:`(b\times c \times w \times h)` raw feature map. :math:`b`: batch size, :math:`c`: number
-     of feature channels, :math:`w`: feature map width, :math:`h`: feature map height
-    :param P: :math:`(b\times n \times 2)` point set containing point coordinates. The coordinates are at the scale of
-     the original image size. :math:`n`: number of points
-    :param ns_t: :math:`(b)` number of exact points. We support batched instances with different number of nodes, and
-     ``ns_t`` is required to specify the exact number of nodes of each instance in the batch.
-    :param ori_size: size of the original image. Since the point coordinates are in the scale of the original image
-     size, this parameter is required.
-    :param device: output device. If not specified, it will be the same as the input
-    :return: :math:`(b\times c \times n)` extracted feature vectors
-    """
-    if device is None:
-        device = raw_feature.device
-
-    batch_num = raw_feature.shape[0]
-    channel_num = raw_feature.shape[1]
-    n_max = P.shape[1]
-
-    ori_size = torch.tensor(ori_size, dtype=torch.float32, device=device)
-    F = torch.zeros(batch_num, channel_num, n_max, dtype=torch.float32, device=device)
-    for idx, feature in enumerate(raw_feature):
-        n = ns_t[idx]
-        feat_size = torch.as_tensor(feature.shape[1:3], dtype=torch.float32, device=device)
-        _P = P[idx, 0:n]
-        interp_2d(feature, _P, ori_size, feat_size, out=F[idx, :, 0:n])
-    return F
-
-
-def interp_2d(z: Tensor, P: Tensor, ori_size: Tensor, feat_size: Tensor, out=None, device=None) -> Tensor:
-    r"""
-    Interpolate in 2d grid space. z can be 3-dimensional where the first dimension is feature dimension.
-
-    :param z: :math:`(c\times w\times h)` feature map. :math:`c`: number of feature channels, :math:`w`: feature map
-     width, :math:`h`: feature map height
-    :param P: :math:`(n\times 2)` point set containing point coordinates. The coordinates are at the scale of
-     the original image size. :math:`n`: number of points
-    :param ori_size: :math:`(2)` size of the original image
-    :param feat_size: :math:`(2)` size of the feature map
-    :param out: optional output tensor
-    :param device: output device. If not specified, it will be the same as the input
-    :return: :math:`(c \times n)` extracted feature vectors
-    """
-    if device is None:
-        device = z.device
-
-    step = ori_size / feat_size
-    if out is None:
-        out = torch.zeros(z.shape[0], P.shape[0], dtype=torch.float32, device=device)
-    for i, p in enumerate(P):
-        p = (p - step / 2) / ori_size * feat_size
-        out[:, i] = bilinear_interpolate(z, p[0], p[1])
-
-    return out
-
-
-def bilinear_interpolate(im: Tensor, x: Tensor, y: Tensor, device=None):
-    r"""
-    Bi-linear interpolate 3d feature map to 2d coordinate (x, y).
-    The coordinates are at the same scale of :math:`w\times h`.
-
-    :param im: :math:`(c\times w\times h)` feature map
-    :param x: :math:`(1)` x coordinate
-    :param y: :math:`(1)` y coordinate
-    :param device: output device. If not specified, it will be the same as the input
-    :return: :math:`(c)` interpolated feature vector
-    """
-    if device is None:
-        device = im.device
-    x = x.to(torch.float32).to(device)
-    y = y.to(torch.float32).to(device)
-
-    x0 = torch.floor(x)
-    x1 = x0 + 1
-    y0 = torch.floor(y)
-    y1 = y0 + 1
-
-    x0 = torch.clamp(x0, 0, im.shape[2] - 1)
-    x1 = torch.clamp(x1, 0, im.shape[2] - 1)
-    y0 = torch.clamp(y0, 0, im.shape[1] - 1)
-    y1 = torch.clamp(y1, 0, im.shape[1] - 1)
-
-    x0 = x0.to(torch.int32).to(device)
-    x1 = x1.to(torch.int32).to(device)
-    y0 = y0.to(torch.int32).to(device)
-    y1 = y1.to(torch.int32).to(device)
-
-    Ia = im[:, y0, x0]
-    Ib = im[:, y1, x0]
-    Ic = im[:, y0, x1]
-    Id = im[:, y1, x1]
-
-    # to perform nearest neighbor interpolation if out of bounds
-    if x0 == x1:
-        if x0 == 0:
-            x0 -= 1
-        else:
-            x1 += 1
-    if y0 == y1:
-        if y0 == 0:
-            y0 -= 1
-        else:
-            y1 += 1
-
-    x0 = x0.to(torch.float32).to(device)
-    x1 = x1.to(torch.float32).to(device)
-    y0 = y0.to(torch.float32).to(device)
-    y1 = y1.to(torch.float32).to(device)
-
-    wa = (x1 - x) * (y1 - y)
-    wb = (x1 - x) * (y - y0)
-    wc = (x - x0) * (y1 - y)
-    wd = (x - x0) * (y - y0)
-
-    out = Ia * wa + Ib * wb + Ic * wc + Id * wd
-    return out
diff --git a/COMMON/src/gconv.py b/COMMON/src/gconv.py
deleted file mode 100644
index a2ae120..0000000
--- a/COMMON/src/gconv.py
+++ /dev/null
@@ -1,173 +0,0 @@
-import torch
-import torch.nn as nn
-import torch.nn.functional as F
-from torch import Tensor
-from typing import Tuple, Optional, List, Union
-
-
-class Gconv(nn.Module):
-    r"""
-    Graph Convolutional Layer which is inspired and developed based on Graph Convolutional Network (GCN).
-    Inspired by `Kipf and Welling. Semi-Supervised Classification with Graph Convolutional Networks. ICLR 2017.
-    <https://arxiv.org/abs/1609.02907>`_
-
-    :param in_features: the dimension of input node features
-    :param out_features: the dimension of output node features
-    """
-    def __init__(self, in_features: int, out_features: int):
-        super(Gconv, self).__init__()
-        self.num_inputs = in_features
-        self.num_outputs = out_features
-        self.a_fc = nn.Linear(self.num_inputs, self.num_outputs)
-        self.u_fc = nn.Linear(self.num_inputs, self.num_outputs)
-
-    def forward(self, A: Tensor, x: Tensor, norm: bool=True) -> Tensor:
-        r"""
-        Forward computation of graph convolution network.
-
-        :param A: :math:`(b\times n\times n)` {0,1} adjacency matrix. :math:`b`: batch size, :math:`n`: number of nodes
-        :param x: :math:`(b\times n\times d)` input node embedding. :math:`d`: feature dimension
-        :param norm: normalize connectivity matrix or not
-        :return: :math:`(b\times n\times d^\prime)` new node embedding
-        """
-        if norm is True:
-            A = F.normalize(A, p=1, dim=-2)
-        ax = self.a_fc(x)
-        ux = self.u_fc(x)
-        x = torch.bmm(A, F.relu(ax)) + F.relu(ux) # has size (bs, N, num_outputs)
-        return x
-
-
-class ChannelIndependentConv(nn.Module):
-    r"""
-    Channel Independent Embedding Convolution.
-    Proposed by `"Yu et al. Learning deep graph matching with channel-independent embedding and Hungarian attention.
-    ICLR 2020." <https://openreview.net/forum?id=rJgBd2NYPH>`_
-
-    :param in_features: the dimension of input node features
-    :param out_features: the dimension of output node features
-    :param in_edges: the dimension of input edge features
-    :param out_edges: (optional) the dimension of output edge features. It needs to be the same as ``out_features``
-    """
-    def __init__(self, in_features: int, out_features: int, in_edges: int, out_edges: int=None):
-        super(ChannelIndependentConv, self).__init__()
-        if out_edges is None:
-            out_edges = out_features
-        self.in_features = in_features
-        self.out_features = out_features
-        self.out_edges = out_edges
-        # self.node_fc = nn.Linear(in_features, out_features // self.out_edges)
-        self.node_fc = nn.Linear(in_features, out_features)
-        self.node_sfc = nn.Linear(in_features, out_features)
-        self.edge_fc = nn.Linear(in_edges, self.out_edges)
-
-    def forward(self, A: Tensor, emb_node: Tensor, emb_edge: Tensor, mode: int=1) -> Tuple[Tensor, Tensor]:
-        r"""
-        :param A: :math:`(b\times n\times n)` {0,1} adjacency matrix. :math:`b`: batch size, :math:`n`: number of nodes
-        :param emb_node: :math:`(b\times n\times d_n)` input node embedding. :math:`d_n`: node feature dimension
-        :param emb_edge: :math:`(b\times n\times n\times d_e)` input edge embedding. :math:`d_e`: edge feature dimension
-        :param mode: 1 or 2, refer to the paper for details
-        :return: :math:`(b\times n\times d^\prime)` new node embedding,
-         :math:`(b\times n\times n\times d^\prime)` new edge embedding
-        """
-        if mode == 1:
-            node_x = self.node_fc(emb_node)
-            node_sx = self.node_sfc(emb_node)
-            edge_x = self.edge_fc(emb_edge)
-
-            A = A.unsqueeze(-1)
-            A = torch.mul(A.expand_as(edge_x), edge_x)
-
-            node_x = torch.matmul(A.transpose(2, 3).transpose(1, 2),
-                                  node_x.unsqueeze(2).transpose(2, 3).transpose(1, 2))
-            node_x = node_x.squeeze(-1).transpose(1, 2)
-            node_x = F.relu(node_x) + F.relu(node_sx)
-            edge_x = F.relu(edge_x)
-
-            return node_x, edge_x
-
-        elif mode == 2:
-            node_x = self.node_fc(emb_node)
-            node_sx = self.node_sfc(emb_node)
-            edge_x = self.edge_fc(emb_edge)
-
-            d_x = node_x.unsqueeze(1) - node_x.unsqueeze(2)
-            d_x = torch.sum(d_x ** 2, dim=3, keepdim=False)
-            d_x = torch.exp(-d_x)
-
-            A = A.unsqueeze(-1)
-            A = torch.mul(A.expand_as(edge_x), edge_x)
-
-            node_x = torch.matmul(A.transpose(2, 3).transpose(1, 2),
-                                  node_x.unsqueeze(2).transpose(2, 3).transpose(1, 2))
-            node_x = node_x.squeeze(-1).transpose(1, 2)
-            node_x = F.relu(node_x) + F.relu(node_sx)
-            edge_x = F.relu(edge_x)
-            return node_x, edge_x
-
-        else:
-            raise ValueError('Unknown mode {}. Possible options: 1 or 2'.format(mode))
-
-
-class Siamese_Gconv(nn.Module):
-    r"""
-    Siamese Gconv neural network for processing arbitrary number of graphs.
-
-    :param in_features: the dimension of input node features
-    :param num_features: the dimension of output node features
-    """
-    def __init__(self, in_features, num_features):
-        super(Siamese_Gconv, self).__init__()
-        self.gconv = Gconv(in_features, num_features)
-
-    def forward(self, g1: Tuple[Tensor, Tensor, Tensor, int], *args) -> Union[Tensor, List[Tensor]]:
-        r"""
-        Forward computation of Siamese Gconv.
-
-        :param g1: The first graph, which is a tuple of (:math:`(b\times n\times n)` {0,1} adjacency matrix,
-         :math:`(b\times n\times d)` input node embedding, normalize connectivity matrix or not)
-        :param args: Other graphs
-        :return: A list of tensors composed of new node embeddings :math:`(b\times n\times d^\prime)`
-        """
-        # embx are tensors of size (bs, N, num_features)
-        emb1 = self.gconv(*g1)
-        if len(args) == 0:
-            return emb1
-        else:
-            returns = [emb1]
-            for g in args:
-                returns.append(self.gconv(*g))
-            return returns
-
-class Siamese_ChannelIndependentConv(nn.Module):
-    r"""
-    Siamese Channel Independent Conv neural network for processing arbitrary number of graphs.
-
-    :param in_features: the dimension of input node features
-    :param num_features: the dimension of output node features
-    :param in_edges: the dimension of input edge features
-    :param out_edges: (optional) the dimension of output edge features. It needs to be the same as ``num_features``
-    """
-    def __init__(self, in_features, num_features, in_edges, out_edges=None):
-        super(Siamese_ChannelIndependentConv, self).__init__()
-        self.in_feature = in_features
-        self.gconv = ChannelIndependentConv(in_features, num_features, in_edges, out_edges)
-
-    def forward(self, g1: Tuple[Tensor, Tensor, Optional[bool]], *args) -> List[Tensor]:
-        r"""
-        Forward computation of Siamese Channel Independent Conv.
-
-        :param g1: The first graph, which is a tuple of (:math:`(b\times n\times n)` {0,1} adjacency matrix,
-         :math:`(b\times n\times d_n)` input node embedding, :math:`(b\times n\times n\times d_e)` input edge embedding,
-         mode (``1`` or ``2``))
-        :param args: Other graphs
-        :return: A list of tensors composed of new node embeddings :math:`(b\times n\times d^\prime)`, appended with new
-         edge embeddings :math:`(b\times n\times n\times d^\prime)`
-        """
-        emb1, emb_edge1 = self.gconv(*g1)
-        embs = [emb1]
-        emb_edges = [emb_edge1]
-        for g in args:
-            emb2, emb_edge2 = self.gconv(*g)
-            embs.append(emb2), emb_edges.append(emb_edge2)
-        return embs + emb_edges
diff --git a/COMMON/src/lap_solvers/ILP.py b/COMMON/src/lap_solvers/ILP.py
deleted file mode 100644
index 032ff1c..0000000
--- a/COMMON/src/lap_solvers/ILP.py
+++ /dev/null
@@ -1,169 +0,0 @@
-import torch
-import scipy.optimize as opt
-import numpy as np
-from multiprocessing import Pool
-from torch import Tensor
-# import gurobipy as gp
-# from gurobipy import GRB
-from ortools.linear_solver import pywraplp
-from ortools.linear_solver.linear_solver_natural_api import LinearExpr
-from contextlib import contextmanager
-import sys,os
-
-@contextmanager
-def suppress_stdout():
-    with open(os.devnull, "w") as devnull:
-        old_stdout = sys.stdout
-        sys.stdout = devnull
-        try:
-            yield
-        finally:
-            sys.stdout = old_stdout
-
-def softmax(x,axis=None):
-    x = x - x.max(axis=axis, keepdims=True)
-    y = np.exp(x)
-    return y / y.sum(axis=axis, keepdims=True)
-
-def ILP_solver(s: Tensor, n1: Tensor=None, n2: Tensor=None, nproc: int=1, dummy: bool=False) -> Tensor:
-    r"""
-    Solve optimal LAP permutation by Integer Linear Programming.
-
-    :param s: :math:`(b\times n_1 \times n_2)` input 3d tensor. :math:`b`: batch size
-    :param n1: :math:`(b)` number of objects in dim1
-    :param n2: :math:`(b)` number of objects in dim2
-    :param nproc: number of parallel processes (default: ``nproc=1`` for no parallel)
-    :param dummy: whether to add dummy node in permutation matrix to match the outliers
-    :return: :math:`(b\times n_1 \times n_2)` optimal permutation matrix
-
-    .. note::
-        We support batched instances with different number of nodes, therefore ``n1`` and ``n2`` are
-        required to specify the exact number of objects of each dimension in the batch. If not specified, we assume
-        the batched matrices are not padded.
-    """
-    if len(s.shape) == 2:
-        s = s.unsqueeze(0)
-        matrix_input = True
-    elif len(s.shape) == 3:
-        matrix_input = False
-    else:
-        raise ValueError('input data shape not understood: {}'.format(s.shape))
-
-    device = s.device
-    batch_num = s.shape[0]
-
-    perm_mat = s.cpu().detach().numpy()
-    if n1 is not None:
-        n1 = n1.cpu().numpy()
-    else:
-        n1 = [None] * batch_num
-    if n2 is not None:
-        n2 = n2.cpu().numpy()
-    else:
-        n2 = [None] * batch_num
-
-    if nproc > 1:
-        with Pool(processes=nproc) as pool:
-            mapresult = pool.starmap_async(_ilp_kernel, zip(perm_mat, n1, n2, dummy))
-            perm_mat = np.stack(mapresult.get())
-    else:
-        perm_mat = np.stack([_ilp_kernel(perm_mat[b], n1[b], n2[b], dummy) for b in range(batch_num)])
-
-    perm_mat = torch.from_numpy(perm_mat).to(device)
-
-    if matrix_input:
-        perm_mat.squeeze_(0)
-
-    return perm_mat
-
-def _ilp_kernel(s: torch.Tensor, n1=None, n2=None, dummy=False):
-    if n1 is None:
-        n1 = s.shape[0]
-    if n2 is None:
-        n2 = s.shape[1]
-    # row, col = opt.linear_sum_assignment(s[:n1, :n2])
-    row, col = ilp_gurobi(s[:n1, :n2], dummy)
-    perm_mat = np.zeros_like(s)
-    perm_mat[row, col] = 1
-    return perm_mat
-
-def ilp_gurobi(s, dummy=False):
-
-    s_list = [[None for _ in range(s.shape[1])] for _ in range(s.shape[0])]
-    s_sum = []
-    # try:
-    with suppress_stdout():
-        # m = gp.Model("mip1")
-        solver = pywraplp.Solver.CreateSolver('SCIP')
-    for i in range(s.shape[0]):
-        for j in range(s.shape[1]):
-            # s_list[i][j] = m.addVar(vtype=GRB.BINARY, name="{row}_{col}".format(row=i,col=j))
-            s_list[i][j] = solver.BoolVar("{row}_{col}".format(row=i,col=j))
-            s_sum.append(-s_list[i][j] * np.log(s[i,j]+1e-10))
-            # s_sum += -s_list[i][j] * np.log(s[i,j]+0.8)
-            # s_sum += -s_list[i][j] * s[i, j]
-    # Set objective
-    # m.setObjective(s_sum, GRB.MINIMIZE)
-    solver.Minimize(solver.Sum(s_sum))
-
-    if dummy==False:
-        # Add row constraint
-        for i in range(s.shape[0]):
-            row_c = s_list[i][0]
-            for j in range(1, s.shape[1]):
-                row_c += s_list[i][j]
-            # m.addConstr(row_c == 1, "row_{row}".format(row=i))
-            solver.Add(row_c == 1, "row_{row}".format(row=i))
-
-        # Add column constraint
-        for j in range(s.shape[1]):
-            col_c = s_list[0][j]
-            for i in range(1, s.shape[0]):
-                col_c += s_list[i][j]
-            # m.addConstr(col_c == 1, "column_{col}".format(col=j))
-            solver.Add(col_c == 1, "column_{col}".format(col=j))
-    else:
-        # Add row constraint
-        for i in range(s.shape[0]-1):
-            row_c = s_list[i][0]
-            for j in range(1, s.shape[1]):
-                row_c += s_list[i][j]
-            # m.addConstr(row_c == 1, "row_{row}".format(row=i))
-            solver.Add(row_c == 1, "row_{row}".format(row=i))
-        # for i in range(s.shape[0]):
-        #     row_c = s_list[i][0]
-        #     for j in range(1, s.shape[1]):
-        #         row_c += s_list[i][j]
-        #     m.addConstr(row_c <= 1, "row_{row}".format(row=i))
-
-        # Add column constraint
-        for j in range(s.shape[1]-1):
-            col_c = s_list[0][j]
-            for i in range(1, s.shape[0]):
-                col_c += s_list[i][j]
-            # m.addConstr(col_c == 1, "column_{col}".format(col=j))
-            solver.Add(col_c == 1, "column_{col}".format(col=j))
-        # for j in range(s.shape[1]):
-        #     col_c = s_list[0][j]
-        #     for i in range(1, s.shape[0]):
-        #         col_c += s_list[i][j]
-        #     m.addConstr(col_c <= 1, "column_{col}".format(col=j))
-
-    # Optimize model
-    with suppress_stdout():
-        # m.optimize()
-        _ = solver.Solve()
-
-    results = np.zeros(s.size)
-
-    for i,v in enumerate(solver.variables()):
-        results[i] = v.solution_value()
-    results = results.reshape(s.shape)
-    [row, column] = np.nonzero(results)
-    # except gp.GurobiError as e:
-    #     print('Error code ' + str(e.errno) + ': ' + str(e))
-
-    # except AttributeError:
-    #     print('Encountered an attribute error')
-
-    return row, column
\ No newline at end of file
diff --git a/COMMON/src/lap_solvers/__init__.py b/COMMON/src/lap_solvers/__init__.py
deleted file mode 100644
index 4ca5a75..0000000
--- a/COMMON/src/lap_solvers/__init__.py
+++ /dev/null
@@ -1,3 +0,0 @@
-"""
-Solvers for linear assignment problem (LAP)
-"""
diff --git a/COMMON/src/lap_solvers/hungarian.py b/COMMON/src/lap_solvers/hungarian.py
deleted file mode 100644
index 1042bcd..0000000
--- a/COMMON/src/lap_solvers/hungarian.py
+++ /dev/null
@@ -1,66 +0,0 @@
-import torch
-import scipy.optimize as opt
-import numpy as np
-from multiprocessing import Pool
-from torch import Tensor
-
-
-def hungarian(s: Tensor, n1: Tensor=None, n2: Tensor=None, nproc: int=1) -> Tensor:
-    r"""
-    Solve optimal LAP permutation by hungarian algorithm. The time cost is :math:`O(n^3)`.
-
-    :param s: :math:`(b\times n_1 \times n_2)` input 3d tensor. :math:`b`: batch size
-    :param n1: :math:`(b)` number of objects in dim1
-    :param n2: :math:`(b)` number of objects in dim2
-    :param nproc: number of parallel processes (default: ``nproc=1`` for no parallel)
-    :return: :math:`(b\times n_1 \times n_2)` optimal permutation matrix
-
-    .. note::
-        We support batched instances with different number of nodes, therefore ``n1`` and ``n2`` are
-        required to specify the exact number of objects of each dimension in the batch. If not specified, we assume
-        the batched matrices are not padded.
-    """
-    if len(s.shape) == 2:
-        s = s.unsqueeze(0)
-        matrix_input = True
-    elif len(s.shape) == 3:
-        matrix_input = False
-    else:
-        raise ValueError('input data shape not understood: {}'.format(s.shape))
-
-    device = s.device
-    batch_num = s.shape[0]
-
-    perm_mat = s.cpu().detach().numpy() * -1
-    if n1 is not None:
-        n1 = n1.cpu().numpy()
-    else:
-        n1 = [None] * batch_num
-    if n2 is not None:
-        n2 = n2.cpu().numpy()
-    else:
-        n2 = [None] * batch_num
-
-    if nproc > 1:
-        with Pool(processes=nproc) as pool:
-            mapresult = pool.starmap_async(_hung_kernel, zip(perm_mat, n1, n2))
-            perm_mat = np.stack(mapresult.get())
-    else:
-        perm_mat = np.stack([_hung_kernel(perm_mat[b], n1[b], n2[b]) for b in range(batch_num)])
-
-    perm_mat = torch.from_numpy(perm_mat).to(device)
-
-    if matrix_input:
-        perm_mat.squeeze_(0)
-
-    return perm_mat
-
-def _hung_kernel(s: torch.Tensor, n1=None, n2=None):
-    if n1 is None:
-        n1 = s.shape[0]
-    if n2 is None:
-        n2 = s.shape[1]
-    row, col = opt.linear_sum_assignment(s[:n1, :n2])
-    perm_mat = np.zeros_like(s)
-    perm_mat[row, col] = 1
-    return perm_mat
\ No newline at end of file
diff --git a/COMMON/src/lap_solvers/sinkhorn.py b/COMMON/src/lap_solvers/sinkhorn.py
deleted file mode 100644
index 8c30d51..0000000
--- a/COMMON/src/lap_solvers/sinkhorn.py
+++ /dev/null
@@ -1,256 +0,0 @@
-import torch
-import torch.nn as nn
-from torch import Tensor
-import pygmtools as pygm
-
-
-class Sinkhorn(nn.Module):
-    r"""
-    Sinkhorn algorithm turns the input matrix into a bi-stochastic matrix.
-
-    Sinkhorn algorithm firstly applies an ``exp`` function with temperature :math:`\tau`:
-
-    .. math::
-        \mathbf{S}_{i,j} = \exp \left(\frac{\mathbf{s}_{i,j}}{\tau}\right)
-
-    And then turns the matrix into doubly-stochastic matrix by iterative row- and column-wise normalization:
-
-    .. math::
-        \mathbf{S} &= \mathbf{S} \oslash (\mathbf{1}_{n_2} \mathbf{1}_{n_2}^\top \cdot \mathbf{S}) \\
-        \mathbf{S} &= \mathbf{S} \oslash (\mathbf{S} \cdot \mathbf{1}_{n_2} \mathbf{1}_{n_2}^\top)
-
-    where :math:`\oslash` means element-wise division, :math:`\mathbf{1}_n` means a column-vector with length :math:`n`
-    whose elements are all :math:`1`\ s.
-
-    :param max_iter: maximum iterations (default: ``10``)
-    :param tau: the hyper parameter :math:`\tau` controlling the temperature (default: ``1``)
-    :param epsilon: a small number for numerical stability (default: ``1e-4``)
-    :param log_forward: apply log-scale computation for better numerical stability (default: ``True``)
-    :param batched_operation: apply batched_operation for better efficiency (but may cause issues for back-propagation,
-     default: ``False``)
-
-    .. note::
-        ``tau`` is an important hyper parameter to be set for Sinkhorn algorithm. ``tau`` controls the distance between
-        the predicted doubly-stochastic matrix, and the discrete permutation matrix computed by Hungarian algorithm (see
-        :func:`~src.lap_solvers.hungarian.hungarian`). Given a small ``tau``, Sinkhorn performs more closely to
-        Hungarian, at the cost of slower convergence speed and reduced numerical stability.
-
-    .. note::
-        We recommend setting ``log_forward=True`` because it is more numerically stable. It provides more precise
-        gradient in back propagation and helps the model to converge better and faster.
-
-    .. note::
-        Setting ``batched_operation=True`` may be preferred when you are doing inference with this module and do not
-        need the gradient.
-    """
-    def __init__(self, max_iter: int=10, tau: float=1., epsilon: float=1e-4,
-                 log_forward: bool=True, batched_operation: bool=False):
-        super(Sinkhorn, self).__init__()
-        self.max_iter = max_iter
-        self.tau = tau
-        self.epsilon = epsilon
-        self.log_forward = log_forward
-        if not log_forward:
-            print('Warning: Sinkhorn algorithm without log forward is deprecated because log_forward is more stable.')
-        self.batched_operation = batched_operation # batched operation may cause instability in backward computation,
-                                                   # but will boost computation.
-
-    def forward(self, s: Tensor, nrows: Tensor=None, ncols: Tensor=None, dummy_row: bool=False) -> Tensor:
-        r"""
-        :param s: :math:`(b\times n_1 \times n_2)` input 3d tensor. :math:`b`: batch size
-        :param nrows: :math:`(b)` number of objects in dim1
-        :param ncols: :math:`(b)` number of objects in dim2
-        :param dummy_row: whether to add dummy rows (rows whose elements are all 0) to pad the matrix to square matrix.
-         default: ``False``
-        :return: :math:`(b\times n_1 \times n_2)` the computed doubly-stochastic matrix
-
-        .. note::
-            We support batched instances with different number of nodes, therefore ``nrows`` and ``ncols`` are
-            required to specify the exact number of objects of each dimension in the batch. If not specified, we assume
-            the batched matrices are not padded.
-
-        .. note::
-            The original Sinkhorn algorithm only works for square matrices. To handle cases where the graphs to be
-            matched have different number of nodes, it is a common practice to add dummy rows to construct a square
-            matrix. After the row and column normalizations, the padded rows are discarded.
-
-        .. note::
-            We assume row number <= column number. If not, the input matrix will be transposed.
-        """
-        if self.log_forward:
-            return self.forward_log(s, nrows, ncols, dummy_row)
-        else:
-            return self.forward_ori(s, nrows, ncols, dummy_row) # deprecated
-
-    def forward_log(self, s, nrows=None, ncols=None, dummy_row=False):
-        """Compute sinkhorn with row/column normalization in the log space."""
-        return pygm.sinkhorn(s, n1=nrows, n2=ncols, dummy_row=dummy_row, max_iter=self.max_iter, tau=self.tau, batched_operation=self.batched_operation, backend='pytorch')
-
-    def forward_ori(self, s, nrows=None, ncols=None, dummy_row=False):
-        r"""
-        Computing sinkhorn with row/column normalization.
-
-        .. warning::
-            This function is deprecated because :meth:`~src.lap_solvers.sinkhorn.Sinkhorn.forward_log` is more
-            numerically stable.
-        """
-        if len(s.shape) == 2:
-            s = s.unsqueeze(0)
-            matrix_input = True
-        elif len(s.shape) == 3:
-            matrix_input = False
-        else:
-            raise ValueError('input data shape not understood.')
-
-        batch_size = s.shape[0]
-
-        #s = s.to(dtype=dtype)
-
-        if nrows is None:
-            nrows = [s.shape[1] for _ in range(batch_size)]
-        if ncols is None:
-            ncols = [s.shape[2] for _ in range(batch_size)]
-
-        # tau scaling
-        ret_s = torch.zeros_like(s)
-        for b, n in enumerate(nrows):
-            ret_s[b, 0:n, 0:ncols[b]] = \
-                nn.functional.softmax(s[b, 0:n, 0:ncols[b]] / self.tau, dim=-1)
-        s = ret_s
-
-        # add dummy elements
-        if dummy_row:
-            dummy_shape = list(s.shape)
-            dummy_shape[1] = s.shape[2] - s.shape[1]
-            #s = torch.cat((s, torch.full(dummy_shape, self.epsilon * 10).to(s.device)), dim=1)
-            #nrows = nrows + dummy_shape[1] # non in-place
-            s = torch.cat((s, torch.full(dummy_shape, 0.).to(s.device)), dim=1)
-            ori_nrows = nrows
-            nrows = ncols
-            for b in range(batch_size):
-                s[b, ori_nrows[b]:nrows[b], :ncols[b]] = self.epsilon
-
-        row_norm_ones = torch.zeros(batch_size, s.shape[1], s.shape[1], device=s.device, dtype=s.dtype)  # size: row x row
-        col_norm_ones = torch.zeros(batch_size, s.shape[2], s.shape[2], device=s.device, dtype=s.dtype)  # size: col x col
-        for b in range(batch_size):
-            row_slice = slice(0, nrows[b])
-            col_slice = slice(0, ncols[b])
-            row_norm_ones[b, row_slice, row_slice] = 1
-            col_norm_ones[b, col_slice, col_slice] = 1
-
-        s += self.epsilon
-
-        for i in range(self.max_iter):
-            if i % 2 == 0:
-                # column norm
-                #ones = torch.ones(batch_size, s.shape[1], s.shape[1], device=s.device)
-                sum = torch.sum(torch.mul(s.unsqueeze(3), col_norm_ones.unsqueeze(1)), dim=2)
-            else:
-                # row norm
-                # ones = torch.ones(batch_size, s.shape[2], s.shape[2], device=s.device)
-                sum = torch.sum(torch.mul(row_norm_ones.unsqueeze(3), s.unsqueeze(1)), dim=2)
-
-            tmp = torch.zeros_like(s)
-            for b in range(batch_size):
-                row_slice = slice(0, nrows[b] if nrows is not None else s.shape[2])
-                col_slice = slice(0, ncols[b] if ncols is not None else s.shape[1])
-                tmp[b, row_slice, col_slice] = 1 / sum[b, row_slice, col_slice]
-            s = s * tmp
-
-        if dummy_row:
-            if dummy_shape[1] > 0:
-                s = s[:, :-dummy_shape[1]]
-            for b in range(batch_size):
-                s[b, ori_nrows[b]:nrows[b], :ncols[b]] = 0
-
-        if matrix_input:
-            s.squeeze_(0)
-
-        return s
-
-
-class GumbelSinkhorn(nn.Module):
-    """
-    Gumbel Sinkhorn Layer turns the input matrix into a bi-stochastic matrix.
-    See details in `"Mena et al. Learning Latent Permutations with Gumbel-Sinkhorn Networks. ICLR 2018"
-    <https://arxiv.org/abs/1802.08665>`_
-
-    :param max_iter: maximum iterations (default: ``10``)
-    :param tau: the hyper parameter :math:`\tau` controlling the temperature (default: ``1``)
-    :param epsilon: a small number for numerical stability (default: ``1e-4``)
-    :param batched_operation: apply batched_operation for better efficiency (but may cause issues for back-propagation,
-     default: ``False``)
-
-    .. note::
-        This module only supports log-scale Sinkhorn operation.
-    """
-    def __init__(self, max_iter=10, tau=1., epsilon=1e-4, batched_operation=False):
-        super(GumbelSinkhorn, self).__init__()
-        self.sinkhorn = Sinkhorn(max_iter, tau, epsilon, batched_operation=batched_operation)
-
-    def forward(self, s: Tensor, nrows: Tensor=None, ncols: Tensor=None,
-                sample_num=5, dummy_row=False) -> Tensor:
-        r"""
-        :param s: :math:`(b\times n_1 \times n_2)` input 3d tensor. :math:`b`: batch size
-        :param nrows: :math:`(b)` number of objects in dim1
-        :param ncols: :math:`(b)` number of objects in dim2
-        :param sample_num: number of samples
-        :param dummy_row: whether to add dummy rows (rows whose elements are all 0) to pad the matrix to square matrix.
-         default: ``False``
-        :return: :math:`(b m\times n_1 \times n_2)` the computed doubly-stochastic matrix. :math:`m`: number of samples
-         (``sample_num``)
-
-        The samples are stacked at the fist dimension of the output tensor. You may reshape the output tensor ``s`` as:
-
-        ::
-
-            s = torch.reshape(s, (-1, sample_num, s.shape[1], s.shape[2]))
-
-        .. note::
-            We support batched instances with different number of nodes, therefore ``nrows`` and ``ncols`` are
-            required to specify the exact number of objects of each dimension in the batch. If not specified, we assume
-            the batched matrices are not padded.
-
-        .. note::
-            The original Sinkhorn algorithm only works for square matrices. To handle cases where the graphs to be
-            matched have different number of nodes, it is a common practice to add dummy rows to construct a square
-            matrix. After the row and column normalizations, the padded rows are discarded.
-
-        .. note::
-            We assume row number <= column number. If not, the input matrix will be transposed.
-        """
-        def sample_gumbel(t_like, eps=1e-20):
-            """
-            randomly sample standard gumbel variables
-            """
-            u = torch.empty_like(t_like).uniform_()
-            return -torch.log(-torch.log(u + eps) + eps)
-
-        s_rep = torch.repeat_interleave(s, sample_num, dim=0)
-        s_rep = s_rep + sample_gumbel(s_rep)
-        nrows_rep = torch.repeat_interleave(nrows, sample_num, dim=0)
-        ncols_rep = torch.repeat_interleave(ncols, sample_num, dim=0)
-        s_rep = self.sinkhorn(s_rep, nrows_rep, ncols_rep, dummy_row)
-        #s_rep = torch.reshape(s_rep, (-1, sample_num, s_rep.shape[1], s_rep.shape[2]))
-        return s_rep
-
-
-if __name__ == '__main__':
-    bs = Sinkhorn(max_iter=8, epsilon=1e-4)
-    inp = torch.tensor([[[1., 0, 1.],
-                         [1., 0, 3.],
-                         [2., 0, 1.],
-                         [4., 0, 2.]]], requires_grad=True)
-    outp = bs(inp, (3, 4))
-
-    print(outp)
-    l = torch.sum(outp)
-    l.backward()
-    print(inp.grad * 1e10)
-
-    outp2 = torch.tensor([[0.1, 0.1, 1],
-                          [2, 3, 4.]], requires_grad=True)
-
-    l = torch.sum(outp2)
-    l.backward()
-    print(outp2.grad)
diff --git a/COMMON/src/loss_func.py b/COMMON/src/loss_func.py
deleted file mode 100644
index b50c8ef..0000000
--- a/COMMON/src/loss_func.py
+++ /dev/null
@@ -1,489 +0,0 @@
-import torch
-import torch.nn as nn
-import torch.nn.functional as F
-from src.lap_solvers.hungarian import hungarian
-from src.lap_solvers.ILP import ILP_solver
-from torch import Tensor
-
-
-class PermutationLoss(nn.Module):
-    r"""
-    Binary cross entropy loss between two permutations, also known as "permutation loss".
-    Proposed by `"Wang et al. Learning Combinatorial Embedding Networks for Deep Graph Matching. ICCV 2019."
-    <http://openaccess.thecvf.com/content_ICCV_2019/papers/Wang_Learning_Combinatorial_Embedding_Networks_for_Deep_Graph_Matching_ICCV_2019_paper.pdf>`_
-
-    .. math::
-        L_{perm} =- \sum_{i \in \mathcal{V}_1, j \in \mathcal{V}_2}
-        \left(\mathbf{X}^{gt}_{i,j} \log \mathbf{S}_{i,j} + (1-\mathbf{X}^{gt}_{i,j}) \log (1-\mathbf{S}_{i,j}) \right)
-
-    where :math:`\mathcal{V}_1, \mathcal{V}_2` are vertex sets for two graphs.
-
-    .. note::
-        For batched input, this loss function computes the averaged loss among all instances in the batch.
-    """
-    def __init__(self):
-        super(PermutationLoss, self).__init__()
-
-    def forward(self, pred_dsmat: Tensor, gt_perm: Tensor, src_ns: Tensor, tgt_ns: Tensor) -> Tensor:
-        r"""
-        :param pred_dsmat: :math:`(b\times n_1 \times n_2)` predicted doubly-stochastic matrix :math:`(\mathbf{S})`
-        :param gt_perm: :math:`(b\times n_1 \times n_2)` ground truth permutation matrix :math:`(\mathbf{X}^{gt})`
-        :param src_ns: :math:`(b)` number of exact pairs in the first graph (also known as source graph).
-        :param tgt_ns: :math:`(b)` number of exact pairs in the second graph (also known as target graph).
-        :return: :math:`(1)` averaged permutation loss
-
-        .. note::
-            We support batched instances with different number of nodes, therefore ``src_ns`` and ``tgt_ns`` are
-            required to specify the exact number of nodes of each instance in the batch.
-        """
-        batch_num = pred_dsmat.shape[0]
-
-        pred_dsmat = pred_dsmat.to(dtype=torch.float32)
-
-        try:
-            assert torch.all((pred_dsmat >= 0) * (pred_dsmat <= 1))
-            assert torch.all((gt_perm >= 0) * (gt_perm <= 1))
-        except AssertionError as err:
-            print(pred_dsmat)
-            raise err
-
-        loss = torch.tensor(0.).to(pred_dsmat.device)
-        n_sum = torch.zeros_like(loss)
-        for b in range(batch_num):
-            batch_slice = [b, slice(src_ns[b]), slice(tgt_ns[b])]
-            loss += F.binary_cross_entropy(
-                pred_dsmat[batch_slice],
-                gt_perm[batch_slice],
-                reduction='sum')
-            n_sum += src_ns[b].to(n_sum.dtype).to(pred_dsmat.device)
-
-        return loss / n_sum
-
-
-class CrossEntropyLoss(nn.Module):
-    r"""
-    Multi-class cross entropy loss between two permutations.
-
-    .. math::
-        L_{ce} =- \sum_{i \in \mathcal{V}_1, j \in \mathcal{V}_2} \left(\mathbf{X}^{gt}_{i,j} \log \mathbf{S}_{i,j}\right)
-
-    where :math:`\mathcal{V}_1, \mathcal{V}_2` are vertex sets for two graphs.
-
-    .. note::
-        For batched input, this loss function computes the averaged loss among all instances in the batch.
-    """
-    def __init__(self):
-        super(CrossEntropyLoss, self).__init__()
-
-    def forward(self, pred_dsmat: Tensor, gt_perm: Tensor, src_ns: Tensor, tgt_ns: Tensor) -> Tensor:
-        r"""
-        :param pred_dsmat: :math:`(b\times n_1 \times n_2)` predicted doubly-stochastic matrix :math:`(\mathbf{S})`
-        :param gt_perm: :math:`(b\times n_1 \times n_2)` ground truth permutation matrix :math:`(\mathbf{X}^{gt})`
-        :param src_ns: :math:`(b)` number of exact pairs in the first graph (also known as source graph).
-        :param tgt_ns: :math:`(b)` number of exact pairs in the second graph (also known as target graph).
-        :return: :math:`(1)` averaged cross-entropy loss
-
-        .. note::
-            We support batched instances with different number of nodes, therefore ``src_ns`` and ``tgt_ns`` are
-            required to specify the exact number of nodes of each instance in the batch.
-        """
-        batch_num = pred_dsmat.shape[0]
-
-        pred_dsmat = pred_dsmat.to(dtype=torch.float32)
-
-        try:
-            assert torch.all((pred_dsmat >= 0) * (pred_dsmat <= 1))
-            assert torch.all((gt_perm >= 0) * (gt_perm <= 1))
-        except AssertionError as err:
-            print(pred_dsmat)
-            raise err
-
-        loss = torch.tensor(0.).to(pred_dsmat.device)
-        n_sum = torch.zeros_like(loss)
-        for b in range(batch_num):
-            batch_slice = [b, slice(src_ns[b]), slice(tgt_ns[b])]
-            gt_index = torch.max(gt_perm[batch_slice], dim=-1).indices
-            loss += F.nll_loss(
-                torch.log(pred_dsmat[batch_slice]),
-                gt_index,
-                reduction='sum')
-            n_sum += src_ns[b].to(n_sum.dtype).to(pred_dsmat.device)
-
-        return loss / n_sum
-
-
-class PermutationLossHung(nn.Module):
-    r"""
-    Binary cross entropy loss between two permutations with Hungarian attention. The vanilla version without Hungarian
-    attention is :class:`~src.loss_func.PermutationLoss`.
-
-    .. math::
-        L_{hung} &=-\sum_{i\in\mathcal{V}_1,j\in\mathcal{V}_2}\mathbf{Z}_{ij}\left(\mathbf{X}^\text{gt}_{ij}\log \mathbf{S}_{ij}+\left(1-\mathbf{X}^{\text{gt}}_{ij}\right)\log\left(1-\mathbf{S}_{ij}\right)\right) \\
-        \mathbf{Z}&=\mathrm{OR}\left(\mathrm{Hungarian}(\mathbf{S}),\mathbf{X}^\text{gt}\right)
-
-    where :math:`\mathcal{V}_1, \mathcal{V}_2` are vertex sets for two graphs.
-
-    Hungarian attention highlights the entries where the model makes wrong decisions after the Hungarian step (which is
-    the default discretization step during inference).
-
-    Proposed by `"Yu et al. Learning deep graph matching with channel-independent embedding and Hungarian attention.
-    ICLR 2020." <https://openreview.net/forum?id=rJgBd2NYPH>`_
-
-    .. note::
-        For batched input, this loss function computes the averaged loss among all instances in the batch.
-
-    A working example for Hungarian attention:
-
-    .. image:: ../../images/hungarian_attention.png
-    """
-    def __init__(self):
-        super(PermutationLossHung, self).__init__()
-
-    def forward(self, pred_dsmat: Tensor, gt_perm: Tensor, src_ns: Tensor, tgt_ns: Tensor) -> Tensor:
-        r"""
-        :param pred_dsmat: :math:`(b\times n_1 \times n_2)` predicted doubly-stochastic matrix :math:`(\mathbf{S})`
-        :param gt_perm: :math:`(b\times n_1 \times n_2)` ground truth permutation matrix :math:`(\mathbf{X}^{gt})`
-        :param src_ns: :math:`(b)` number of exact pairs in the first graph (also known as source graph).
-        :param tgt_ns: :math:`(b)` number of exact pairs in the second graph (also known as target graph).
-        :return: :math:`(1)` averaged permutation loss
-
-        .. note::
-            We support batched instances with different number of nodes, therefore ``src_ns`` and ``tgt_ns`` are
-            required to specify the exact number of nodes of each instance in the batch.
-        """
-        batch_num = pred_dsmat.shape[0]
-
-        assert torch.all((pred_dsmat >= 0) * (pred_dsmat <= 1))
-        assert torch.all((gt_perm >= 0) * (gt_perm <= 1))
-
-        dis_pred = hungarian(pred_dsmat, src_ns, tgt_ns)
-        ali_perm = dis_pred + gt_perm
-        ali_perm[ali_perm > 1.0] = 1.0 # Hung
-        pred_dsmat = torch.mul(ali_perm, pred_dsmat)
-        gt_perm = torch.mul(ali_perm, gt_perm)
-        loss = torch.tensor(0.).to(pred_dsmat.device)
-        n_sum = torch.zeros_like(loss)
-        for b in range(batch_num):
-            loss += F.binary_cross_entropy(
-                pred_dsmat[b, :src_ns[b], :tgt_ns[b]],
-                gt_perm[b, :src_ns[b], :tgt_ns[b]],
-                reduction='sum')
-            n_sum += src_ns[b].to(n_sum.dtype).to(pred_dsmat.device)
-        return loss / n_sum
-
-
-class OffsetLoss(nn.Module):
-    r"""
-    OffsetLoss Criterion computes a robust loss function based on image pixel offset.
-    Proposed by `"Zanfir et al. Deep Learning of Graph Matching. CVPR 2018."
-    <http://openaccess.thecvf.com/content_cvpr_2018/html/Zanfir_Deep_Learning_of_CVPR_2018_paper.html>`_
-
-    .. math::
-        \mathbf{d}_i =& \sum_{j \in V_2} \left( \mathbf{S}_{i, j} P_{2j} \right)- P_{1i} \\
-        L_{off} =& \sum_{i \in V_1} \sqrt{||\mathbf{d}_i - \mathbf{d}^{gt}_i||^2 + \epsilon}
-
-    :math:`\mathbf{d}_i` is the displacement vector. See :class:`src.displacement_layer.Displacement` or more details
-
-    :param epsilon: a small number for numerical stability
-    :param norm: (optional) division taken to normalize the loss
-    """
-    def __init__(self, epsilon: float=1e-5, norm=None):
-        super(OffsetLoss, self).__init__()
-        self.epsilon = epsilon
-        self.norm = norm
-
-    def forward(self, d1: Tensor, d2: Tensor, mask: float=None) -> Tensor:
-        """
-        :param d1: predicted displacement matrix
-        :param d2: ground truth displacement matrix
-        :param mask: (optional) dummy node mask
-        :return: computed offset loss
-        """
-        # Loss = Sum(Phi(d_i - d_i^gt))
-        # Phi(x) = sqrt(x^T * x + epsilon)
-        if mask is None:
-            mask = torch.ones_like(mask)
-        x = d1 - d2
-        if self.norm is not None:
-            x = x / self.norm
-
-        xtx = torch.sum(x * x * mask, dim=-1)
-        phi = torch.sqrt(xtx + self.epsilon)
-        loss = torch.sum(phi) / d1.shape[0]
-
-        return loss
-
-
-class FocalLoss(nn.Module):
-    r"""
-    Focal loss between two permutations.
-
-    .. math::
-        L_{focal} =- \sum_{i \in \mathcal{V}_1, j \in \mathcal{V}_2}
-        \left((1-\mathbf{S}_{i,j})^{\gamma} \mathbf{X}^{gt}_{i,j} \log \mathbf{S}_{i,j} +
-        \mathbf{S}_{i,j}^{\gamma} (1-\mathbf{X}^{gt}_{i,j}) \log (1-\mathbf{S}_{i,j}) \right)
-
-    where :math:`\mathcal{V}_1, \mathcal{V}_2` are vertex sets for two graphs, :math:`\gamma` is the focal loss
-    hyper parameter.
-
-    :param gamma: :math:`\gamma` parameter for focal loss
-    :param eps: a small parameter for numerical stability
-
-    .. note::
-        For batched input, this loss function computes the averaged loss among all instances in the batch.
-    """
-    def __init__(self, gamma=0., eps=1e-15):
-        super(FocalLoss, self).__init__()
-        self.gamma = gamma
-        self.eps = eps
-
-    def forward(self, pred_dsmat: Tensor, gt_perm: Tensor, src_ns: Tensor, tgt_ns: Tensor) -> Tensor:
-        r"""
-        :param pred_dsmat: :math:`(b\times n_1 \times n_2)` predicted doubly-stochastic matrix :math:`(\mathbf{S})`
-        :param gt_perm: :math:`(b\times n_1 \times n_2)` ground truth permutation matrix :math:`(\mathbf{X}^{gt})`
-        :param src_ns: :math:`(b)` number of exact pairs in the first graph (also known as source graph).
-        :param tgt_ns: :math:`(b)` number of exact pairs in the second graph (also known as target graph).
-        :return: :math:`(1)` averaged focal loss
-
-        .. note::
-            We support batched instances with different number of nodes, therefore ``src_ns`` and ``tgt_ns`` are
-            required to specify the exact number of nodes of each instance in the batch.
-        """
-        batch_num = pred_dsmat.shape[0]
-
-        pred_dsmat = pred_dsmat.to(dtype=torch.float32)
-
-        assert torch.all((pred_dsmat >= 0) * (pred_dsmat <= 1))
-        assert torch.all((gt_perm >= 0) * (gt_perm <= 1))
-
-        loss = torch.tensor(0.).to(pred_dsmat.device)
-        n_sum = torch.zeros_like(loss)
-        for b in range(batch_num):
-            x = pred_dsmat[b, :src_ns[b], :tgt_ns[b]]
-            y = gt_perm[b, :src_ns[b], :tgt_ns[b]]
-            loss += torch.sum(
-                - (1 - x) ** self.gamma * y * torch.log(x + self.eps)
-                - x ** self.gamma * (1 - y) * torch.log(1 - x + self.eps)
-            )
-            n_sum += src_ns[b].to(n_sum.dtype).to(pred_dsmat.device)
-
-        return loss / n_sum
-
-
-class InnerProductLoss(nn.Module):
-    r"""
-    Inner product loss for self-supervised problems.
-
-    .. math::
-        L_{ce} =- \sum_{i \in \mathcal{V}_1, j \in \mathcal{V}_2} \left(\mathbf{X}^{gt}_{i,j} \mathbf{S}_{i,j}\right)
-
-    where :math:`\mathcal{V}_1, \mathcal{V}_2` are vertex sets for two graphs.
-
-    .. note::
-        For batched input, this loss function computes the averaged loss among all instances in the batch.
-    """
-    def __init__(self):
-        super(InnerProductLoss, self).__init__()
-
-    def forward(self, pred_dsmat: Tensor, gt_perm: Tensor, src_ns: Tensor, tgt_ns: Tensor) -> Tensor:
-        r"""
-        :param pred_dsmat: :math:`(b\times n_1 \times n_2)` predicted doubly-stochastic matrix :math:`(\mathbf{S})`
-        :param gt_perm: :math:`(b\times n_1 \times n_2)` ground truth permutation matrix :math:`(\mathbf{X}^{gt})`
-        :param src_ns: :math:`(b)` number of exact pairs in the first graph (also known as source graph).
-        :param tgt_ns: :math:`(b)` number of exact pairs in the second graph (also known as target graph).
-        :return: :math:`(1)` averaged inner product loss
-
-        .. note::
-            We support batched instances with different number of nodes, therefore ``src_ns`` and ``tgt_ns`` are
-            required to specify the exact number of nodes of each instance in the batch.
-        """
-        batch_num = pred_dsmat.shape[0]
-
-        pred_dsmat = pred_dsmat.to(dtype=torch.float32)
-
-        try:
-            assert torch.all((gt_perm >= 0) * (gt_perm <= 1))
-        except AssertionError as err:
-            raise err
-
-        loss = torch.tensor(0.).to(pred_dsmat.device)
-        n_sum = torch.zeros_like(loss)
-        for b in range(batch_num):
-            batch_slice = [b, slice(src_ns[b]), slice(tgt_ns[b])]
-            loss -= torch.sum(pred_dsmat[batch_slice] * gt_perm[batch_slice])
-            n_sum += src_ns[b].to(n_sum.dtype).to(pred_dsmat.device)
-
-        return loss / n_sum
-
-
-class HammingLoss(torch.nn.Module):
-    r"""
-    Hamming loss between two permutations.
-
-    .. math::
-        L_{hamm} = \sum_{i \in \mathcal{V}_1, j \in \mathcal{V}_2}
-        \left(\mathbf{X}_{i,j} (1-\mathbf{X}^{gt}_{i,j}) +  (1-\mathbf{X}_{i,j}) \mathbf{X}^{gt}_{i,j}\right)
-
-    where :math:`\mathcal{V}_1, \mathcal{V}_2` are vertex sets for two graphs.
-
-    Firstly adopted by `"Rolinek et al. Deep Graph Matching via Blackbox Differentiation of Combinatorial Solvers.
-    ECCV 2020." <https://arxiv.org/abs/2003.11657>`_
-
-    .. note::
-        Hamming loss is defined between two discrete matrices, and discretization will in general truncate gradient. A
-        workaround may be using the `blackbox differentiation technique <https://arxiv.org/abs/1912.02175>`_.
-    """
-    def __init__(self):
-        super(HammingLoss, self).__init__()
-
-    def forward(self, pred_perm: Tensor, gt_perm: Tensor) -> Tensor:
-        r"""
-        :param pred_perm: :math:`(b\times n_1 \times n_2)` predicted permutation matrix :math:`(\mathbf{X})`
-        :param gt_perm: :math:`(b\times n_1 \times n_2)` ground truth permutation matrix :math:`(\mathbf{X}^{gt})`
-        :return:
-        """
-        errors = pred_perm * (1.0 - gt_perm) + (1.0 - pred_perm) * gt_perm
-        return errors.mean(dim=0).sum()
-
-
-class ILP_attention_loss(nn.Module):
-    r"""
-    Integer Linear Programming (ILP) attention loss between two permutations.
-    Proposed by `"Jiang et al. Graph-Context Attention Networks for Size-Varied Deep Graph Matching. CVPR 2022."
-    <https://openaccess.thecvf.com/content/CVPR2022/html/Jiang_Graph-Context_Attention_Networks_for_Size-Varied_Deep_Graph_Matching_CVPR_2022_paper.html>`_
-
-    .. math::
-        L_{perm} =- \sum_{i \in \mathcal{V}_1, j \in \mathcal{V}_2}
-        \left( \max\left(a_{i,j}, \mathbf{X}^{gt}_{i,j} \right) \log \mathbf{S}_{i,j} + (1-\mathbf{X}^{gt}_{i,j}) \log (1-\mathbf{S}_{i,j}) \right)
-
-    where :math:`\mathcal{V}_1, \mathcal{V}_2` are vertex sets for two graphs, and a_{i,j} is the ILP assignment result.
-
-    .. note::
-        For batched input, this loss function computes the averaged loss among all instances in the batch.
-    """
-    def __init__(self, varied_size=True):
-        super(ILP_attention_loss, self).__init__()
-        self.varied_size = varied_size
-
-    def forward(self, pred_dsmat: Tensor, gt_perm: Tensor, src_ns: Tensor, tgt_ns: Tensor) -> Tensor:
-        r"""
-        :param pred_dsmat: :math:`(b\times n_1 \times n_2)` predicted doubly-stochastic matrix :math:`(\mathbf{S})`
-        :param gt_perm: :math:`(b\times n_1 \times n_2)` ground truth permutation matrix :math:`(\mathbf{X}^{gt})`
-        :param src_ns: :math:`(b)` number of exact pairs in the first graph (also known as source graph).
-        :param tgt_ns: :math:`(b)` number of exact pairs in the second graph (also known as target graph).
-        :return: :math:`(1)` averaged permutation loss
-
-        .. note::
-            We support batched instances with different number of nodes, therefore ``src_ns`` and ``tgt_ns`` are
-            required to specify the exact number of nodes of each instance in the batch.
-        """
-        batch_num = pred_dsmat.shape[0]
-
-        pred_dsmat = pred_dsmat.to(dtype=torch.float32)
-
-        try:
-            assert torch.all((gt_perm >= 0) * (gt_perm <= 1))
-        except AssertionError as err:
-            print(pred_dsmat)
-            raise err
-
-        if self.varied_size:
-            dis_pred = ILP_solver(pred_dsmat+1, src_ns+1, tgt_ns+1, dummy=True)
-        else:
-            dis_pred = ILP_solver(pred_dsmat, src_ns, tgt_ns)
-        ali_perm = dis_pred + gt_perm
-        ali_perm[ali_perm >= 1.0] = 1
-        pred_dsmat = torch.mul(ali_perm, pred_dsmat)
-        gt_perm = torch.mul(ali_perm, gt_perm)
-
-        loss = torch.tensor(0.).to(pred_dsmat.device)
-        n_sum = torch.zeros_like(loss)
-        for b in range(batch_num):
-            batch_slice = [b, slice(src_ns[b]), slice(tgt_ns[b])]
-            loss += F.binary_cross_entropy(
-                pred_dsmat[batch_slice],
-                gt_perm[batch_slice],
-                reduction='sum')
-            n_sum += src_ns[b].to(n_sum.dtype).to(pred_dsmat.device)
-
-        return loss / n_sum
-
-
-class Distill_InfoNCE(torch.nn.Module):
-    def __init__(self):
-        super(Distill_InfoNCE, self).__init__()
-
-    def forward(self, feature: Tensor, feature_m: Tensor, alpha: float, dynamic_temperature: Tensor,
-                dynamic_temperature_m: Tensor) -> Tensor:
-        graph1_feat = F.normalize(feature[0], dim=-1)
-        graph2_feat = F.normalize(feature[1], dim=-1)
-
-        # following the contrastive in "Learning Transferable Visual Models From Natural Language Supervision"
-        sim_1to2 = dynamic_temperature.exp() * graph1_feat @ graph2_feat.T
-        sim_2to1 = dynamic_temperature.exp() * graph2_feat @ graph1_feat.T
-
-        # get momentum features
-        with torch.no_grad():
-            graph1_feat_m = F.normalize(feature_m[0], dim=-1)
-            graph2_feat_m = F.normalize(feature_m[1], dim=-1)
-
-            # momentum similiarity
-            sim_1to2_m = dynamic_temperature_m.exp() * graph1_feat_m @ graph2_feat_m.T
-            sim_2to1_m = dynamic_temperature_m.exp() * graph2_feat_m @ graph1_feat_m.T
-            sim_1to2_m = F.softmax(sim_1to2_m, dim=1)
-            sim_2to1_m = F.softmax(sim_2to1_m, dim=1)
-
-            # online similiarity
-            sim_targets = torch.zeros(sim_1to2_m.size()).to(graph1_feat.device)
-            sim_targets.fill_diagonal_(1)
-
-            # generate pseudo contrastive labels
-            sim_1to2_targets = alpha * sim_1to2_m + (1 - alpha) * sim_targets
-            sim_2to1_targets = alpha * sim_2to1_m + (1 - alpha) * sim_targets
-
-        loss_i2t = -torch.sum(F.log_softmax(sim_1to2, dim=1) * sim_1to2_targets, dim=1).mean()
-        loss_t2i = -torch.sum(F.log_softmax(sim_2to1, dim=1) * sim_2to1_targets, dim=1).mean()
-        contrast_loss = (loss_i2t + loss_t2i) / 2
-        return contrast_loss
-
-
-class Distill_QuadraticContrast(torch.nn.Module):
-    def __init__(self):
-        super(Distill_QuadraticContrast, self).__init__()
-
-    def normalize(self, x: Tensor):
-        x = (x - x.min()) / (x.max() - x.min())
-        return x
-
-    def forward(self, feature: Tensor, feature_m: Tensor, dynamic_temperature: Tensor,
-                dynamic_temperature_m: Tensor) -> Tensor:
-        graph1_feat = F.normalize(feature[0], dim=-1)
-        graph2_feat = F.normalize(feature[1], dim=-1)
-        batch_size = graph1_feat.shape[0]
-
-        with torch.no_grad():
-            graph1_feat_m = F.normalize(feature_m[0], dim=-1)
-            graph2_feat_m = F.normalize(feature_m[1], dim=-1)
-            sim_1to2_m = graph1_feat_m @ graph2_feat_m.T
-            w = ((torch.diag(sim_1to2_m) / sim_1to2_m.sum(dim=1)) + (
-                        torch.diag(sim_1to2_m) / sim_1to2_m.sum(dim=0))) / 2
-            # normalize w
-            w = self.normalize(w)
-            w = torch.mm(w.unsqueeze(1), w.unsqueeze(0))
-            w = self.normalize(w)
-
-        # cross-graph similarity
-        sim_1to2 = dynamic_temperature.exp() * graph1_feat @ graph2_feat.T
-        sim_2to1 = dynamic_temperature.exp() * graph2_feat @ graph1_feat.T
-        # within-graph similarity
-        sim_1to1 = dynamic_temperature.exp() * graph1_feat @ graph1_feat.T
-        sim_2to2 = dynamic_temperature.exp() * graph2_feat @ graph2_feat.T
-        # within-graph consistency
-        within_graph_loss = (w * (sim_1to1 - sim_2to2).square()).mean() * batch_size / \
-                            (dynamic_temperature.exp() * dynamic_temperature.exp()) # using batch_size to scale the loss
-        # cross-graph consistency
-        cross_graph_loss = (w * (sim_1to2 - sim_2to1).square()).mean() * batch_size / \
-                           (dynamic_temperature.exp() * dynamic_temperature.exp())
-        graph_loss = within_graph_loss + cross_graph_loss
-
-        return graph_loss
diff --git a/COMMON/src/parallel/__init__.py b/COMMON/src/parallel/__init__.py
deleted file mode 100644
index 68d3877..0000000
--- a/COMMON/src/parallel/__init__.py
+++ /dev/null
@@ -1,3 +0,0 @@
-from .data_parallel import *
-
-__all__ = ['DataParallel']
diff --git a/COMMON/src/parallel/data_parallel.py b/COMMON/src/parallel/data_parallel.py
deleted file mode 100644
index f88a141..0000000
--- a/COMMON/src/parallel/data_parallel.py
+++ /dev/null
@@ -1,16 +0,0 @@
-import torch.nn as nn
-from .scatter_gather import scatter_kwargs, gather
-
-
-class DataParallel(nn.DataParallel):
-    """
-    DataParallel wrapper with customized scatter/gather functions
-    """
-    def __init__(self, *args, **kwargs):
-        super(DataParallel, self).__init__(*args, **kwargs)
-
-    def scatter(self, inputs, kwargs, device_ids):
-        return scatter_kwargs(inputs, kwargs, device_ids, dim=self.dim)
-
-    def gather(self, outputs, output_device):
-        return gather(outputs, output_device, dim=self.dim)
diff --git a/COMMON/src/parallel/scatter_gather.py b/COMMON/src/parallel/scatter_gather.py
deleted file mode 100644
index 27f1fd1..0000000
--- a/COMMON/src/parallel/scatter_gather.py
+++ /dev/null
@@ -1,91 +0,0 @@
-import torch
-import torch.nn.parallel.scatter_gather as torch_
-from src.sparse_torch import CSRMatrix3d, CSCMatrix3d, concatenate
-
-
-def scatter(inputs, target_gpus, dim=0):
-    """
-    Slices tensors into approximately equal chunks and
-    distributes them across given GPUs. Duplicates
-    references to objects that are not tensors.
-    """
-    def scatter_map(obj):
-        if isinstance(obj, torch.Tensor):
-            return torch_.Scatter.apply(target_gpus, None, dim, obj)
-        if isinstance(obj, tuple) and len(obj) > 0:
-            return list(zip(*map(scatter_map, obj)))
-        if isinstance(obj, list) and len(obj) > 0:
-            return list(map(list, zip(*map(scatter_map, obj))))
-        if isinstance(obj, dict) and len(obj) > 0:
-            return list(map(type(obj), zip(*map(scatter_map, obj.items()))))
-
-        # modified here
-        if isinstance(obj, CSRMatrix3d) or isinstance(obj, CSCMatrix3d):
-            return scatter_sparse_matrix(target_gpus, obj)
-
-        return [obj for targets in target_gpus]
-
-    # After scatter_map is called, a scatter_map cell will exist. This cell
-    # has a reference to the actual function scatter_map, which has references
-    # to a closure that has a reference to the scatter_map cell (because the
-    # fn is recursive). To avoid this reference cycle, we set the function to
-    # None, clearing the cell
-    try:
-        return scatter_map(inputs)
-    finally:
-        scatter_map = None
-
-
-def scatter_kwargs(inputs, kwargs, target_gpus, dim=0):
-    """Scatter with support for kwargs dictionary"""
-    inputs = scatter(inputs, target_gpus, dim) if inputs else []
-    kwargs = scatter(kwargs, target_gpus, dim) if kwargs else []
-    if len(inputs) < len(kwargs):
-        inputs.extend([() for _ in range(len(kwargs) - len(inputs))])
-    elif len(kwargs) < len(inputs):
-        kwargs.extend([{} for _ in range(len(inputs) - len(kwargs))])
-    inputs = tuple(inputs)
-    kwargs = tuple(kwargs)
-    return inputs, kwargs
-
-
-def scatter_sparse_matrix(target_gpus, obj):
-    """Scatter for customized sparse matrix"""
-    def get_device(i):
-        return torch.device('cuda:{}'.format(i)) if i != -1 else torch.device('cpu')
-    step = len(obj) // len(target_gpus)
-    return tuple([obj[i:i+step].to(get_device(i // step)) for i in range(0, len(obj), step)])
-
-
-def gather(outputs, target_device, dim=0):
-    """
-    Gathers tensors from different GPUs on a specified device (-1 means the CPU).
-    """
-    def gather_map(outputs):
-        out = outputs[0]
-        if isinstance(out, torch.Tensor):
-            return torch_.Gather.apply(target_device, dim, *outputs)
-
-        # modified here
-        if isinstance(out, CSRMatrix3d) or isinstance(out, CSCMatrix3d):
-            return concatenate(*outputs, device=target_device)
-
-        if out is None:
-            return None
-        if isinstance(out, dict):
-            if not all((len(out) == len(d) for d in outputs)):
-                raise ValueError('All dicts must have the same number of keys')
-            return type(out)(((k, gather_map([d[k] for d in outputs]))
-                              for k in out))
-        if isinstance(out, int):
-            assert all([out == _ for _ in outputs])
-            return out
-
-        return type(out)(map(gather_map, zip(*outputs)))
-
-    # Recursive function calls like this create reference cycles.
-    # Setting the function to None clears the refcycle.
-    try:
-        return gather_map(outputs)
-    finally:
-        gather_map = None
diff --git a/COMMON/src/qap_solvers/__init__.py b/COMMON/src/qap_solvers/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/COMMON/src/qap_solvers/rrwhm.py b/COMMON/src/qap_solvers/rrwhm.py
deleted file mode 100644
index 2d826a3..0000000
--- a/COMMON/src/qap_solvers/rrwhm.py
+++ /dev/null
@@ -1,61 +0,0 @@
-import torch
-import torch.nn as nn
-
-from src.lap_solvers.sinkhorn import Sinkhorn as Sinkhorn
-
-
-class RRWHM(nn.Module):
-    """
-    RRWHM solver for hyper graph matching, implemented by tensor power iteration with Sinkhorn reweighted jumps.
-    Parameter: maximum iteration max_iter
-    Input: input tensor H
-           maximum size of source graph num_src
-           sizes of source graph in batch ns_src
-           sizes of target graph in batch ns_tgt
-           (optional) initialization vector v0. If not specified, v0 will be initialized with all 1.
-    Output: computed eigenvector v
-    """
-    def __init__(self, max_iter=50, sk_iter=20, alpha=0.2, beta=30):
-        super(RRWHM, self).__init__()
-        self.max_iter = max_iter
-        self.alpha = alpha
-        self.beta = beta
-        self.sk = Sinkhorn(max_iter=sk_iter,log_forward=False)
-
-    def forward(self, H, num_src, ns_src, ns_tgt, v0=None):
-        order = len(H.shape) - 1
-        sum_dims = [i+2 for i in range(order-1)]
-        d = H.sum(dim=sum_dims, keepdim=True)
-        dmax = d.max(dim=1, keepdim=True).values
-        H = H / dmax
-
-        batch_num = H.shape[0]
-        mn = H.shape[1]
-        if v0 is None:
-            v0 = torch.zeros(batch_num, num_src, mn // num_src, dtype=H.dtype, device=H.device)
-            for b in range(batch_num):
-                v0[b, 0:ns_src[b], 0:ns_tgt[b]] = torch.tensor(1.) / (ns_src[b] * ns_tgt[b])
-
-            v0 = v0.transpose(1, 2).reshape(batch_num, mn, 1)
-
-        v = v0
-        for i in range(self.max_iter):
-            H_red = H.unsqueeze(-1)
-            for o in range(order - 1):
-                v_shape = [v.shape[0]] + [1] * (order - 1 - o) + list(v.shape[1:])
-                H_red = torch.sum(torch.mul(H_red, v.view(*v_shape)), dim=-2)
-            v = H_red
-            last_v = v
-            n = torch.norm(v, p=1, dim=1, keepdim=True)
-            v = v / n
-            s = v.view(batch_num, -1, num_src).transpose(1, 2)
-            s = torch.exp(self.beta * s / s.max(dim=1, keepdim=True).values.max(dim=2, keepdim=True).values)
-
-            v = self.alpha * self.sk(s, ns_src, ns_tgt).transpose(1, 2).reshape(batch_num, mn, 1) + (1 - self.alpha) * v
-            n = torch.norm(v, p=1, dim=1, keepdim=True)
-            v = torch.matmul(v, 1 / n)
-
-            if torch.norm(v - last_v) < 1e-5:
-                break
-
-        return v.view(batch_num, -1)
diff --git a/COMMON/src/qap_solvers/rrwm.py b/COMMON/src/qap_solvers/rrwm.py
deleted file mode 100644
index d72348b..0000000
--- a/COMMON/src/qap_solvers/rrwm.py
+++ /dev/null
@@ -1,55 +0,0 @@
-import torch
-import torch.nn as nn
-
-from src.lap_solvers.sinkhorn import Sinkhorn as Sinkhorn
-
-
-class RRWM(nn.Module):
-    """
-    RRWM solver for graph matching (QAP), implemented by power iteration with Sinkhorn reweighted jumps.
-    Parameter: maximum iteration max_iter
-    Input: input matrix M
-           maximum size of source graph num_src
-           sizes of source graph in batch ns_src
-           sizes of target graph in batch ns_tgt
-           (optional) initialization vector v0. If not specified, v0 will be initialized with all 1.
-    Output: computed eigenvector v
-    """
-    def __init__(self, max_iter=50, sk_iter=20, alpha=0.2, beta=30):
-        super(RRWM, self).__init__()
-        self.max_iter = max_iter
-        self.alpha = alpha
-        self.beta = beta
-        self.sk = Sinkhorn(max_iter=sk_iter)
-
-    def forward(self, M, num_src, ns_src, ns_tgt, v0=None):
-        d = M.sum(dim=2, keepdim=True)
-        dmax = d.max(dim=1, keepdim=True).values
-        M = M / (dmax + d.min() * 1e-5)
-
-        batch_num = M.shape[0]
-        mn = M.shape[1]
-        if v0 is None:
-            v0 = torch.zeros(batch_num, num_src, mn // num_src, dtype=M.dtype, device=M.device)
-            for b in range(batch_num):
-                v0[b, 0:ns_src[b], 0:ns_tgt[b]] = torch.tensor(1.) / (ns_src[b] * ns_tgt[b])
-
-            v0 = v0.transpose(1, 2).reshape(batch_num, mn, 1)
-
-        v = v0
-        for i in range(self.max_iter):
-            v = torch.bmm(M, v)
-            last_v = v
-            n = torch.norm(v, p=1, dim=1, keepdim=True)
-            v = v / n
-            s = v.view(batch_num, -1, num_src).transpose(1, 2)
-            s = torch.exp(self.beta * s / s.max(dim=1, keepdim=True).values.max(dim=2, keepdim=True).values)
-
-            v = self.alpha * self.sk(torch.log(s), ns_src, ns_tgt).transpose(1, 2).reshape(batch_num, mn, 1) + (1 - self.alpha) * v
-            n = torch.norm(v, p=1, dim=1, keepdim=True)
-            v = torch.matmul(v, 1 / n)
-
-            if torch.norm(v - last_v) < 1e-5:
-                break
-
-        return v.view(batch_num, -1)
diff --git a/COMMON/src/qap_solvers/spectral_matching.py b/COMMON/src/qap_solvers/spectral_matching.py
deleted file mode 100644
index 1224884..0000000
--- a/COMMON/src/qap_solvers/spectral_matching.py
+++ /dev/null
@@ -1,50 +0,0 @@
-import torch
-import torch.nn as nn
-from src.utils.sparse import sbmm
-
-
-class SpectralMatching(nn.Module):
-    """
-    Spectral Graph Matching solver.
-    Also known as Power Iteration layer, which computes the leading eigenvector of input matrix.
-    For every iteration,
-        v_k+1 = M * v_k / ||M * v_k||_2
-    Parameter: maximum iteration max_iter
-    Input: input matrix M
-           (optional) initialization vector v0. If not specified, v0 will be initialized with all 1.
-    Output: computed eigenvector v
-    """
-    def __init__(self, max_iter=50, stop_thresh=2e-7):
-        super(SpectralMatching, self).__init__()
-        self.max_iter = max_iter
-        self.stop_thresh = stop_thresh
-
-    def forward(self, M, v0=None, **kwargs):
-        batch_num = M.shape[0]
-        mn = M.shape[1]
-        if v0 is None:
-            v0 = torch.ones(batch_num, mn, 1, dtype=M.dtype, device=M.device)
-
-        v = vlast = v0
-        for i in range(self.max_iter):
-            if M.is_sparse:
-                v = sbmm(M, v)
-            else:
-                v = torch.bmm(M, v)
-            n = torch.norm(v, p=2, dim=1)
-            v = torch.matmul(v, (1 / n).view(batch_num, 1, 1))
-            if torch.norm(v - vlast) < self.stop_thresh:
-                return v.view(batch_num, -1)
-            vlast = v
-
-        return v.view(batch_num, -1)
-
-
-if __name__ == '__main__':
-    from torch.autograd import gradcheck
-    input = (torch.randn(3, 40, 40, dtype=torch.double, requires_grad=True),)
-
-    pi = SpectralMatching()
-
-    test = gradcheck(pi, input, eps=1e-6, atol=1e-4)
-    print(test)
\ No newline at end of file
diff --git a/COMMON/src/sparse_torch/__init__.py b/COMMON/src/sparse_torch/__init__.py
deleted file mode 100644
index ee3bc16..0000000
--- a/COMMON/src/sparse_torch/__init__.py
+++ /dev/null
@@ -1,5 +0,0 @@
-"""
-sparse matrix in pytorch implementation.
-"""
-
-from .csx_matrix import CSRMatrix3d, CSCMatrix3d, dot, concatenate
diff --git a/COMMON/src/sparse_torch/csx_matrix.py b/COMMON/src/sparse_torch/csx_matrix.py
deleted file mode 100644
index 9cef6c2..0000000
--- a/COMMON/src/sparse_torch/csx_matrix.py
+++ /dev/null
@@ -1,479 +0,0 @@
-import sys
-import os
-import torch
-import numpy as np
-import scipy.sparse as ssp
-
-if 'SPHINX' not in os.environ:
-    from torch.utils.cpp_extension import load
-
-    sparse_dot = load(name='sparse_dot',
-                      sources=['src/extension/sparse_dot/sparse_dot.cpp',
-                               'src/extension/sparse_dot/csr_dot_csc_cuda.cu',
-                               'src/extension/sparse_dot/csr_dot_diag_cuda.cu'],
-                      extra_include_paths=[
-                          '/usr/include/python{}.{}/'.format(sys.version_info.major, sys.version_info.minor)]
-                      )
-
-
-class CSXMatrix3d:
-    def __init__(self, inp, shape, device=None):
-        def from_ssp(inp_s: list, shape, device=None, sptype=self.sptype):
-            """
-            Load data from list of scipy.sparse matrix
-            :param inp_s: list of input scipy.sparse matrix
-            :param shape: output matrix shape.
-            :param device: device. If not specified, it will be the same as input.
-            :param sptype: sparse matrix type. Should be 'csr' or 'csc'
-            """
-            assert len(shape) == 3, 'Only 3-dimensional tensor (bxhxw) is supported'
-            batch_num = shape[0]
-
-            indices = []
-            indptr = []
-            data = []
-            indptr_offset = 0
-
-            for b in range(batch_num):
-                if sptype == 'csc':
-                    inp_s[b].eliminate_zeros()
-                    sp = inp_s[b].tocsc().astype(dtype=inp_s[b].dtype)
-                elif sptype == 'csr':
-                    inp_s[b].eliminate_zeros()
-                    sp = inp_s[b].tocsr().astype(dtype=inp_s[b].dtype)
-                else:
-                    raise ValueError('Sparse type not understood {}'.format(sptype))
-
-                indices.append(sp.indices)
-                indptr.append(sp.indptr[:-1] + indptr_offset)
-                data.append(sp.data)
-                indptr_offset += sp.indptr[-1]
-            indptr.append(np.array([indptr_offset]))
-
-            return from_tensors(*[np.concatenate(x) for x in (indices, indptr, data)], shape=shape,
-                                device=device)
-
-        def from_tensors(ind: torch.Tensor or np.ndarray, indp: torch.Tensor or np.ndarray,
-                         data: torch.Tensor or np.ndarray, shape, device=None):
-            """
-            Load data from raw input tensors/arrays.
-            :param ind: indices array/tensor
-            :param indp: indptr array/tensor
-            :param data: data array/tensor
-            :param shape: output matrix shape.
-            :param device: device. Optional
-            :return: indices(Tensor), indptr(Tensor), data(Tensor), shape(tuple)
-            """
-            if type(ind) == torch.Tensor and device is None:
-                device = ind.device
-
-            if type(ind) is torch.Tensor:
-                indices_t = ind.to(torch.int64).to(device)
-            else:
-                indices_t = torch.tensor(ind, dtype=torch.int64, device=device)
-            if type(indp) is torch.Tensor:
-                indptr_t = indp.to(torch.int64).to(device)
-            else:
-                indptr_t = torch.tensor(indp, dtype=torch.int64, device=device)
-            if type(data) is torch.Tensor:
-                data_t = data.to(dtype=data.dtype).to(device)
-            else:
-                data_t = torch.tensor(data, device=device)
-
-            return indices_t, indptr_t, data_t, tuple(shape)
-
-        if type(inp) == list and isinstance(inp[0], ssp.spmatrix):
-            self.indices, self.indptr, self.data, self.shape = from_ssp(inp, shape, device)
-
-        elif type(inp) == list:
-            self.indices, self.indptr, self.data, self.shape = from_tensors(*inp, shape, device)
-
-        else:
-            raise ValueError('Data type {} not understood.'.format(type(inp)))
-
-    def __getitem__(self, item):
-        """
-        Get item through slicing. The slicing is only supported on the batch dimention
-        :param item: index or slice
-        :return: new sparse matrix
-        """
-        if isinstance(item, int):
-            indices, indptr, data = self.get_batch(item)
-            return self.__class__([indices, indptr, data], shape=[1] + list(self.shape[1:3]))
-        elif isinstance(item, slice):
-            indices = []
-            indptr = []
-            data = []
-            indptr_offset = int(0)
-            batch_iter = range(item.start, item.stop, item.step if item.step is not None else 1)
-            for b in batch_iter:
-                _indices, _indptr, _data = self.get_batch(b)
-                indices.append(_indices)
-                indptr.append(_indptr[:-1] + indptr_offset)
-                data.append(_data)
-                indptr_offset = indptr_offset + _indptr[-1]
-            assert isinstance(indptr_offset, torch.Tensor)
-            indptr.append(indptr_offset.view(1))
-
-            indices = torch.cat(indices)
-            indptr = torch.cat(indptr)
-            data = torch.cat(data)
-            return self.__class__([indices, indptr, data], shape=[len(batch_iter)] + list(self.shape[1:3]))
-        else:
-            raise ValueError('Index type {} not supported.'.format(type(item)))
-
-    def __len__(self):
-        return self.shape[0]
-
-    @property
-    def device(self):
-        return self.indices.device
-
-    @property
-    def sptype(self):
-        raise NotImplementedError
-
-    def transpose(self, keep_type=False):
-        raise NotImplementedError
-
-    def to(self, tgt):
-        """
-        Compatible to torch.Tensor.to()
-        :param tgt: target, can be torch.device or torch.dtype
-        :return: a new instance
-        """
-        if isinstance(tgt, torch.device):
-            return self.__class__([x.to(tgt) for x in [self.indices, self.indptr, self.data]], self.shape)
-        elif isinstance(tgt, torch.dtype):
-            return self.__class__([self.indices, self.indptr, self.data.to(tgt)], self.shape)
-        else:
-            raise ValueError('Data type not understood.')
-
-    def cuda(self):
-        """
-        Compatible to torch.Tensor.cuda()
-        :return: a new instance on CUDA
-        """
-        return self.__class__([x.cuda() for x in [self.indices, self.indptr, self.data]], self.shape)
-
-    def cpu(self):
-        """
-        Compatible to torch.Tensor.cpu()
-        :return: a new instance on CPU
-        """
-        return self.__class__([x.cpu() for x in [self.indices, self.indptr, self.data]], self.shape)
-
-    def numpy(self):
-        """
-        Return dense numpy array.
-        :return: dense numpy array.
-        """
-        ret = [x.toarray() for x in self.as_ssp()]
-        ret = np.stack(ret, axis=0)
-        return ret
-
-    def as_list(self, mask=None):
-        """
-        Return [indices, indptr, data] in a list.
-        :param mask: Optional. It should be an iterable containing 3 items, each indicating its corresponding attribute
-                     shall be masked out or not.
-        :return: [indices, indptr, data] * mask
-        """
-        attrs = [self.indices, self.indptr, self.data]
-        if mask is not None:
-            ret = []
-            for m, a in zip(mask, attrs):
-                if m:
-                    ret.append(a)
-        else:
-            ret = attrs
-        return ret
-
-    def as_ssp(self):
-        """
-        Return scipy.sparse matrix.
-        :return: list of scipy.sparse matrix
-        """
-        ret = []
-        for b in range(self.shape[0]):
-            indice, indptr, data = self.get_batch(b)
-            construct_func = ssp.csr_matrix if self.sptype == 'csr' else ssp.csc_matrix
-            ret.append(
-                construct_func(
-                    (data.cpu().to(dtype=data.dtype).numpy(),
-                     indice.cpu().numpy(),
-                     indptr.cpu().numpy()),
-                    shape=self.shape[1:3]
-                )
-            )
-        return ret
-
-    def as_sparse_torch(self):
-        coo = torch.zeros(3, self.data.shape[0], dtype=torch.long, device=self.device)
-        for b in range(self.shape[0]):
-            if self.sptype == 'csr':
-                start_ptr = b * self.shape[1]
-                end_ptr = (b + 1) * self.shape[1] + 1
-                compressed_len = self.shape[1]
-                compressed_idx = 1
-            elif self.sptype == 'csc':
-                start_ptr = b * self.shape[2]
-                end_ptr = (b + 1) * self.shape[2] + 1
-                compressed_len = self.shape[2]
-                compressed_idx = 2
-            else:
-                raise ValueError('Data type not understood.')
-            indptr = self.indptr[start_ptr: end_ptr]
-            coo[0, indptr[0]:indptr[-1]] = b
-            for i in range(compressed_len):
-                coo[compressed_idx, indptr[i]:indptr[i+1]] = i
-
-        if self.sptype == 'csr':
-            coo[2, :] = self.indices
-        else:
-            coo[1, :] = self.indices
-
-        return torch.sparse.FloatTensor(coo, self.data, self.shape)
-
-    def get_batch(self, item):
-        """
-        Get a certain batch in tuple (indices, indptr, data)
-        :param item: batch index
-        :return: (indices, indptr, data)
-        """
-        if type(item) != int:
-            raise IndexError('Only int indices is currently supported.')
-
-        if self.sptype == 'csr':
-            start_idx = item * self.shape[1]
-            end_idx = (item + 1) * self.shape[1] + 1
-        elif self.sptype == 'csc':
-            start_idx = item * self.shape[2]
-            end_idx = (item + 1) * self.shape[2] + 1
-        else:
-            raise ValueError('Data type not understood.')
-        indptr = self.indptr[start_idx: end_idx].clone()
-        indice = self.indices[indptr[0]: indptr[-1]].clone()
-        data = self.data[indptr[0]: indptr[-1]].clone()
-        indptr = indptr - indptr[0]
-        return indice, indptr, data
-
-    def shape_eq(self, other):
-        ret = True
-        for s_shape, o_shape in zip(self.shape, other.shape):
-            if s_shape != o_shape:
-                ret = False
-                break
-        return ret
-
-
-class CSCMatrix3d(CSXMatrix3d):
-    def __init__(self, inp, shape=None, device=None):
-        if type(inp) == list and isinstance(inp[0], ssp.spmatrix):
-            max_shape = [0, 0]
-            for s in inp:
-                max_shape[0] = max(max_shape[0], s.shape[0])
-                max_shape[1] = max(max_shape[1], s.shape[1])
-            if shape is None:
-                shape = tuple([len(inp)] + max_shape)
-            else:
-                assert shape[0] == len(inp)
-                assert shape[1] <= max_shape[0]
-                assert shape[2] <= max_shape[1]
-
-        elif type(inp) == list:
-            assert shape is not None
-            batch = shape[0]
-            row = _max(inp[0])
-            col = (len(inp[1]) - 1) // batch
-            assert shape[1] >= row
-            assert shape[2] == col
-
-        super(CSCMatrix3d, self).__init__(inp, shape, device)
-
-    @property
-    def sptype(self):
-        return 'csc'
-
-    def transpose(self, keep_type=False):
-        if not keep_type:
-            shape_t = list(self.shape)
-            tmp = shape_t[1]
-            shape_t[1] = shape_t[2]
-            shape_t[2] = tmp
-            return CSRMatrix3d(self.as_list(), shape=shape_t, device=self.device)
-        else:
-            coo = []
-            for sp in self.as_ssp():
-                coo.append(sp.transpose().tocoo().astype(sp.dtype))
-            return CSCMatrix3d(coo, device=self.device)
-
-    def Tdot(self, other, *args, **kwargs):
-        """
-        The dot result of a TRANSPOSED CSC matrix and another CSC matrix.
-        This is equivalent to CSR dot CSC.
-        :param other: second CSC matrix
-        :return: dot product in a new CSR matrix
-        """
-        t_csr = self.transpose()
-        return dot(t_csr, other, *args, **kwargs)
-
-
-class CSRMatrix3d(CSXMatrix3d):
-    def __init__(self, inp, shape=None, device=None):
-        if type(inp) == list and isinstance(inp[0], ssp.spmatrix):
-            max_shape = [0, 0]
-            for s in inp:
-                max_shape[0] = max(max_shape[0], s.shape[0])
-                max_shape[1] = max(max_shape[1], s.shape[1])
-            if shape is None:
-                shape = tuple([len(inp)] + max_shape)
-            else:
-                assert shape[0] == len(inp)
-                assert shape[1] <= max_shape[0]
-                assert shape[2] <= max_shape[1]
-
-        elif type(inp) == list:
-            assert shape is not None
-            batch = shape[0]
-            row = (len(inp[1]) - 1) // batch
-            col = _max(inp[0])
-            assert shape[1] == row
-            assert shape[2] >= col
-
-        super(CSRMatrix3d, self).__init__(inp, shape, device)
-
-    @property
-    def sptype(self):
-        return 'csr'
-
-    def transpose(self, keep_type=False):
-        if not keep_type:
-            shape_t = list(self.shape)
-            tmp = shape_t[1]
-            shape_t[1] = shape_t[2]
-            shape_t[2] = tmp
-            return CSCMatrix3d(self.as_list(), shape=shape_t, device=self.device)
-        else:
-            coo = []
-            for sp in self.as_ssp():
-                coo.append(sp.transpose().tocoo().astype(sp.dtype))
-            return CSRMatrix3d(coo, device=self.device)
-
-    def dot(self, other, *args, **kwargs):
-        """
-        Dot product of this CSR matrix and a CSC matrix.
-        :param other: CSC matrix.
-        :return: dot product in CSR matrix
-        """
-        return dot(self, other, *args, **kwargs)
-
-    def dotdiag(self, other):
-        """
-        Dot product of this CSR matrix and a diagonal matrix from a vector.
-        :param other: input vector.
-        :return: dot product in CSR matrix
-        """
-        assert self.shape[0] == other.shape[0], 'Batch size mismatch'
-        assert self.shape[2] == other.shape[1], 'Matrix shape mismatch'
-        batch_size = self.shape[0]
-        out_h = self.shape[1]
-        out_w = self.shape[2]
-
-        result = sparse_dot.csr_dot_diag(*self.as_list(), other, batch_size, out_h, out_w)
-        ret = CSRMatrix3d(result, shape=self.shape)
-        '''
-        indptr = self.indptr.clone()
-        indice = self.indices.clone()
-        data = self.data.clone()
-
-        for b in range(batch_size):
-            start_idx = b * self.shape[1]
-            end_idx = (b + 1) * self.shape[1] + 1
-            indp_b = indptr[start_idx: end_idx]
-            indx_b = indice[indp_b[0]: indp_b[-1]]
-            data_b = data[indp_b[0]: indp_b[-1]]
-
-            for j in range(self.shape[2]):
-                data_b[indx_b == j] *= other[b, j]
-
-        ret = CSRMatrix3d([indice, indptr, data], self.shape)
-        '''
-        return ret
-
-
-def dot(csr: CSRMatrix3d, csc: CSCMatrix3d, dense=False):
-    """
-    Compute the dot product of one CSR matrix and one CSC matrix. The result will be returned in a new CSR or dense
-    matrix. Note that CUDA implementations do not work when dense=False.
-    :param csr: fist input CSR matrix
-    :param csc: second input CSC matrix
-    :param dense: output matrix in dense format
-    :return: dot result in new csr matrix (dense=False) or
-             dot result in dense matrix (dense=True)
-    """
-    assert type(csr) == CSRMatrix3d
-    assert type(csc) == CSCMatrix3d
-    assert csr.shape[0] == csc.shape[0], 'Batch size mismatch'
-    batch_num = csr.shape[0]
-    assert csr.shape[2] == csc.shape[1], 'Matrix size mismatch'
-    out_h = csr.shape[1]
-    out_w = csc.shape[2]
-
-    if csr.indptr.device == torch.device('cpu'):
-        new_indices, new_indptr, new_data = \
-            sparse_dot.csr_dot_csc(*csr.as_list(), *csc.as_list(), batch_num, out_h, out_w)
-        ret = CSRMatrix3d([new_indices, new_indptr, new_data], shape=(batch_num, out_h, out_w))
-        if dense:
-            ret = ret.numpy()
-    else:
-        if not dense:
-            raise RuntimeWarning('Sparse dot product result in CUDA is not implemented.')
-        ret = sparse_dot.csr_dot_csc_dense_cuda(*csr.as_list(), *csc.as_list(), batch_num, out_h, out_w)
-    return ret
-
-
-def concatenate(*mats: CSXMatrix3d, device=None):
-    """
-    Concatenate multiple sparse matrix in first (batch) dimension.
-    :param mats: sequence of input matrix
-    :return: concatenated matrix
-    """
-    device = mats[0].device if device is None else device
-
-    mat_type = type(mats[0])
-    mat_h = mats[0].shape[1]
-    mat_w = mats[0].shape[2]
-    batch_size = 0
-
-    indptr_offset = 0
-    indices = []
-    indptr = []
-    data = []
-    for mat in mats:
-        assert type(mat) == mat_type, 'Matrix type inconsistent'
-        assert mat.shape[1] == mat_h, 'Matrix shape inconsistent in dimension 1'
-        assert mat.shape[2] == mat_w, 'Matrix shape inconsistent in dimension 2'
-        indices.append(mat.indices.clone().to(device))
-        indptr.append(mat.indptr[:-1].clone().to(device) + indptr_offset)
-        data.append(mat.data.clone().to(device))
-        indptr_offset += mat.indptr[-1].to(device)
-        indptr_offset = indptr_offset.to(device)
-        batch_size += mat.shape[0]
-
-    indptr.append(indptr_offset.view(1))
-
-    indices = torch.cat(indices)
-    indptr = torch.cat(indptr)
-    data = torch.cat(data)
-
-    return mat_type([indices, indptr, data], shape=(batch_size, mat_h, mat_w))
-
-
-def _max(inp, *args, **kwargs):
-    if type(inp) == np.ndarray:
-        return np.max(inp, *args, **kwargs)
-    elif type(inp) == torch.Tensor:
-        return torch.max(inp, *args, **kwargs)
-    else:
-        raise ValueError('Data type {} not understood.'.format(type(inp)))
diff --git a/COMMON/src/spectral_clustering.py b/COMMON/src/spectral_clustering.py
deleted file mode 100644
index f6c1d2f..0000000
--- a/COMMON/src/spectral_clustering.py
+++ /dev/null
@@ -1,237 +0,0 @@
-import numpy as np
-import torch
-from torch import Tensor
-from typing import Union, Tuple
-
-def initialize(X: Tensor, num_clusters: int, method: str='plus') -> np.array:
-    r"""
-    Initialize cluster centers.
-
-    :param X: matrix
-    :param num_clusters: number of clusters
-    :param method: denotes different initialization strategies: ``'plus'`` (default) or ``'random'``
-    :return: initial state
-
-    .. note::
-        We support two initialization strategies: random initialization by setting ``method='random'``, or `kmeans++
-        <https://en.wikipedia.org/wiki/K-means%2B%2B>`_ by setting ``method='plus'``.
-    """
-    if method == 'plus':
-        init_func = _initialize_plus
-    elif method == 'random':
-        init_func = _initialize_random
-    else:
-        raise NotImplementedError
-    return init_func(X, num_clusters)
-
-
-def _initialize_random(X, num_clusters):
-    """
-    Initialize cluster centers randomly. See :func:`src.spectral_clustering.initialize` for details.
-    """
-    num_samples = len(X)
-    indices = np.random.choice(num_samples, num_clusters, replace=False)
-    initial_state = X[indices]
-    return initial_state
-
-def _initialize_plus(X, num_clusters):
-    """
-    Initialize cluster centers by k-means++. See :func:`src.spectral_clustering.initialize` for details.
-    """
-    num_samples = len(X)
-    centroid_index = np.zeros(num_clusters)
-    for i in range(num_clusters):
-        if i == 0:
-            choice_prob = np.full(num_samples, 1 / num_samples)
-        else:
-            centroid_X = X[centroid_index[:i]]
-            dis = _pairwise_distance(X, centroid_X)
-            dis_to_nearest_centroid = torch.min(dis, dim=1).values
-            choice_prob = dis_to_nearest_centroid / torch.sum(dis_to_nearest_centroid)
-            choice_prob = choice_prob.detach().cpu().numpy()
-
-        centroid_index[i] = np.random.choice(num_samples, 1, p=choice_prob, replace=False)
-
-    initial_state = X[centroid_index]
-    return initial_state
-
-def kmeans(
-        X: Tensor,
-        num_clusters: int,
-        init_x: Union[Tensor, str]='plus',
-        distance: str='euclidean',
-        tol: float=1e-4,
-        device=torch.device('cpu'),
-) -> Tuple[Tensor, Tensor]:
-    r"""
-    Perform kmeans on given data matrix :math:`\mathbf X`.
-
-    :param X: :math:`(n\times d)` input data matrix. :math:`n`: number of samples. :math:`d`: feature dimension
-    :param num_clusters: (int) number of clusters
-    :param init_x: how to initiate x (provide a initial state of x or define a init method) [default: 'plus']
-    :param distance: distance [options: 'euclidean', 'cosine'] [default: 'euclidean']
-    :param tol: convergence threshold [default: 0.0001]
-    :param device: computing device [default: cpu]
-    :return: cluster ids, cluster centers
-    """
-    if distance == 'euclidean':
-        pairwise_distance_function = _pairwise_distance
-    elif distance == 'cosine':
-        pairwise_distance_function = _pairwise_cosine
-    else:
-        raise NotImplementedError
-
-    # convert to float
-    X = X.float()
-
-    # transfer to device
-    X = X.to(device)
-
-    # initialize
-    if type(init_x) is str:
-        initial_state = initialize(X, num_clusters, method=init_x)
-    else:
-        initial_state = init_x
-
-    iteration = 0
-    while True:
-        dis = pairwise_distance_function(X, initial_state)
-
-        choice_cluster = torch.argmin(dis, dim=1)
-
-        initial_state_pre = initial_state.clone()
-
-        for index in range(num_clusters):
-            selected = torch.nonzero(choice_cluster == index, as_tuple=False).squeeze().to(device)
-
-            selected = torch.index_select(X, 0, selected)
-            initial_state[index] = selected.mean(dim=0)
-
-        center_shift = torch.sum(
-            torch.sqrt(
-                torch.sum((initial_state - initial_state_pre) ** 2, dim=1)
-            ))
-
-        # increment iteration
-        iteration = iteration + 1
-
-        if center_shift ** 2 < tol:
-            break
-
-        if torch.isnan(initial_state).any():
-            print('NAN encountered in clustering. Retrying...')
-            initial_state = initialize(X, num_clusters)
-
-    return choice_cluster.cpu(), initial_state.cpu()
-
-
-def kmeans_predict(
-        X: Tensor,
-        cluster_centers: Tensor,
-        distance: str='euclidean',
-        device=torch.device('cpu')
-) -> Tensor:
-    r"""
-    Kmeans prediction using existing cluster centers.
-
-    :param X: matrix
-    :param cluster_centers: cluster centers
-    :param distance: distance [options: 'euclidean', 'cosine'] [default: 'euclidean']
-    :param device: computing device [default: 'cpu']
-    :return: cluster ids
-    """
-    if distance == 'euclidean':
-        pairwise_distance_function = _pairwise_distance
-    elif distance == 'cosine':
-        pairwise_distance_function = _pairwise_cosine
-    else:
-        raise NotImplementedError
-
-    # convert to float
-    X = X.float()
-
-    # transfer to device
-    X = X.to(device)
-
-    dis = pairwise_distance_function(X, cluster_centers)
-    choice_cluster = torch.argmin(dis, dim=1)
-
-    return choice_cluster.cpu()
-
-
-def _pairwise_distance(data1, data2, device=torch.device('cpu')):
-    """Compute pairwise Euclidean distance"""
-    # transfer to device
-    data1, data2 = data1.to(device), data2.to(device)
-
-    # N*1*M
-    A = data1.unsqueeze(dim=1)
-
-    # 1*N*M
-    B = data2.unsqueeze(dim=0)
-
-    dis = (A - B) ** 2.0
-    # return N*N matrix for pairwise distance
-    dis = dis.sum(dim=-1) #.squeeze(-1)
-    return dis
-
-
-def _pairwise_cosine(data1, data2, device=torch.device('cpu')):
-    """Compute pairwise cosine distance"""
-    # transfer to device
-    data1, data2 = data1.to(device), data2.to(device)
-
-    # N*1*M
-    A = data1.unsqueeze(dim=1)
-
-    # 1*N*M
-    B = data2.unsqueeze(dim=0)
-
-    # normalize the points  | [0.3, 0.4] -> [0.3/sqrt(0.09 + 0.16), 0.4/sqrt(0.09 + 0.16)] = [0.3/0.5, 0.4/0.5]
-    A_normalized = A / A.norm(dim=-1, keepdim=True)
-    B_normalized = B / B.norm(dim=-1, keepdim=True)
-
-    cosine = A_normalized * B_normalized
-
-    # return N*N matrix for pairwise distance
-    cosine_dis = 1 - cosine.sum(dim=-1).squeeze(-1)
-    return cosine_dis
-
-
-def spectral_clustering(sim_matrix: Tensor, cluster_num: int, init: Tensor=None,
-                        return_state: bool=False, normalized: bool=False):
-    r"""
-    Perform spectral clustering based on given similarity matrix.
-
-    This function firstly computes the leading eigenvectors of the given similarity matrix, and then utilizes the
-    eigenvectors as features and performs k-means clustering based on these features.
-
-    :param sim_matrix: :math:`(n\times n)` input similarity matrix. :math:`n`: number of instances
-    :param cluster_num: number of clusters
-    :param init: the initialization technique or initial features for k-means
-    :param return_state: whether return state features (can be further used for prediction)
-    :param normalized: whether to normalize the similarity matrix by its degree
-    :return: the belonging of each instance to clusters, state features (if ``return_state==True``)
-    """
-    degree = torch.diagflat(torch.sum(sim_matrix, dim=-1))
-    if normalized:
-        aff_matrix = (degree - sim_matrix) / torch.diag(degree).unsqueeze(1)
-    else:
-        aff_matrix = degree - sim_matrix
-    e, v = torch.symeig(aff_matrix, eigenvectors=True)
-    topargs = torch.argsort(torch.abs(e), descending=False)[1:cluster_num]
-    v = v[:, topargs]
-
-    if cluster_num == 2:
-        choice_cluster = (v > 0).to(torch.int).squeeze(1)
-    else:
-        choice_cluster, initial_state = kmeans(v, cluster_num, init if init is not None else 'plus',
-                                               distance='euclidean', tol=1e-6)
-
-    choice_cluster = choice_cluster.to(sim_matrix.device)
-
-    if return_state:
-        return choice_cluster, initial_state
-    else:
-        return choice_cluster
-
diff --git a/COMMON/src/utils/__init__.py b/COMMON/src/utils/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/COMMON/src/utils/config.py b/COMMON/src/utils/config.py
deleted file mode 100755
index 5b7b27a..0000000
--- a/COMMON/src/utils/config.py
+++ /dev/null
@@ -1,295 +0,0 @@
-"""Graph matching config system.
-This file specifies default config options for Fast R-CNN. You should not
-change values in this file. Instead, you should write a config file (in yaml)
-and use cfg_from_file(yaml_file) to load it and override the default options.
-Most tools in $ROOT/tools take a --cfg option to specify an override file.
-    - See tools/{train,test}_net.py for example code that uses cfg_from_file()
-    - See experiments/cfgs/*.yml for example YAML config override files
-"""
-
-import os
-from easydict import EasyDict as edict
-import numpy as np
-import importlib
-import src.dataset
-
-__C = edict()
-# Consumers can get config by:
-#   from config import cfg
-cfg = __C
-
-# Minibatch size
-__C.BATCH_SIZE = 4
-
-#
-# Problem settings. Set these parameters the same for fair comparison.
-#
-__C.PROBLEM = edict()
-
-# Problem type.
-# Candidates can be '2GM' (two graph matching), 'MGM' (multi-graph matching), 'MGMC' (multi-graph matching and clustering)
-__C.PROBLEM.TYPE = '2GM'
-
-# If UNSUPERVISED==True, ground truth permutations will not be provided during training.
-__C.PROBLEM.UNSUPERVISED = False
-
-# Rescaled image size
-__C.PROBLEM.RESCALE = (256, 256)
-
-# Filter of the keypoint. Chosen from 'intersection', 'inclusion', 'unfiltered'
-__C.PROBLEM.FILTER = 'intersection'
-
-# Do not include the problem if n_1 x n_2 > MAX_PROB_SIZE. -1 for no filtering
-__C.PROBLEM.MAX_PROB_SIZE = -1
-
-# # Allow outlier in source graph. Useful for 2GM
-# __C.PROBLEM.SRC_OUTLIER = False
-#
-# # Allow outlier in target graph. Useful for 2GM
-# __C.PROBLEM.TGT_OUTLIER = False
-
-# Number of graphs in a MGM/MGMC problem. Useful for MGM & MGMC
-# No effect if TEST_ALL_GRAPHS/TRAIN_ALL_GRAPHS=True
-__C.PROBLEM.NUM_GRAPHS = 3
-
-# Number of clusters in MGMC problem. Useful for MGMC
-__C.PROBLEM.NUM_CLUSTERS = 1
-
-# During testing, jointly match all graphs from the same class. Useful for MGM & MGMC
-__C.PROBLEM.TEST_ALL_GRAPHS = False
-
-# During training, jointly match all graphs from the same class. Useful for MGM & MGMC
-__C.PROBLEM.TRAIN_ALL_GRAPHS = False
-
-# Shape of candidates, useful for the setting in Zanfir et al CVPR2018
-#__C.PROBLEM.CANDIDATE_SHAPE = (16, 16)
-#__C.PROBLEM.CANDIDATE_LENGTH = np.cumprod(__C.PAIR.CANDIDATE_SHAPE)[-1]
-
-#
-# Graph construction settings.
-#
-__C.GRAPH = edict()
-
-# The ways of constructing source graph/target graph.
-# Candidates can be 'tri' (Delaunay triangulation), 'fc' (Fully-connected)
-__C.GRAPH.SRC_GRAPH_CONSTRUCT = 'tri'
-__C.GRAPH.TGT_GRAPH_CONSTRUCT = 'fc'
-
-# Build a symmetric adjacency matrix, else only the upper right triangle of adjacency matrix will be filled
-__C.GRAPH.SYM_ADJACENCY = True
-
-# Padding length on number of keypoints for batched operation
-__C.GRAPH.PADDING = 23
-
-#
-# Training options
-#
-
-__C.TRAIN = edict()
-
-# Iterations per epochs
-__C.TRAIN.EPOCH_ITERS = 7000
-
-# Training start epoch. If not 0, will be resumed from checkpoint.
-__C.TRAIN.START_EPOCH = 0
-
-# Total epochs
-__C.TRAIN.NUM_EPOCHS = 30
-
-# Optimizer type
-__C.TRAIN.OPTIMIZER = 'SGD'
-
-# Start learning rate
-__C.TRAIN.LR = 0.01
-
-# Use separate learning rate for the K regression module
-__C.TRAIN.SEPARATE_K_LR = False
-
-# Start learning rate for K regression module
-__C.TRAIN.K_LR = __C.TRAIN.LR
-
-# Use separate learning rate for the CNN backbone
-__C.TRAIN.SEPARATE_BACKBONE_LR = False
-
-# Start learning rate for backbone
-__C.TRAIN.BACKBONE_LR = __C.TRAIN.LR
-
-# Learning rate decay
-__C.TRAIN.LR_DECAY = 0.1
-
-# Learning rate decay step (in epochs)
-__C.TRAIN.LR_STEP = [10, 20]
-
-# SGD momentum
-__C.TRAIN.MOMENTUM = 0.9
-
-# RobustLoss normalization
-__C.TRAIN.RLOSS_NORM = max(__C.PROBLEM.RESCALE)
-
-# Specify a class for training
-__C.TRAIN.CLASS = 'none'
-
-# Loss function. Should be 'offset' or 'perm'
-__C.TRAIN.LOSS_FUNC = 'perm'
-
-#
-# Evaluation options
-#
-
-__C.EVAL = edict()
-
-# Evaluation epoch number
-__C.EVAL.EPOCH = 30
-
-# PCK metric (deprecated)
-#__C.EVAL.PCK_ALPHAS = []
-#__C.EVAL.PCK_L = float(max(__C.PROBLEM.RESCALE))  # PCK reference.
-
-# Number of samples for testing. Stands for number of image pairs in each classes (VOC)
-__C.EVAL.SAMPLES = 1000
-
-# Evaluated classes
-__C.EVAL.CLASS = 'all'
-
-#
-# MISC
-#
-
-# name of backbone net
-__C.BACKBONE = 'VGG16_bn'
-
-# Parallel GPU indices ([0] for single GPU)
-__C.GPUS = [0]
-
-# num of dataloader processes
-__C.DATALOADER_NUM = __C.BATCH_SIZE
-
-# path to load pretrained model weights
-__C.PRETRAINED_PATH = ''
-
-# Mean and std to normalize images
-__C.NORM_MEANS = [0.485, 0.456, 0.406]
-__C.NORM_STD = [0.229, 0.224, 0.225]
-
-# Data cache path
-__C.CACHE_PATH = 'data/cache'
-
-# Model name and dataset name
-__C.MODEL_NAME = ''
-__C.DATASET_NAME = ''
-__C.DATASET_FULL_NAME = ''
-
-# Module path of module
-__C.MODULE = ''
-
-# Output path (for checkpoints, running logs)
-__C.OUTPUT_PATH = ''
-
-# The step of iteration to print running statistics.
-# The real step value will be the least common multiple of this value and batch_size
-__C.STATISTIC_STEP = 100
-
-# random seed used for data loading
-__C.RANDOM_SEED = 123
-
-# enable fp16 instead of fp32 in the model (via nvidia/apex)
-__C.FP16 = False
-
-def lcm(x, y):
-    """
-    Compute the least common multiple of x and y. This function is used for running statistics.
-    """
-    greater = max(x, y)
-    while True:
-        if (greater % x == 0) and (greater % y == 0):
-            lcm = greater
-            break
-        greater += 1
-    return lcm
-
-
-def get_output_dir(model, dataset):
-    """
-    Return the directory where experimental artifacts are placed.
-    :param model: model name
-    :param dataset: dataset name
-    :return: output path (checkpoint and log)
-    """
-    outp_path = os.path.join('output', '{}_{}'.format(model, dataset))
-    return outp_path
-
-
-def _merge_a_into_b(a, b):
-    """Merge config dictionary a into config dictionary b, clobbering the
-    options in b whenever they are also specified in a.
-    """
-    if type(a) is not edict:
-        return
-
-    for k, v in a.items():
-        # a must specify keys that are in b
-        if k not in b:
-            raise KeyError('{} is not a valid config key'.format(k))
-
-        # the types must match, too
-        if type(b[k]) is not type(v):
-            if type(b[k]) is float and type(v) is int:
-                v = float(v)
-            else:
-                if not k in ['CLASS']:
-                    raise ValueError('Type mismatch ({} vs. {}) for config key: {}'.format(type(b[k]), type(v), k))
-
-        # recursively merge dicts
-        if type(v) is edict:
-            try:
-                _merge_a_into_b(a[k], b[k])
-            except:
-                print('Error under config key: {}'.format(k))
-                raise
-        else:
-            b[k] = v
-
-
-def cfg_from_file(filename):
-    """Load a config file and merge it into the default options."""
-    import yaml
-    with open(filename, 'r') as f:
-        yaml_cfg = edict(yaml.full_load(f))
-
-    if 'MODULE' in yaml_cfg and yaml_cfg.MODULE not in __C:
-        model_cfg_module = '.'.join(yaml_cfg.MODULE.split('.')[:-1] + ['model_config'])
-        mod = importlib.import_module(model_cfg_module)
-        __C.update(mod.model_cfg)
-
-    if 'DATASET_FULL_NAME' in yaml_cfg and yaml_cfg.DATASET_FULL_NAME in yaml_cfg \
-        and yaml_cfg.DATASET_FULL_NAME not in __C:
-        if yaml_cfg.DATASET_FULL_NAME in src.dataset.dataset_cfg:
-            __C[yaml_cfg.DATASET_FULL_NAME] = src.dataset.dataset_cfg[yaml_cfg.DATASET_FULL_NAME]
-            __C[yaml_cfg.DATASET_FULL_NAME].update(yaml_cfg[yaml_cfg.DATASET_FULL_NAME])
-        else:
-            __C[yaml_cfg.DATASET_FULL_NAME] = yaml_cfg[yaml_cfg.DATASET_FULL_NAME]
-
-    _merge_a_into_b(yaml_cfg, __C)
-
-
-def cfg_from_list(cfg_list):
-    """Set config keys via list (e.g., from command line)."""
-    from ast import literal_eval
-    assert len(cfg_list) % 2 == 0
-    for k, v in zip(cfg_list[0::2], cfg_list[1::2]):
-        key_list = k.split('.')
-        d = __C
-        for subkey in key_list[:-1]:
-            assert subkey in d.keys()
-            d = d[subkey]
-        subkey = key_list[-1]
-        assert subkey in d.keys()
-        try:
-            value = literal_eval(v)
-        except:
-            # handle the case when v is a string literal
-            value = v
-        assert type(value) == type(d[subkey]), \
-            'type {} does not match original type {}'.format(
-            type(value), type(d[subkey]))
-        d[subkey] = value
diff --git a/COMMON/src/utils/count_model_params.py b/COMMON/src/utils/count_model_params.py
deleted file mode 100644
index d74cb75..0000000
--- a/COMMON/src/utils/count_model_params.py
+++ /dev/null
@@ -1,4 +0,0 @@
-import numpy as np
-
-def count_parameters(model):
-  return np.sum(np.prod(v.size()) for name, v in model.named_parameters() if "auxiliary" not in name)
diff --git a/COMMON/src/utils/data_to_cuda.py b/COMMON/src/utils/data_to_cuda.py
deleted file mode 100644
index 32b2a52..0000000
--- a/COMMON/src/utils/data_to_cuda.py
+++ /dev/null
@@ -1,34 +0,0 @@
-import torch
-from src.sparse_torch.csx_matrix import CSRMatrix3d, CSCMatrix3d
-import torch_geometric as pyg
-
-def data_to_cuda(inputs):
-    """
-    Call cuda() on all tensor elements in inputs
-    :param inputs: input list/dictionary
-    :return: identical to inputs while all its elements are on cuda
-    """
-    if type(inputs) is list:
-        for i, x in enumerate(inputs):
-            inputs[i] = data_to_cuda(x)
-    elif type(inputs) is tuple:
-        inputs = list(inputs)
-        for i, x in enumerate(inputs):
-            inputs[i] = data_to_cuda(x)
-    elif type(inputs) is dict:
-        for key in inputs:
-            inputs[key] = data_to_cuda(inputs[key])
-    elif type(inputs) in [str, int, float]:
-        inputs = inputs
-    elif type(inputs) in [torch.Tensor, CSRMatrix3d, CSCMatrix3d]:
-        inputs = inputs.cuda()
-    else:
-        try:
-            pyg_datatypes = [pyg.data.Data, pyg.data.Batch, pyg.data.batch.DataBatch]
-        except AttributeError:
-            pyg_datatypes = [pyg.data.Data, pyg.data.Batch]
-        if type(inputs) in pyg_datatypes:
-            inputs = inputs.to('cuda')
-        else:
-            raise TypeError('Unknown type of inputs: {}'.format(type(inputs)))
-    return inputs
diff --git a/COMMON/src/utils/dup_stdout_manager.py b/COMMON/src/utils/dup_stdout_manager.py
deleted file mode 100644
index 79ad6ef..0000000
--- a/COMMON/src/utils/dup_stdout_manager.py
+++ /dev/null
@@ -1,43 +0,0 @@
-import sys
-
-
-class DupStdoutFileWriter(object):
-    def __init__(self, stdout, path, mode):
-        self.path = path
-        self._content = ''
-        self._stdout = stdout
-        self._file = open(path, mode)
-
-    def write(self, msg):
-        while '\n' in msg:
-            pos = msg.find('\n')
-            self._content += msg[:pos + 1]
-            self.flush()
-            msg = msg[pos + 1:]
-        self._content += msg
-        if len(self._content) > 1000:
-            self.flush()
-
-    def flush(self):
-        self._stdout.write(self._content)
-        self._stdout.flush()
-        self._file.write(self._content)
-        self._file.flush()
-        self._content = ''
-
-    def __del__(self):
-        self._file.close()
-
-
-class DupStdoutFileManager(object):
-    def __init__(self, path, mode='w+'):
-        self.path = path
-        self.mode = mode
-
-    def __enter__(self):
-        self._stdout = sys.stdout
-        self._file = DupStdoutFileWriter(self._stdout, self.path, self.mode)
-        sys.stdout = self._file
-
-    def __exit__(self, exc_type, exc_value, traceback):
-        sys.stdout = self._stdout
\ No newline at end of file
diff --git a/COMMON/src/utils/gpu_memory.py b/COMMON/src/utils/gpu_memory.py
deleted file mode 100644
index 561872c..0000000
--- a/COMMON/src/utils/gpu_memory.py
+++ /dev/null
@@ -1,16 +0,0 @@
-from pynvml import *
-nvmlInit()
-import torch
-
-def gpu_free_memory(device_id):
-    """
-    Return total amount of available memory in Bytes
-    :param device_id: GPU device id (int)
-    :return: total amount of available memory in Bytes
-    """
-    #ree = nvmlDeviceGetMemoryInfo(nvmlDeviceGetHandleByIndex(device_id)).free
-    #rsvd = torch.cuda.memory_reserved(device_id)
-    #used = torch.cuda.memory_allocated(device_id)
-    torch.cuda.empty_cache()
-    free = nvmlDeviceGetMemoryInfo(nvmlDeviceGetHandleByIndex(device_id)).free
-    return free
\ No newline at end of file
diff --git a/COMMON/src/utils/model_sl.py b/COMMON/src/utils/model_sl.py
deleted file mode 100644
index 4db6463..0000000
--- a/COMMON/src/utils/model_sl.py
+++ /dev/null
@@ -1,23 +0,0 @@
-import torch
-from torch.nn import DataParallel
-
-
-def save_model(model, path):
-    if isinstance(model, DataParallel):
-        model = model.module
-
-    torch.save(model.state_dict(), path)
-
-
-def load_model(model, path, strict=True):
-    if isinstance(model, DataParallel):
-        module = model.module
-    else:
-        module = model
-    missing_keys, unexpected_keys = module.load_state_dict(torch.load(path), strict=strict)
-    if len(unexpected_keys) > 0:
-        print('Warning: Unexpected key(s) in state_dict: {}. '.format(
-            ', '.join('"{}"'.format(k) for k in unexpected_keys)))
-    if len(missing_keys) > 0:
-        print('Warning: Missing key(s) in state_dict: {}. '.format(
-            ', '.join('"{}"'.format(k) for k in missing_keys)))
diff --git a/COMMON/src/utils/pad_tensor.py b/COMMON/src/utils/pad_tensor.py
deleted file mode 100644
index 93b4d23..0000000
--- a/COMMON/src/utils/pad_tensor.py
+++ /dev/null
@@ -1,59 +0,0 @@
-import torch
-import numpy as np
-import torch.nn.functional as functional
-
-def pad_tensor(inp):
-    """
-    Pad a list of input tensors into a list of tensors with same dimension
-    :param inp: input tensor list
-    :return: output tensor list
-    """
-    assert type(inp[0]) == torch.Tensor
-    it = iter(inp)
-    t = next(it)
-    max_shape = list(t.shape)
-    while True:
-        try:
-            t = next(it)
-            for i in range(len(max_shape)):
-                max_shape[i] = int(max(max_shape[i], t.shape[i]))
-        except StopIteration:
-            break
-    max_shape = np.array(max_shape)
-
-    padded_ts = []
-    for t in inp:
-        pad_pattern = np.zeros(2 * len(max_shape), dtype=np.int64)
-        pad_pattern[::-2] = max_shape - np.array(t.shape)
-        pad_pattern = tuple(pad_pattern.tolist())
-        padded_ts.append(functional.pad(t, pad_pattern, 'constant', 0))
-
-    return padded_ts
-
-def pad_tensor_varied(inp,dummy=-100):
-    """
-    Pad a list of input tensors into a list of tensors with same dimension
-    :param inp: input tensor list
-    :return: output tensor list
-    """
-    assert type(inp[0]) == torch.Tensor
-    it = iter(inp)
-    t = next(it)
-    max_shape = list(t.shape)
-    while True:
-        try:
-            t = next(it)
-            for i in range(len(max_shape)):
-                max_shape[i] = int(max(max_shape[i], t.shape[i]))
-        except StopIteration:
-            break
-    max_shape = np.array(max_shape)+1
-
-    padded_ts = []
-    for t in inp:
-        pad_pattern = np.zeros(2 * len(max_shape), dtype=np.int64)
-        pad_pattern[::-2] = max_shape - np.array(t.shape)
-        pad_pattern = tuple(pad_pattern.tolist())
-        padded_ts.append(functional.pad(t, pad_pattern, 'constant', dummy))
-
-    return padded_ts
\ No newline at end of file
diff --git a/COMMON/src/utils/parse_args.py b/COMMON/src/utils/parse_args.py
deleted file mode 100644
index a59db67..0000000
--- a/COMMON/src/utils/parse_args.py
+++ /dev/null
@@ -1,37 +0,0 @@
-import argparse
-from src.utils.config import cfg, cfg_from_file, cfg_from_list, get_output_dir
-from pathlib import Path
-
-
-def parse_args(description):
-    parser = argparse.ArgumentParser(description=description)
-    parser.add_argument('--cfg', '--config', dest='cfg_file', action='append',
-                        help='an optional config file', default=None, type=str)
-    parser.add_argument('--batch', dest='batch_size',
-                        help='batch size', default=None, type=int)
-    parser.add_argument('--epoch', dest='epoch',
-                        help='epoch number', default=None, type=int)
-    args = parser.parse_args()
-
-    # load cfg from file
-    if args.cfg_file is not None:
-        for f in args.cfg_file:
-            cfg_from_file(f)
-
-    # load cfg from arguments
-    if args.batch_size is not None:
-        cfg_from_list(['BATCH_SIZE', args.batch_size])
-    if args.epoch is not None:
-        cfg_from_list(['TRAIN.START_EPOCH', args.epoch, 'EVAL.EPOCH', args.epoch])
-
-    assert len(cfg.MODULE) != 0, 'Please specify a module name in your yaml file (e.g. MODULE: models.PCA.model).'
-    assert len(cfg.DATASET_FULL_NAME) != 0, 'Please specify the full name of dataset in your yaml file (e.g. DATASET_FULL_NAME: PascalVOC).'
-
-    if len(cfg.MODEL_NAME) != 0 and len(cfg.DATASET_NAME) != 0:
-        outp_path = get_output_dir(cfg.MODEL_NAME, cfg.DATASET_NAME)
-        cfg_from_list(['OUTPUT_PATH', outp_path])
-    assert len(cfg.OUTPUT_PATH) != 0, 'Invalid OUTPUT_PATH! Make sure model name and dataset name are specified.'
-    if not Path(cfg.OUTPUT_PATH).exists():
-        Path(cfg.OUTPUT_PATH).mkdir(parents=True)
-
-    return args
diff --git a/COMMON/src/utils/print_easydict.py b/COMMON/src/utils/print_easydict.py
deleted file mode 100644
index 20660ff..0000000
--- a/COMMON/src/utils/print_easydict.py
+++ /dev/null
@@ -1,35 +0,0 @@
-from easydict import EasyDict as edict
-
-def static_vars(**kwargs):
-    def decorate(func):
-        for k in kwargs:
-            setattr(func, k, kwargs[k])
-        return func
-    return decorate
-
-@static_vars(indent_cnt=0)
-def print_easydict(inp_dict: edict):
-    for key, value in inp_dict.items():
-        if type(value) is edict or type(value) is dict:
-            print('{}{}:'.format(' ' * 2 * print_easydict.indent_cnt, key))
-            print_easydict.indent_cnt += 1
-            print_easydict(value)
-            print_easydict.indent_cnt -= 1
-
-        else:
-            print('{}{}: {}'.format(' ' * 2 * print_easydict.indent_cnt, key, value))
-
-@static_vars(indent_cnt=0)
-def print_easydict_str(inp_dict: edict):
-    ret_str = ''
-    for key, value in inp_dict.items():
-        if type(value) is edict or type(value) is dict:
-            ret_str += '{}{}:\n'.format(' ' * 2 * print_easydict_str.indent_cnt, key)
-            print_easydict_str.indent_cnt += 1
-            ret_str += print_easydict_str(value)
-            print_easydict_str.indent_cnt -= 1
-
-        else:
-            ret_str += '{}{}: {}\n'.format(' ' * 2 * print_easydict_str.indent_cnt, key, value)
-
-    return ret_str
diff --git a/COMMON/src/utils/sparse.py b/COMMON/src/utils/sparse.py
deleted file mode 100644
index a4f314c..0000000
--- a/COMMON/src/utils/sparse.py
+++ /dev/null
@@ -1,473 +0,0 @@
-import sys
-import os
-import torch
-from torch.autograd import Function
-import numpy as np
-import scipy.sparse as ssp
-
-from src.sparse_torch import CSRMatrix3d, CSCMatrix3d
-
-if 'SPHINX' not in os.environ:
-    from torch.utils.cpp_extension import load
-    bilinear_diag = load(name='bilinear_diag', sources=['src/extension/bilinear_diag/bilinear_diag.cpp',
-                                                        'src/extension/bilinear_diag/bilinear_diag_cuda.cu'],
-                         extra_include_paths=[
-                             '/usr/include/python{}.{}/'.format(sys.version_info.major, sys.version_info.minor)]
-                         )
-
-
-def to_sparse(x, dense_dim=1):
-    """ converts dense tensor x to sparse format """
-    x_typename = torch.typename(x).split('.')[-1]
-    sparse_tensortype = getattr(torch.sparse, x_typename)
-
-    indices = torch.nonzero(x, as_tuple=False)[:, :len(x.shape) - dense_dim + 1]
-    if len(indices.shape) == 0:  # if all elements are zeros
-        return sparse_tensortype(*x.shape)
-    indices = indices.t()
-    values = x[tuple(indices[i] for i in range(indices.shape[0]))]
-    return sparse_tensortype(indices, values, x.shape)
-
-
-def sbmm(t1, t2):
-    """
-    Perform bmm (Batch Matrix Matrix) for sparse x dense -> dense.
-    """
-    return SparseDenseDenseBMM.apply(t1, t2)
-
-
-def sbmm_diag(t1, t2):
-    """
-    Perform bmm and diagonal for sparse x dense -> dense. The diagonalized result is returned in vector tensor.
-    This is a wrapper function and does not support gradient.
-    """
-    assert t1.is_sparse != t2.is_sparse, 't1, t2 must be one sparse and one dense!'
-    return sdd_bmm_diag_torch(t1, t2)
-
-
-def sdsbmm(t1, t2):
-    """
-    Perform bmm for sparse x dense -> sparse.
-    This is a wrapper function and does not support gradient.
-    """
-    assert (type(t1) == list) != (type(t2) == list) or t1.is_sparse != t2.is_sparse, \
-        't1, t2 must be one sparse and one dense!'
-    if type(t1) == list or t1.is_sparse:
-        result = sds_bmm_torch(t1, t2)
-    else:
-        result = sds_bmm_torch(t2.transpose(1, 2), t1.transpose(1, 2)).transpose(1, 2)
-    return result
-
-
-def sssbmm_diag(m1, m2):
-    """
-    Perform bmm and diagonal for sparse x sparse -> sparse.
-    This is a wrapper function and does not support gradient.
-    """
-    if (type(m1) == list and type(m1[0]) == torch.Tensor) or type(m1) == torch.Tensor:
-        m1 = torch2ssp(m1)
-    if (type(m2) == list and type(m2[0]) == torch.Tensor) or type(m2) == torch.Tensor:
-        m2 = torch2ssp(m2)
-    return sss_bmm_diag_spp(m1, m2)
-
-
-'''
-Torch API Functions
-'''
-
-
-class SparseDenseDenseBMM(Function):
-    """
-    bmm (Batch Matrix Matrix) for sparse x dense -> dense.
-    with s_t1.shape = (b, x, s), d_t2.shape = (b, s, y), the output shape is (b, x, y)
-    This is a work around utilizing torch.mm for sparse x dense -> dense. Forward and backward options are implemented.
-    """
-    @staticmethod
-    def forward(ctx, t1, t2):
-        """
-        :param t1: tensor 1
-        :param t2: tensor 2
-        :return: bmm result in dense
-        """
-        ctx.save_for_backward(t1, t2)
-        assert t1.is_sparse != t2.is_sparse, 't1, t2 must be one sparse and one dense!'
-        if t1.is_sparse:
-            result = sdd_bmm_torch(t1, t2)
-        else:
-            result = sdd_bmm_torch(t2.transpose(1, 2), t1.transpose(1, 2)).transpose(1, 2)
-        return result
-
-    @staticmethod
-    def backward(ctx, dm):
-        s_t1, d_t2 = ctx.saved_tensors
-        dt1 = dt2 = None
-        if ctx.needs_input_grad[0]:
-            dt1 = torch.bmm(dm, d_t2.transpose(1, 2))
-            dt1 = dense_to_sparse(dt1)
-        if ctx.needs_input_grad[1]:
-            dt2 = sdd_bmm_torch(s_t1.transpose(1, 2), dm)
-        return dt1, dt2
-
-
-def sdd_bmm_torch(s_t1, d_t2):
-    """
-    bmm (Batch Matrix Matrix) for sparse x dense -> dense. This function itself doesn't support gradient.
-    with s_t1.shape = (b, x, s), d_t2.shape = (b, s, y), the output shape is (b, x, y)
-    This is a work around utilizing torch.mm for sparse x dense -> dense
-    :param s_t1: sparse tensor 1
-    :param d_t2: dense tensor 2
-    :return: bmm result in dense
-    """
-    device = s_t1.device
-    batch_num = s_t1.shape[0]
-    x = s_t1.shape[1]
-    y = d_t2.shape[2]
-    assert s_t1.shape[0] == d_t2.shape[0], 'Batch size mismatch.'
-    assert s_t1.shape[2] == d_t2.shape[1], 'Matrix shape mismatch.'
-    outp = torch.empty(batch_num, x, y, dtype=s_t1.dtype, device=device)
-    for b in range(batch_num):
-        _s_t1 = get_batches(s_t1, b)
-        torch.mm(_s_t1, d_t2[b, :, :], out=outp[b, :, :])
-    return outp
-
-
-def sdd_bmm_diag_torch(t1, t2):
-    """
-    Perform bmm and diagonal for sparse x dense -> dense. The diagonalized result is returned in vector tensor.
-    With s_t1.shape = (b, x, s), d_t2.shape = (b, s, x), the output shape is (b, x).
-    This method avoids a temporal (b, x, x) for memory efficiency.
-    :param t1: tensor 1
-    :param t2: tensor 2
-    :return: bmm_diag result in dense
-    """
-    assert t1.shape[0] == t2.shape[0], 'Batch size mismatch.'
-    assert t1.shape[2] == t2.shape[1] and t1.shape[1] == t2.shape[2], 'Matrix shape mismatch.'
-    if t1.is_sparse:
-        d_t1 = t1.transpose(1, 2).to_dense()
-        outp = torch.sum(d_t1.mul_(t2), dim=1)
-    else:
-        d_t2 = t2.transpose(1, 2).to_dense()
-        outp = torch.sum(d_t2.mul_(t1), dim=2)
-    return outp
-
-
-def sds_bmm_torch(s_t1, d_t2):
-    """
-    bmm (Batch Matrix Matrix) for sparse x dense -> sparse. This function doesn't support gradient.
-    And sparse tensors cannot accept gradient due to the limitation of torch implementation.
-    with s_t1.shape = (b, x, s), d_t2.shape = (b, s, y), the output shape is (b, x, y)
-    This is a work around utilizing torch.smm for sparse x dense -> sparse
-    :param s_t1: sparse tensor 1 (in list, representing batches)
-    :param d_t2: dense tensor 2
-    :return: bmm result in sparse (in list, representing batches)
-    """
-    device = d_t2.device
-    assert type(s_t1) == list
-    batch_num = len(s_t1)
-
-    assert batch_num == d_t2.shape[0], 'Batch size mismatch.'
-
-    outp = []
-    for b in range(batch_num):
-        # force cpu
-        _s_t1 = s_t1[b].cpu()
-        _d_t2 = d_t2[b].cpu()
-        assert _s_t1.shape[1] == _d_t2.shape[0], 'Matrix shape mismatch.'
-        _outp = torch.smm(_s_t1, _d_t2)  # CUDA version of smm is not implemented
-        outp.append(_outp)
-
-    return outp
-
-
-def bilinear_diag_torch(s_t1: CSRMatrix3d, d_t2: torch.Tensor, s_t3: CSCMatrix3d, device=None):
-    """
-    Bilinear and diagonal in sequence, for diagonal(sparse x dense x sparse) -> dense vector.
-    with s_t1.shape = (b, x, y), d_t2.shape = (b, y, y), d_t3.shape = (b, y, x), the output shape is (b, x).
-    In this function, two sparse tensors (s1 and s3) are represented in CSR and CSC format to guarantee efficient
-    computation.
-    The main operation is implemented in a custom C++ extension, and will be ~1000x faster if CUDA is available.
-    :param s_t1: CSR matrix 1
-    :param d_t2: dense tensor 2
-    :param s_t3: CSC matrix 3
-    :param device: device. If not specified, it will be the same as input.
-    :return: returned dense vector
-    """
-    if device is None:
-        device = d_t2.device
-    #dtype = d_t2.dtype
-
-    batch_num = s_t1.shape[0]
-    xlen = s_t1.shape[1]
-    assert s_t1.shape[0] == d_t2.shape[0] == s_t3.shape[0], 'Batch size mismatch.'
-    assert s_t1.shape[1] == s_t3.shape[2], 'Sparse matrix 1 & 3 shape mismatch.'
-    assert s_t1.shape[2] == d_t2.shape[1] == d_t2.shape[2] == s_t3.shape[1], 'Matrix size mismatch.'
-    '''
-    s_t1_input = [[], [], []]
-    s_t3_input = [[], [], []]
-    t1_indptr_offset = 0
-    t3_indptr_offset = 0
-    for b in range(batch_num):
-        _s_t1 = s_t1[b].tocsc()
-        s_t1_input[0].append(_s_t1.indices)
-        s_t1_input[1].append(_s_t1.indptr[:-1] + t1_indptr_offset)
-        s_t1_input[2].append(_s_t1.data)
-        t1_indptr_offset += _s_t1.indptr[-1]
-
-        _s_t3 = s_t3[b].tocsc()
-        s_t3_input[0].append(_s_t3.indices)
-        s_t3_input[1].append(_s_t3.indptr[:-1] + t3_indptr_offset)
-        s_t3_input[2].append(_s_t3.data)
-        t3_indptr_offset += _s_t3.indptr[-1]
-
-    s_t1_input[1].append(np.array([t1_indptr_offset]))
-    s_t3_input[1].append(np.array([t3_indptr_offset]))
-
-    for input in (s_t1_input, s_t3_input):
-        for idx in range(len(input)):
-            if idx == 2:  # data
-                _dtype = dtype
-            else:  # indices & indptr
-                _dtype = torch.int64
-            input[idx] = torch.tensor(np.concatenate(input[idx]), dtype=_dtype, device=device)
-    '''
-    outp = bilinear_diag.bilinear_diag(*s_t1.as_list(), d_t2, *s_t3.as_list(), batch_num, xlen)
-
-    return outp.to(device)
-
-
-def dense_to_sparse(d_t):
-    """
-    Convert a dense tensor to a sparse one.
-    :param d_t: dense tensor
-    :return: sparse tensor
-    """
-    dtype = d_t.dtype
-    device = d_t.device
-    req_grad = d_t.requires_grad
-
-    indices = torch.nonzero(d_t)
-    if len(indices.shape) == 0:  # if all elements are zeros
-        return torch.sparse_coo_tensor([], [], d_t.shape, dtype=dtype, device=device, requires_grad=req_grad)
-    indices = indices.t()
-    values = d_t[tuple(indices[i] for i in range(indices.shape[0]))]
-    return torch.sparse_coo_tensor(indices, values, d_t.size(), dtype=dtype, device=device, requires_grad=req_grad)
-
-
-def get_batches(s_t, b=None, device=None):
-    """
-    Get batches from a 3d sparse tensor.
-    :param s_t: sparse tensor
-    :param b: if None, return all batches in a list; else, return a specific batch
-    :param device: device. If None, it will be the same as input
-    :return: sparse tensor or list of sparse tensors
-    """
-    if device is None:
-        device = s_t.device
-
-    coo = s_t._indices()
-    data = s_t._values()
-    if b is not None:
-        idx = (coo[0, :] == b).nonzero()
-        _coo = coo[1:3, idx].view(2, -1)
-        _data = data[idx].view(-1)
-        outp = torch.sparse_coo_tensor(_coo, _data, s_t.shape[1:3], dtype=_data.dtype, device=device)
-    else:
-        batch_num = s_t.shape[0]
-        outp = []
-        for b in range(batch_num):
-            idx = (coo[0, :] == b).nonzero()
-            _coo = coo[1:3, idx].view(2, -1)
-            _data = data[idx].view(-1)
-            outp.append(torch.sparse_coo_tensor(_coo, _data, s_t.shape[1:3], dtype=_data.dtype, device=device))
-    return outp
-
-
-def slicing_torch(s_t, slice, preserve_dim=False):
-    """
-    A slicing function for torch sparse tensors.
-    :param s_t: input sparse tensor
-    :param slice: tensor containing indices, -1 stands for all.
-                  For example, (1, -1) returns the second row of a 2d tensor.
-    :param preserve_dim: If True, the dimension of the original tensor will be preserved,
-                         i.e. 1 will be padded for those removed dimensions.
-    :return: sliced sparse tensor
-    """
-    device = s_t.device
-    dim = slice.shape[0]
-    assert len(s_t.shape) == dim
-    coo = s_t._indices()
-    data = s_t._values()
-    idx_flag = torch.ones(coo.shape[1], dtype=torch.uint8, device=device)
-    for i in range(dim):
-        s = slice[i]
-        if s == -1:
-            continue
-        _idx_flag = (coo[i, :] == s).view(-1)
-        idx_flag.mul_(_idx_flag)
-    idx = idx_flag.nonzero().view(-1)
-    if not preserve_dim:
-        dim_flag = (slice == -1).nonzero().view(-1)
-        if dim_flag.numel() == 0:
-            coo = torch.tensor([[0]], dtype=coo.dtype, device=device)
-            shape = torch.Size([1])
-        else:
-            coo = coo[:, idx]
-            coo = coo[dim_flag, :]
-            shape = torch.Size(torch.tensor(s_t.shape)[dim_flag])
-    else:
-        coo = coo[:, idx]
-        coo.mul_((slice == -1).type(coo.dtype).view(-1, 1))
-        _dtype = torch.int32
-        shape = torch.Size(torch.tensor(s_t.shape, dtype=_dtype, device=device) * (slice == -1).type(_dtype)
-                           + torch.ones(len(s_t.shape), dtype=_dtype, device=device) * (slice != -1).type(_dtype))
-    data = data[idx]
-
-    return torch.sparse_coo_tensor(coo, data, shape, dtype=s_t.dtype, device=s_t.device)
-
-
-'''
-scipy.sparse API Functions
-'''
-
-
-def sss_bmm_diag_spp(s_m1, s_m2):
-    """
-    bmm (Batch Matrix Matrix) for sparse x sparse -> sparse. The diagonalized result is returned in vector tensor.
-    with s_m1.shape = (b, x, s), s_m2.shape = (b, s, x), the output shape is (b, x)
-    This function doesn't support gradient.
-    :param s_m1: sparse matrix 1
-    :param s_m2: sparse matrix 2
-    :return: result in sparse vector
-    """
-    if type(s_m1) != list:
-        s_m1 = [s_m1]
-    if type(s_m2) != list:
-        s_m2 = [s_m2]
-    assert len(s_m1) == len(s_m2), 'Batch size mismatch.'
-
-    outp = []
-    for _m1, _m2 in zip(s_m1, s_m2):
-        assert _m1.shape[1] == _m2.shape[0] and _m1.shape[0] == _m2.shape[1], 'Matrix shape mismatch.'
-        outp.append(_m1.dot(_m2).diagonal().tocoo())
-
-    return outp
-
-
-'''
-Conversion Functions
-'''
-
-
-def ssp2torch(M, batch='dim', dtype=torch.float32, device=None):
-    """
-    Convert scipy.sparse matrix to torch sparse matrix. Since scipy.sparse has a dimension limit of 2, list of matrices
-    is supported for batches.
-    :param M: input scipy.sparse matrix
-    :param batch: the type that represent batches in the output.
-                  If batch='list', tensors are 2d and stored in list.
-                  If batch='dim', tensors are 3d ane the first dimension represents batch size.
-    :param dtype: output data type
-    :param device: device
-    :return: output torch sparse matrix
-    """
-    assert batch in ('list', 'dim')
-
-    if type(M) != list:
-        M = [M]
-    batch_num = len(M)
-
-    if batch == 'list':
-        outp = []
-        for i in range(batch_num):
-            _M = M[i]
-            _M = _M.tocoo()
-            coo = np.array([_M.row, _M.col])
-            data = _M.data
-            outp.append(torch.sparse_coo_tensor(coo, data, _M.shape, dtype=dtype, device=device))
-    else:
-        batch, row, col, data = np.array([]), np.array([]), np.array([]), np.array([])
-        for i in range(batch_num):
-            _M = M[i]
-            _M = _M.tocoo()
-            batch = np.append(batch, np.ones(_M.nnz) * i)
-            row = np.append(row, _M.row)
-            col = np.append(col, _M.col)
-            data = np.append(data, _M.data)
-
-        coo = np.array([batch, row, col])
-        outp = torch.sparse_coo_tensor(coo, data, torch.Size([batch_num] + list(_M.shape)), dtype=dtype, device=device)
-
-    return outp
-
-
-def torch2ssp(M):
-    """
-    Convert torch sparse matrix to scipy.sparse matrix. Since scipy.sparse has a dimension limit of 2, batches are
-    represented in list in the output.
-    :param M: input torch sparse matrix
-    :return: output scipy.sparse matrix
-    """
-    if type(M) == list:
-        batch_num = len(M)
-        outp = []
-        for b in range(batch_num):
-            _M = M[b]
-            _coo = _M._indices()
-            _data = _M._values()
-            outp.append(ssp.coo_matrix((_data, _coo), _M.shape))
-    else:
-        coo = M._indices()
-        data = M._values()
-        batch_num = M.shape[0]
-
-        if len(M.shape) == 2:
-            outp = ssp.coo_matrix((data, coo), M.shape)
-        else:
-            assert len(M.shape) == 3
-            outp = []
-            for b in range(batch_num):
-                idx = (coo[0, :] == b).nonzero()
-                _coo = coo[1:3, idx].view(2, -1)
-                _data = data[idx].view(-1)
-                outp.append(ssp.coo_matrix((_data, _coo), M.shape[1:3]))
-    return outp
-
-
-def recover_ssp(t_dict):
-    """
-    Recover scipy.sparse coo_matrix from a dictionary containing row, col and data tensors.
-    :param t_dict: containing keys
-                   'row', 'col', 'data', each corresponds to a bxn tensor
-                   'shape', containing the MxN shape of each tensor
-    :return: list of scipy.sparse matrix. list indices represent batches.
-    """
-    batch_size = t_dict['row'].shape[0]
-    np_dict = {key: t_dict[key].numpy() for key in t_dict}
-    ss = []
-    max_shape = np.zeros((2,), dtype=np.int)
-    for b in range(batch_size):
-        shape = np_dict['shape'][b].astype(np.int)
-        max_shape[0] = max(shape[0], max_shape[0])
-        max_shape[1] = max(shape[1], max_shape[1])
-    for b in range(batch_size):
-        data = np_dict['data'][b]
-        row = np_dict['row'][b]
-        col = np_dict['col'][b]
-        _ss = ssp.coo_matrix((data, (row, col)), shape=max_shape)
-        ss.append(_ss)
-    return ss
-
-
-if __name__ == '__main__':
-    t = torch.tensor([[[ 1,  2,  3,  4],
-                       [11, 22, 33, 44]]])
-    t = dense_to_sparse(t)
-    s = slicing_torch(t, torch.tensor((0, 0, 1)), preserve_dim=True)
-    print(s.to_dense())
-
-
-    from torch.autograd import gradcheck
-    input = (dense_to_sparse(torch.randn(1, 20, 30, dtype=torch.double, requires_grad=True)),
-             torch.randn(1, 30, 40, dtype=torch.double, requires_grad=True))
-    test = gradcheck(sbmm, input, eps=1e-6, atol=1e-4)
-    print(test)
diff --git a/COMMON/src/utils/timer.py b/COMMON/src/utils/timer.py
deleted file mode 100644
index 84a77fb..0000000
--- a/COMMON/src/utils/timer.py
+++ /dev/null
@@ -1,22 +0,0 @@
-from time import time
-
-
-class Timer:
-    def __init__(self):
-        self.t = time()
-        self.tk = False
-
-    def tick(self):
-        self.t = time()
-        self.tk = True
-
-    def toc(self, tick_again=False):
-        if not self.tk:
-            raise RuntimeError('not ticked yet!')
-        self.tk = False
-        before_t = self.t
-        cur_t = time()
-        if tick_again:
-            self.t = cur_t
-            self.tk = True
-        return cur_t - before_t
diff --git a/COMMON/train_eval.py b/COMMON/train_eval.py
deleted file mode 100644
index b1ab78f..0000000
--- a/COMMON/train_eval.py
+++ /dev/null
@@ -1,402 +0,0 @@
-import torch.cuda
-import torch.optim as optim
-import time
-import xlwt
-from datetime import datetime
-from pathlib import Path
-from tensorboardX import SummaryWriter
-
-from src.dataset.data_loader import GMDataset, get_dataloader
-from src.displacement_layer import Displacement
-from src.loss_func import *
-from src.evaluation_metric import matching_accuracy
-from src.parallel import DataParallel
-from src.utils.model_sl import load_model, save_model
-from eval import eval_model
-from src.lap_solvers.hungarian import hungarian
-from src.utils.data_to_cuda import data_to_cuda
-
-from src.utils.config import cfg
-from pygmtools.benchmark import Benchmark
-
-
-def train_eval_model(model,
-                     criterion,
-                     optimizer,
-                     optimizer_k,
-                     image_dataset,
-                     dataloader,
-                     tfboard_writer,
-                     benchmark,
-                     num_epochs=25,
-                     start_epoch=0,
-                     xls_wb=None):
-    print('Start training...')
-
-    since = time.time()
-    dataset_size = len(dataloader['train'].dataset)
-    displacement = Displacement()
-
-    device = next(model.parameters()).device
-    print('model on device: {}'.format(device))
-
-    checkpoint_path = Path(cfg.OUTPUT_PATH) / 'params'
-    if not checkpoint_path.exists():
-        checkpoint_path.mkdir(parents=True)
-
-    model_path, optim_path, optim_k_path = '', '', ''
-    if start_epoch != 0:
-        model_path = str(checkpoint_path / 'params_{:04}.pt'.format(start_epoch))
-        optim_path = str(checkpoint_path / 'optim_{:04}.pt'.format(start_epoch))
-        if optimizer_k is not None:
-            optim_k_path = str(checkpoint_path / 'optim_k_{:04}.pt'.format(start_epoch))
-    if len(cfg.PRETRAINED_PATH) > 0:
-        model_path = cfg.PRETRAINED_PATH
-    if len(model_path) > 0:
-        print('Loading model parameters from {}'.format(model_path))
-        load_model(model, model_path, strict=False)
-    if len(optim_path) > 0:
-        print('Loading optimizer state from {}'.format(optim_path))
-        optimizer.load_state_dict(torch.load(optim_path))
-    if len(optim_k_path) > 0:
-        print('Loading optimizer_k state from {}'.format(optim_k_path))
-        optimizer_k.load_state_dict(torch.load(optim_k_path))
-
-    if optimizer_k is not None:
-        scheduler = optim.lr_scheduler.MultiStepLR(optimizer,
-                                                   milestones=cfg.TRAIN.LR_STEP,
-                                                   gamma=cfg.TRAIN.LR_DECAY,
-                                                   last_epoch=-1)  # cfg.TRAIN.START_EPOCH - 1
-        scheduler_k = optim.lr_scheduler.MultiStepLR(optimizer_k,
-                                                   milestones=cfg.TRAIN.LR_STEP,
-                                                   gamma=cfg.TRAIN.LR_DECAY,
-                                                   last_epoch=-1)  # cfg.TRAIN.START_EPOCH - 1
-    else:
-        scheduler = optim.lr_scheduler.MultiStepLR(optimizer,
-                                                   milestones=cfg.TRAIN.LR_STEP,
-                                                   gamma=cfg.TRAIN.LR_DECAY,
-                                                   last_epoch=cfg.TRAIN.START_EPOCH - 1)
-
-    for epoch in range(start_epoch, num_epochs):
-        # Reset seed after evaluation per epoch
-        torch.manual_seed(cfg.RANDOM_SEED + epoch + 1)
-        dataloader['train'] = get_dataloader(image_dataset['train'], shuffle=True, fix_seed=False)
-        print('Epoch {}/{}'.format(epoch, num_epochs - 1))
-        print('-' * 10)
-
-        model.train()  # Set model to training mode
-        model.module.trainings = True
-
-        print('lr = ' + ', '.join(['{:.2e}'.format(x['lr']) for x in optimizer.param_groups]))
-        if optimizer_k is not None:
-            print('K_regression_lr = ' + ', '.join(['{:.2e}'.format(x['lr']) for x in optimizer_k.param_groups]))
-
-        epoch_loss = 0.0
-        running_loss = 0.0
-        running_ks_loss = 0.0
-        running_ks_error = 0
-        running_since = time.time()
-        iter_num = 0
-
-        # Iterate over data.
-        for inputs in dataloader['train']:
-            if iter_num >= cfg.TRAIN.EPOCH_ITERS:
-                break
-            if model.module.device != torch.device('cpu'):
-                inputs = data_to_cuda(inputs)
-
-            iter_num = iter_num + 1
-
-            # zero the parameter gradients
-            optimizer.zero_grad()
-            if optimizer_k is not None:
-                optimizer_k.zero_grad()
-
-            with torch.set_grad_enabled(True):
-                # torch.autograd.set_detect_anomaly(True)
-                # forward
-                if 'common' in cfg.MODEL_NAME: # COMMON use the iter number to control the warmup temperature
-                    outputs = model(inputs, training=True, iter_num=iter_num, epoch=epoch)
-                else:
-                    outputs = model(inputs)
-                if cfg.PROBLEM.TYPE == '2GM':
-                    assert 'ds_mat' in outputs
-                    assert 'perm_mat' in outputs
-                    assert 'gt_perm_mat' in outputs
-
-                    # compute loss
-                    if cfg.TRAIN.LOSS_FUNC == 'offset':
-                        d_gt, grad_mask = displacement(outputs['gt_perm_mat'], *outputs['Ps'], outputs['ns'][0])
-                        d_pred, _ = displacement(outputs['ds_mat'], *outputs['Ps'], outputs['ns'][0])
-                        loss = criterion(d_pred, d_gt, grad_mask)
-                    elif cfg.TRAIN.LOSS_FUNC in ['perm', 'ce', 'hung', 'ilp']:
-                        loss = criterion(outputs['ds_mat'], outputs['gt_perm_mat'], *outputs['ns'])
-                    elif cfg.TRAIN.LOSS_FUNC == 'hamming':
-                        loss = criterion(outputs['perm_mat'], outputs['gt_perm_mat'])
-                    elif cfg.TRAIN.LOSS_FUNC == 'custom':
-                        loss = torch.sum(outputs['loss'])
-                    else:
-                        raise ValueError(
-                            'Unsupported loss function {} for problem type {}'.format(cfg.TRAIN.LOSS_FUNC,
-                                                                                      cfg.PROBLEM.TYPE))
-                    if 'ks_loss' in outputs:
-                        ks_loss = outputs['ks_loss']
-                        ks_error = outputs['ks_error']
-
-                    # compute accuracy
-                    acc = matching_accuracy(outputs['perm_mat'], outputs['gt_perm_mat'], outputs['ns'], idx=0)
-
-                elif cfg.PROBLEM.TYPE in ['MGM', 'MGM3']:
-                    assert 'ds_mat_list' in outputs
-                    assert 'graph_indices' in outputs
-                    assert 'perm_mat_list' in outputs
-                    if not 'gt_perm_mat_list' in outputs:
-                        assert 'gt_perm_mat' in outputs
-                        gt_perm_mat_list = [outputs['gt_perm_mat'][idx] for idx in outputs['graph_indices']]
-                    else:
-                        gt_perm_mat_list = outputs['gt_perm_mat_list']
-
-                    # compute loss & accuracy
-                    if cfg.TRAIN.LOSS_FUNC in ['perm', 'ce' 'hung']:
-                        loss = torch.zeros(1, device=model.module.device)
-                        ns = outputs['ns']
-                        for s_pred, x_gt, (idx_src, idx_tgt) in \
-                                zip(outputs['ds_mat_list'], gt_perm_mat_list, outputs['graph_indices']):
-                            l = criterion(s_pred, x_gt, ns[idx_src], ns[idx_tgt])
-                            loss += l
-                        loss /= len(outputs['ds_mat_list'])
-                    elif cfg.TRAIN.LOSS_FUNC == 'plain':
-                        loss = torch.sum(outputs['loss'])
-                    else:
-                        raise ValueError(
-                            'Unsupported loss function {} for problem type {}'.format(cfg.TRAIN.LOSS_FUNC,
-                                                                                      cfg.PROBLEM.TYPE))
-
-                    # compute accuracy
-                    acc = torch.zeros(1, device=model.module.device)
-                    for x_pred, x_gt, (idx_src, idx_tgt) in \
-                            zip(outputs['perm_mat_list'], gt_perm_mat_list, outputs['graph_indices']):
-                        a = matching_accuracy(x_pred, x_gt, ns, idx=idx_src)
-                        acc += torch.sum(a)
-                    acc /= len(outputs['perm_mat_list'])
-                else:
-                    raise ValueError('Unknown problem type {}'.format(cfg.PROBLEM.TYPE))
-
-                # backward + optimize
-                if cfg.FP16:
-                    with amp.scale_loss(loss, optimizer) as scaled_loss:
-                        scaled_loss.backward()
-                else:
-                    # with torch.autograd.detect_anomaly():
-                    loss.backward()
-                    if optimizer_k is not None:
-                        ks_loss.backward()
-                # for n, p in model.named_parameters():
-                #     if p.grad is not None and torch.any(torch.isnan(p.grad)):
-                #         print('NaN!!!')
-                #         print('name:', n, '-->require_grad:', p.requires_grad)
-                optimizer.step()
-                if optimizer_k is not None:
-                    optimizer_k.step()
-
-                batch_num = inputs['batch_size']
-
-                # tfboard writer
-                loss_dict = dict()
-                loss_dict['loss'] = loss.item()
-                tfboard_writer.add_scalars('loss', loss_dict, epoch * cfg.TRAIN.EPOCH_ITERS + iter_num)
-
-                accdict = dict()
-                accdict['matching accuracy'] = torch.mean(acc)
-                tfboard_writer.add_scalars(
-                    'training accuracy',
-                    accdict,
-                    epoch * cfg.TRAIN.EPOCH_ITERS + iter_num
-                )
-
-                # statistics
-                running_loss += loss.item() * batch_num
-                epoch_loss += loss.item() * batch_num
-                if 'ks_loss' in outputs:
-                    running_ks_loss += ks_loss * batch_num
-                    running_ks_error += ks_error * batch_num
-
-                if iter_num % cfg.STATISTIC_STEP == 0:
-                    running_speed = cfg.STATISTIC_STEP * batch_num / (time.time() - running_since)
-                    print('Epoch {:<4} Iteration {:<4} {:>4.2f}sample/s Loss={:<8.4f} Ks_Loss={:<8.4f} Ks_Error={:<8.4f}'
-                          .format(epoch, iter_num, running_speed, running_loss / cfg.STATISTIC_STEP / batch_num, running_ks_loss / cfg.STATISTIC_STEP / batch_num, running_ks_error / cfg.STATISTIC_STEP / batch_num))
-                    tfboard_writer.add_scalars(
-                        'speed',
-                        {'speed': running_speed},
-                        epoch * cfg.TRAIN.EPOCH_ITERS + iter_num
-                    )
-
-                    tfboard_writer.add_scalars(
-                        'learning rate',
-                        {'lr_{}'.format(i): x['lr'] for i, x in enumerate(optimizer.param_groups)},
-                        epoch * cfg.TRAIN.EPOCH_ITERS + iter_num
-                    )
-
-                    running_loss = 0.0
-                    running_ks_loss = 0.0
-                    running_ks_error = 0.0
-                    running_since = time.time()
-
-        epoch_loss = epoch_loss / cfg.TRAIN.EPOCH_ITERS / batch_num
-
-        save_model(model, str(checkpoint_path / 'params_{:04}.pt'.format(epoch + 1)))
-        torch.save(optimizer.state_dict(), str(checkpoint_path / 'optim_{:04}.pt'.format(epoch + 1)))
-        if optimizer_k is not None:
-            torch.save(optimizer_k.state_dict(), str(checkpoint_path / 'optim_k_{:04}.pt'.format(epoch + 1)))
-
-        print('Epoch {:<4} Loss: {:.4f}'.format(epoch, epoch_loss))
-        print()
-
-        # Eval in each epoch
-        if dataloader['test'].dataset.cls not in ['none', 'all', None]:
-            clss = [dataloader['test'].dataset.cls]
-        else:
-            clss = dataloader['test'].dataset.bm.classes
-        l_e = (epoch == (num_epochs - 1))
-        accs = eval_model(model, clss, benchmark['test'], l_e,
-                          xls_sheet=xls_wb.add_sheet('epoch{}'.format(epoch + 1)))
-        acc_dict = {"{}".format(cls): single_acc for cls, single_acc in zip(dataloader['test'].dataset.classes, accs)}
-        acc_dict['average'] = torch.mean(accs)
-        tfboard_writer.add_scalars(
-            'Eval acc',
-            acc_dict,
-            (epoch + 1) * cfg.TRAIN.EPOCH_ITERS
-        )
-        wb.save(wb.__save_path)
-
-        scheduler.step()
-        if optimizer_k is not None:
-            scheduler_k.step()
-
-    time_elapsed = time.time() - since
-    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'
-          .format(time_elapsed // 3600, (time_elapsed // 60) % 60, time_elapsed % 60))
-
-    return model
-
-
-if __name__ == '__main__':
-    from src.utils.dup_stdout_manager import DupStdoutFileManager
-    from src.utils.parse_args import parse_args
-    from src.utils.print_easydict import print_easydict
-
-    args = parse_args('Deep learning of graph matching training & evaluation code.')
-
-    import importlib
-
-    mod = importlib.import_module(cfg.MODULE)
-    Net = mod.Net
-
-    torch.manual_seed(cfg.RANDOM_SEED)
-
-    dataset_len = {'train': cfg.TRAIN.EPOCH_ITERS * cfg.BATCH_SIZE, 'test': cfg.EVAL.SAMPLES}
-    ds_dict = cfg[cfg.DATASET_FULL_NAME] if ('DATASET_FULL_NAME' in cfg) and (cfg.DATASET_FULL_NAME in cfg) else {}
-    benchmark = {
-        x: Benchmark(name=cfg.DATASET_FULL_NAME,
-                     sets=x,
-                     problem=cfg.PROBLEM.TYPE,
-                     obj_resize=cfg.PROBLEM.RESCALE,
-                     filter=cfg.PROBLEM.FILTER,
-                     **ds_dict)
-        for x in ('train', 'test')}
-
-    image_dataset = {
-        x: GMDataset(cfg.DATASET_FULL_NAME,
-                     benchmark[x],
-                     dataset_len[x],
-                     cfg.PROBLEM.TRAIN_ALL_GRAPHS if x == 'train' else cfg.PROBLEM.TEST_ALL_GRAPHS,
-                     cfg.TRAIN.CLASS if x == 'train' else cfg.EVAL.CLASS,
-                     cfg.PROBLEM.TYPE)
-        for x in ('train', 'test')}
-    dataloader = {x: get_dataloader(image_dataset[x], shuffle=True, fix_seed=(x == 'test'))
-                  for x in ('train', 'test')}
-
-    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
-
-    model = Net()
-    model = model.to(device)
-
-    if cfg.TRAIN.LOSS_FUNC.lower() == 'offset':
-        criterion = OffsetLoss(norm=cfg.TRAIN.RLOSS_NORM)
-    elif cfg.TRAIN.LOSS_FUNC.lower() == 'perm':
-        criterion = PermutationLoss()
-    elif cfg.TRAIN.LOSS_FUNC.lower() == 'ce':
-        criterion = CrossEntropyLoss()
-    elif cfg.TRAIN.LOSS_FUNC.lower() == 'focal':
-        criterion = FocalLoss(alpha=.5, gamma=0.)
-    elif cfg.TRAIN.LOSS_FUNC.lower() == 'hung':
-        criterion = PermutationLossHung()
-    elif cfg.TRAIN.LOSS_FUNC.lower() == 'hamming':
-        criterion = HammingLoss()
-    elif cfg.TRAIN.LOSS_FUNC.lower() == 'ilp':
-        criterion = ILP_attention_loss()
-    elif cfg.TRAIN.LOSS_FUNC.lower() == 'custom':
-        criterion = None
-        print('NOTE: You are setting the loss function as \'custom\', please ensure that there is a tensor with key '
-              '\'loss\' in your model\'s returned dictionary.')
-    else:
-        raise ValueError('Unknown loss function {}'.format(cfg.TRAIN.LOSS_FUNC))
-
-    optimizer_k = None
-
-    if cfg.TRAIN.SEPARATE_BACKBONE_LR:
-        if not cfg.TRAIN.SEPARATE_K_LR:
-            backbone_ids = [id(item) for item in model.backbone_params]
-            other_params = [param for param in model.parameters() if id(param) not in backbone_ids]
-
-            model_params = [
-                {'params': other_params},
-                {'params': model.backbone_params, 'lr': cfg.TRAIN.BACKBONE_LR}
-            ]
-        else:
-            backbone_ids = [id(item) for item in model.backbone_params]
-            k_params = model.k_params_id
-            other_params = [param for param in model.parameters() if id(param) not in k_params and id(param) not in backbone_ids]
-
-            model_params = [
-                {'params': other_params},
-                {'params': model.backbone_params, 'lr': cfg.TRAIN.BACKBONE_LR}
-            ]
-            k_reg_params = model.k_params
-            optimizer_k = optim.Adam(k_reg_params, lr=cfg.TRAIN.K_LR)
-
-    else:
-        model_params = model.parameters()
-
-    if cfg.TRAIN.OPTIMIZER.lower() == 'sgd':
-        optimizer = optim.SGD(model_params, lr=cfg.TRAIN.LR, momentum=cfg.TRAIN.MOMENTUM, nesterov=True)
-    elif cfg.TRAIN.OPTIMIZER.lower() == 'adam':
-        optimizer = optim.Adam(model_params, lr=cfg.TRAIN.LR)
-    else:
-        raise ValueError('Unknown optimizer {}'.format(cfg.TRAIN.OPTIMIZER))
-
-    if cfg.FP16:
-        try:
-            from apex import amp
-        except ImportError:
-            raise ImportError("Please install apex from https://www.github.com/nvidia/apex to enable FP16.")
-        model, optimizer = amp.initialize(model, optimizer)
-
-    model = DataParallel(model, device_ids=cfg.GPUS)
-
-    if not Path(cfg.OUTPUT_PATH).exists():
-        Path(cfg.OUTPUT_PATH).mkdir(parents=True)
-
-    now_time = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')
-    tfboardwriter = SummaryWriter(logdir=str(Path(cfg.OUTPUT_PATH) / 'tensorboard' / 'training_{}'.format(now_time)))
-    wb = xlwt.Workbook()
-    wb.__save_path = str(Path(cfg.OUTPUT_PATH) / ('train_eval_result_' + now_time + '.xls'))
-
-    with DupStdoutFileManager(str(Path(cfg.OUTPUT_PATH) / ('train_log_' + now_time + '.log'))) as _:
-        print_easydict(cfg)
-        model = train_eval_model(model, criterion, optimizer, optimizer_k, image_dataset, dataloader, tfboardwriter, benchmark,
-                                 num_epochs=cfg.TRAIN.NUM_EPOCHS,
-                                 start_epoch=cfg.TRAIN.START_EPOCH,
-                                 xls_wb=wb)
-
-    wb.save(wb.__save_path)
diff --git a/GMN/README.md b/GMN/README.md
deleted file mode 100644
index b0ccbfe..0000000
--- a/GMN/README.md
+++ /dev/null
@@ -1,30 +0,0 @@
-# Graph Matching Network
-
-This is a PyTorch re-implementation of the following ICML 2019 paper. If you feel this project helpful to your research, please give a star.
-
-> Yujia Li, Chenjie Gu, Thomas Dullien, Oriol Vinyals, Pushmeet Kohli. *Graph Matching Networks for Learning the Similarity of Graph Structured Objects*. ICML 2019. [[arXiv\]](https://arxiv.org/abs/1904.12787).
-
-## Requirements
-
-torch >= 1.2.0
-
-networkx>=2.3  
-
-numpy>=1.16.4  
-
-six>=1.12
-
-## Usage
-
-The code includes:
-
-- an example implementation of the model,
-- an example graph similarity learning task,
-- an example training loop.
-
-
-Please use `./run.sh` to run.
-
-## References:
-
-[Deepmind-research](https://github.com/deepmind/deepmind-research/tree/master/graph_matching_networks) (using TensorFlow and Sonnet)
diff --git a/GMN/__init__.py b/GMN/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/GMN/__pycache__/__init__.cpython-312.pyc b/GMN/__pycache__/__init__.cpython-312.pyc
deleted file mode 100644
index 7aeb20b..0000000
Binary files a/GMN/__pycache__/__init__.cpython-312.pyc and /dev/null differ
diff --git a/GMN/__pycache__/configure.cpython-312.pyc b/GMN/__pycache__/configure.cpython-312.pyc
deleted file mode 100644
index cd79243..0000000
Binary files a/GMN/__pycache__/configure.cpython-312.pyc and /dev/null differ
diff --git a/GMN/__pycache__/dataset.cpython-312.pyc b/GMN/__pycache__/dataset.cpython-312.pyc
deleted file mode 100644
index 2160244..0000000
Binary files a/GMN/__pycache__/dataset.cpython-312.pyc and /dev/null differ
diff --git a/GMN/__pycache__/graphmatchingnetwork.cpython-312.pyc b/GMN/__pycache__/graphmatchingnetwork.cpython-312.pyc
deleted file mode 100644
index 19bb4b2..0000000
Binary files a/GMN/__pycache__/graphmatchingnetwork.cpython-312.pyc and /dev/null differ
diff --git a/GMN/configure.py b/GMN/configure.py
deleted file mode 100644
index bbd74cf..0000000
--- a/GMN/configure.py
+++ /dev/null
@@ -1,78 +0,0 @@
-def get_default_config():
-    """The default configs."""
-    model_type = 'matching'
-    # Set to `embedding` to use the graph embedding net.
-    node_state_dim = 32
-    edge_state_dim = 16
-    graph_rep_dim = 128
-    graph_embedding_net_config = dict(
-        node_state_dim=node_state_dim,
-        edge_state_dim=edge_state_dim,
-        edge_hidden_sizes=[node_state_dim * 2, node_state_dim * 2],
-        node_hidden_sizes=[node_state_dim * 2],
-        n_prop_layers=5,
-        # set to False to not share parameters across message passing layers
-        share_prop_params=True,
-        # initialize message MLP with small parameter weights to prevent
-        # aggregated message vectors blowing up, alternatively we could also use
-        # e.g. layer normalization to keep the scale of these under control.
-        edge_net_init_scale=0.1,
-        # other types of update like `mlp` and `residual` can also be used here. gru
-        node_update_type='gru',
-        # set to False if your graph already contains edges in both directions.
-        use_reverse_direction=True,
-        # set to True if your graph is directed
-        reverse_dir_param_different=False,
-        # we didn't use layer norm in our experiments but sometimes this can help.
-        layer_norm=False,
-        # set to `embedding` to use the graph embedding net.
-        prop_type=model_type)
-    graph_matching_net_config = graph_embedding_net_config.copy()
-    graph_matching_net_config['similarity'] = 'dotproduct'  # other: euclidean, cosine
-    return dict(
-        encoder=dict(
-            node_hidden_sizes=[node_state_dim],
-            node_feature_dim=1,
-            edge_hidden_sizes=[edge_state_dim]),
-        aggregator=dict(
-            node_hidden_sizes=[graph_rep_dim],
-            graph_transform_sizes=[graph_rep_dim],
-            input_size=[node_state_dim],
-            gated=True,
-            aggregation_type='sum'),
-        graph_embedding_net=graph_embedding_net_config,
-        graph_matching_net=graph_matching_net_config,
-        model_type=model_type,
-        data=dict(
-            problem='graph_edit_distance',
-            dataset_params=dict(
-                # always generate graphs with 20 nodes and p_edge=0.2.
-                n_nodes_range=[20, 20],
-                p_edge_range=[0.2, 0.2],
-                n_changes_positive=1,
-                n_changes_negative=2,
-                validation_dataset_size=1000)),
-        training=dict(
-            batch_size=20,
-            learning_rate=1e-4,
-            mode='pair',
-            loss='margin',  # other: hamming
-            margin=1.0,
-            # A small regularizer on the graph vector scales to avoid the graph
-            # vectors blowing up.  If numerical issues is particularly bad in the
-            # model we can add `snt.LayerNorm` to the outputs of each layer, the
-            # aggregated messages and aggregated node representations to
-            # keep the network activation scale in a reasonable range.
-            graph_vec_regularizer_weight=1e-6,
-            # Add gradient clipping to avoid large gradients.
-            clip_value=10.0,
-            # Increase this to train longer.
-            n_training_steps=500000,
-            # Print training information every this many training steps.
-            print_after=100,
-            # Evaluate on validation set every `eval_after * print_after` steps.
-            eval_after=10),
-        evaluation=dict(
-            batch_size=20),
-        seed=8,
-    )
diff --git a/GMN/dataset.py b/GMN/dataset.py
deleted file mode 100644
index 698e1a6..0000000
--- a/GMN/dataset.py
+++ /dev/null
@@ -1,324 +0,0 @@
-import abc
-import contextlib
-import random
-import collections
-import copy
-
-import numpy as np
-import networkx as nx
-
-"""A general Interface"""
-
-
-class GraphSimilarityDataset(object):
-    """Base class for all the graph similarity learning datasets.
-  This class defines some common interfaces a graph similarity dataset can have,
-  in particular the functions that creates iterators over pairs and triplets.
-  """
-
-    @abc.abstractmethod
-    def triplets(self, batch_size):
-        """Create an iterator over triplets.
-    Args:
-      batch_size: int, number of triplets in a batch.
-    Yields:
-      graphs: a `GraphData` instance.  The batch of triplets put together.  Each
-        triplet has 3 graphs (x, y, z).  Here the first graph is duplicated once
-        so the graphs for each triplet are ordered as (x, y, x, z) in the batch.
-        The batch contains `batch_size` number of triplets, hence `4*batch_size`
-        many graphs.
-    """
-        pass
-
-    @abc.abstractmethod
-    def pairs(self, batch_size):
-        """Create an iterator over pairs.
-    Args:
-      batch_size: int, number of pairs in a batch.
-    Yields:
-      graphs: a `GraphData` instance.  The batch of pairs put together.  Each
-        pair has 2 graphs (x, y).  The batch contains `batch_size` number of
-        pairs, hence `2*batch_size` many graphs.
-      labels: [batch_size] int labels for each pair, +1 for similar, -1 for not.
-    """
-        pass
-
-
-"""Graph Edit Distance Task"""
-
-
-# Graph Manipulation Functions
-def permute_graph_nodes(g):
-    """Permute node ordering of a graph, returns a new graph."""
-    n = g.number_of_nodes()
-    new_g = nx.Graph()
-    new_g.add_nodes_from(range(n))
-    perm = np.random.permutation(n)
-    edges = g.edges()
-    new_edges = []
-    for x, y in edges:
-        new_edges.append((perm[x], perm[y]))
-    new_g.add_edges_from(new_edges)
-    return new_g
-
-
-def substitute_random_edges(g, n):
-    """Substitutes n edges from graph g with another n randomly picked edges."""
-    g = copy.deepcopy(g)
-    n_nodes = g.number_of_nodes()
-    edges = list(g.edges())
-    # sample n edges without replacement
-    e_remove = [
-        edges[i] for i in np.random.choice(np.arange(len(edges)), n, replace=False)
-    ]
-    edge_set = set(edges)
-    e_add = set()
-    while len(e_add) < n:
-        e = np.random.choice(n_nodes, 2, replace=False)
-        # make sure e does not exist and is not already chosen to be added
-        if (
-                (e[0], e[1]) not in edge_set
-                and (e[1], e[0]) not in edge_set
-                and (e[0], e[1]) not in e_add
-                and (e[1], e[0]) not in e_add
-        ):
-            e_add.add((e[0], e[1]))
-
-    for i, j in e_remove:
-        g.remove_edge(i, j)
-    for i, j in e_add:
-        g.add_edge(i, j)
-    return g
-
-
-class GraphEditDistanceDataset(GraphSimilarityDataset):
-    """Graph edit distance dataset."""
-
-    def __init__(
-            self,
-            n_nodes_range,
-            p_edge_range,
-            n_changes_positive,
-            n_changes_negative,
-            permute=True,
-    ):
-        """Constructor.
-    Args:
-      n_nodes_range: a tuple (n_min, n_max).  The minimum and maximum number of
-        nodes in a graph to generate.
-      p_edge_range: a tuple (p_min, p_max).  The minimum and maximum edge
-        probability.
-      n_changes_positive: the number of edge substitutions for a pair to be
-        considered positive (similar).
-      n_changes_negative: the number of edge substitutions for a pair to be
-        considered negative (not similar).
-      permute: if True (default), permute node orderings in addition to
-        changing edges; if False, the node orderings across a pair or triplet of
-        graphs will be the same, useful for visualization.
-    """
-        self._n_min, self._n_max = n_nodes_range
-        self._p_min, self._p_max = p_edge_range
-        self._k_pos = n_changes_positive
-        self._k_neg = n_changes_negative
-        self._permute = permute
-
-    def _get_graph(self):
-        """Generate one graph."""
-        n_nodes = np.random.randint(self._n_min, self._n_max + 1)
-        p_edge = np.random.uniform(self._p_min, self._p_max)
-
-        # do a little bit of filtering
-        n_trials = 100
-        for _ in range(n_trials):
-            g = nx.erdos_renyi_graph(n_nodes, p_edge)
-            if nx.is_connected(g):
-                return g
-
-        raise ValueError("Failed to generate a connected graph.")
-
-    def _get_pair(self, positive):
-        """Generate one pair of graphs."""
-        g = self._get_graph()
-        if self._permute:
-            permuted_g = permute_graph_nodes(g)
-        else:
-            permuted_g = g
-        n_changes = self._k_pos if positive else self._k_neg
-        changed_g = substitute_random_edges(g, n_changes)
-        return permuted_g, changed_g
-
-    def _get_triplet(self):
-        """Generate one triplet of graphs."""
-        g = self._get_graph()
-        if self._permute:
-            permuted_g = permute_graph_nodes(g)
-        else:
-            permuted_g = g
-        pos_g = substitute_random_edges(g, self._k_pos)
-        neg_g = substitute_random_edges(g, self._k_neg)
-        return permuted_g, pos_g, neg_g
-
-    def triplets(self, batch_size):
-        """Yields batches of triplet data."""
-        while True:
-            batch_graphs = []
-            for _ in range(batch_size):
-                g1, g2, g3 = self._get_triplet()
-                batch_graphs.append((g1, g2, g1, g3))
-            yield self._pack_batch(batch_graphs)
-
-    def pairs(self, batch_size):
-        """Yields batches of pair data."""
-        while True:
-            batch_graphs = []
-            batch_labels = []
-            positive = True
-            for _ in range(batch_size):
-                g1, g2 = self._get_pair(positive)
-                batch_graphs.append((g1, g2))
-                batch_labels.append(1 if positive else -1)
-                positive = not positive
-
-            packed_graphs = self._pack_batch(batch_graphs)
-            labels = np.array(batch_labels, dtype=np.int32)
-            yield packed_graphs, labels
-
-    def _pack_batch(self, graphs):
-        """Pack a batch of graphs into a single `GraphData` instance.
-    Args:
-      graphs: a list of generated networkx graphs.
-    Returns:
-      graph_data: a `GraphData` instance, with node and edge indices properly
-        shifted.
-    """
-        Graphs = []
-        for graph in graphs:
-            for inergraph in graph:
-                Graphs.append(inergraph)
-        graphs = Graphs
-        from_idx = []
-        to_idx = []
-        graph_idx = []
-
-        n_total_nodes = 0
-        n_total_edges = 0
-        for i, g in enumerate(graphs):
-            n_nodes = g.number_of_nodes()
-            n_edges = g.number_of_edges()
-            edges = np.array(g.edges(), dtype=np.int32)
-            # shift the node indices for the edges
-            from_idx.append(edges[:, 0] + n_total_nodes)
-            to_idx.append(edges[:, 1] + n_total_nodes)
-            graph_idx.append(np.ones(n_nodes, dtype=np.int32) * i)
-
-            n_total_nodes += n_nodes
-            n_total_edges += n_edges
-
-        GraphData = collections.namedtuple('GraphData', [
-            'from_idx',
-            'to_idx',
-            'node_features',
-            'edge_features',
-            'graph_idx',
-            'n_graphs'])
-
-        return GraphData(
-            from_idx=np.concatenate(from_idx, axis=0),
-            to_idx=np.concatenate(to_idx, axis=0),
-            # this task only cares about the structures, the graphs have no features.
-            # setting higher dimension of ones to confirm code functioning
-            # with high dimensional features.
-            node_features=np.ones((n_total_nodes, 8), dtype=np.float32),
-            edge_features=np.ones((n_total_edges, 4), dtype=np.float32),
-            graph_idx=np.concatenate(graph_idx, axis=0),
-            n_graphs=len(graphs),
-        )
-
-
-# Use Fixed datasets for evaluation
-@contextlib.contextmanager
-def reset_random_state(seed):
-    """This function creates a context that uses the given seed."""
-    np_rnd_state = np.random.get_state()
-    rnd_state = random.getstate()
-    np.random.seed(seed)
-    random.seed(seed + 1)
-    try:
-        yield
-    finally:
-        random.setstate(rnd_state)
-        np.random.set_state(np_rnd_state)
-
-
-class FixedGraphEditDistanceDataset(GraphEditDistanceDataset):
-    """A fixed dataset of pairs or triplets for the graph edit distance task.
-  This dataset can be used for evaluation.
-  """
-
-    def __init__(
-            self,
-            n_nodes_range,
-            p_edge_range,
-            n_changes_positive,
-            n_changes_negative,
-            dataset_size,
-            permute=True,
-            seed=1234,
-    ):
-        super(FixedGraphEditDistanceDataset, self).__init__(
-            n_nodes_range,
-            p_edge_range,
-            n_changes_positive,
-            n_changes_negative,
-            permute=permute,
-        )
-        self._dataset_size = dataset_size
-        self._seed = seed
-
-    def triplets(self, batch_size):
-        """Yield triplets."""
-
-        if hasattr(self, "_triplets"):
-            triplets = self._triplets
-        else:
-            # get a fixed set of triplets
-            with reset_random_state(self._seed):
-                triplets = []
-                for _ in range(self._dataset_size):
-                    g1, g2, g3 = self._get_triplet()
-                    triplets.append((g1, g2, g1, g3))
-            self._triplets = triplets
-
-        ptr = 0
-        while ptr + batch_size <= len(triplets):
-            batch_graphs = triplets[ptr: ptr + batch_size]
-            yield self._pack_batch(batch_graphs)
-            ptr += batch_size
-
-    def pairs(self, batch_size):
-        """Yield pairs and labels."""
-
-        if hasattr(self, "_pairs") and hasattr(self, "_labels"):
-            pairs = self._pairs
-            labels = self._labels
-        else:
-            # get a fixed set of pairs first
-            with reset_random_state(self._seed):
-                pairs = []
-                labels = []
-                positive = True
-                for _ in range(self._dataset_size):
-                    pairs.append(self._get_pair(positive))
-                    labels.append(1 if positive else -1)
-                    positive = not positive
-            labels = np.array(labels, dtype=np.int32)
-
-            self._pairs = pairs
-            self._labels = labels
-
-        ptr = 0
-        while ptr + batch_size <= len(pairs):
-            batch_graphs = pairs[ptr: ptr + batch_size]
-            packed_batch = self._pack_batch(batch_graphs)
-            yield packed_batch, labels[ptr: ptr + batch_size]
-            ptr += batch_size
diff --git a/GMN/evaluation.py b/GMN/evaluation.py
deleted file mode 100644
index 067243e..0000000
--- a/GMN/evaluation.py
+++ /dev/null
@@ -1,59 +0,0 @@
-from sklearn import metrics
-from loss import *
-
-
-def exact_hamming_similarity(x, y):
-    """Compute the binary Hamming similarity."""
-    match = ((x > 0) * (y > 0)).float()
-    return torch.mean(match, dim=1)
-
-
-def compute_similarity(config, x, y):
-    """Compute the distance between x and y vectors.
-
-    The distance will be computed based on the training loss type.
-
-    Args:
-      config: a config dict.
-      x: [n_examples, feature_dim] float tensor.
-      y: [n_examples, feature_dim] float tensor.
-
-    Returns:
-      dist: [n_examples] float tensor.
-
-    Raises:
-      ValueError: if loss type is not supported.
-    """
-    if config['training']['loss'] == 'margin':
-        # similarity is negative distance
-        return -euclidean_distance(x, y)
-    elif config['training']['loss'] == 'hamming':
-        return exact_hamming_similarity(x, y)
-    else:
-        raise ValueError('Unknown loss type %s' % config['training']['loss'])
-
-
-def auc(scores, labels, **auc_args):
-    """Compute the AUC for pair classification.
-
-    See `tf.metrics.auc` for more details about this metric.
-
-    Args:
-      scores: [n_examples] float.  Higher scores mean higher preference of being
-        assigned the label of +1.
-      labels: [n_examples] int.  Labels are either +1 or -1.
-      **auc_args: other arguments that can be used by `tf.metrics.auc`.
-
-    Returns:
-      auc: the area under the ROC curve.
-    """
-    scores_max = torch.max(scores)
-    scores_min = torch.min(scores)
-
-    # normalize scores to [0, 1] and add a small epislon for safety
-    scores = (scores - scores_min) / (scores_max - scores_min + 1e-8)
-
-    labels = (labels + 1) / 2
-
-    fpr, tpr, thresholds = metrics.roc_curve(labels.cpu().detach().numpy(), scores.cpu().detach().numpy())
-    return metrics.auc(fpr, tpr)
diff --git a/GMN/graphembeddingnetwork.py b/GMN/graphembeddingnetwork.py
deleted file mode 100644
index 2659f37..0000000
--- a/GMN/graphembeddingnetwork.py
+++ /dev/null
@@ -1,603 +0,0 @@
-import torch
-import torch.nn as nn
-try:
-    from segment import unsorted_segment_sum
-except:
-    from .segment import unsorted_segment_sum
-
-
-class GraphEncoder(nn.Module):
-    """Encoder module that projects node and edge features to some embeddings."""
-
-    def __init__(self,
-                 node_feature_dim,
-                 edge_feature_dim,
-                 node_hidden_sizes=None,
-                 edge_hidden_sizes=None,
-                 name='graph-encoder'):
-        """Constructor.
-
-        Args:
-          node_hidden_sizes: if provided should be a list of ints, hidden sizes of
-            node encoder network, the last element is the size of the node outputs.
-            If not provided, node features will pass through as is.
-          edge_hidden_sizes: if provided should be a list of ints, hidden sizes of
-            edge encoder network, the last element is the size of the edge outptus.
-            If not provided, edge features will pass through as is.
-          name: name of this module.
-        """
-        super(GraphEncoder, self).__init__()
-
-        # this also handles the case of an empty list
-        self._node_feature_dim = node_feature_dim
-        self._edge_feature_dim = edge_feature_dim
-        self._node_hidden_sizes = node_hidden_sizes if node_hidden_sizes else None
-        self._edge_hidden_sizes = edge_hidden_sizes
-        self._build_model()
-
-    def _build_model(self):
-        layer = []
-        layer.append(nn.Linear(self._node_feature_dim, self._node_hidden_sizes[0]))
-        for i in range(1, len(self._node_hidden_sizes)):
-            layer.append(nn.ReLU())
-            layer.append(nn.Linear(self._node_hidden_sizes[i - 1], self._node_hidden_sizes[i]))
-        self.MLP1 = nn.Sequential(*layer)
-
-        if self._edge_hidden_sizes is not None:
-            layer = []
-            layer.append(nn.Linear(self._edge_feature_dim, self._edge_hidden_sizes[0]))
-            for i in range(1, len(self._edge_hidden_sizes)):
-                layer.append(nn.ReLU())
-                layer.append(nn.Linear(self._edge_hidden_sizes[i - 1], self._edge_hidden_sizes[i]))
-            self.MLP2 = nn.Sequential(*layer)
-        else:
-            self.MLP2 = None
-
-    def forward(self, node_features, edge_features=None):
-        """Encode node and edge features.
-
-        Args:
-          node_features: [n_nodes, node_feat_dim] float tensor.
-          edge_features: if provided, should be [n_edges, edge_feat_dim] float
-            tensor.
-
-        Returns:
-          node_outputs: [n_nodes, node_embedding_dim] float tensor, node embeddings.
-          edge_outputs: if edge_features is not None and edge_hidden_sizes is not
-            None, this is [n_edges, edge_embedding_dim] float tensor, edge
-            embeddings; otherwise just the input edge_features.
-        """
-        if self._node_hidden_sizes is None:
-            node_outputs = node_features
-        else:
-            node_outputs = self.MLP1(node_features)
-        if edge_features is None or self._edge_hidden_sizes is None:
-            edge_outputs = edge_features
-        else:
-            edge_outputs = self.MLP2(edge_features)
-
-        return node_outputs, edge_outputs
-
-
-def graph_prop_once(node_states,
-                    from_idx,
-                    to_idx,
-                    message_net,
-                    aggregation_module=None,
-                    edge_features=None):
-    """One round of propagation (message passing) in a graph.
-
-    Args:
-      node_states: [n_nodes, node_state_dim] float tensor, node state vectors, one
-        row for each node.
-      from_idx: [n_edges] int tensor, index of the from nodes.
-      to_idx: [n_edges] int tensor, index of the to nodes.
-      message_net: a network that maps concatenated edge inputs to message
-        vectors.
-      aggregation_module: a module that aggregates messages on edges to aggregated
-        messages for each node.  Should be a callable and can be called like the
-        following,
-        `aggregated_messages = aggregation_module(messages, to_idx, n_nodes)`,
-        where messages is [n_edges, edge_message_dim] tensor, to_idx is the index
-        of the to nodes, i.e. where each message should go to, and n_nodes is an
-        int which is the number of nodes to aggregate into.
-      edge_features: if provided, should be a [n_edges, edge_feature_dim] float
-        tensor, extra features for each edge.
-
-    Returns:
-      aggregated_messages: an [n_nodes, edge_message_dim] float tensor, the
-        aggregated messages, one row for each node.
-    """
-    from_states = node_states[from_idx]
-    to_states = node_states[to_idx]
-    edge_inputs = [from_states, to_states]
-
-    if edge_features is not None:
-        edge_inputs.append(edge_features)
-
-    edge_inputs = torch.cat(edge_inputs, dim=-1)
-    messages = message_net(edge_inputs)
-
-    from segment import unsorted_segment_sum
-    tensor = unsorted_segment_sum(messages, to_idx, node_states.shape[0])
-    return tensor
-
-class GraphPropLayer(nn.Module):
-    """Implementation of a graph propagation (message passing) layer."""
-
-    def __init__(self,
-                 node_state_dim,
-                 edge_state_dim,
-                 edge_hidden_sizes,  # int
-                 node_hidden_sizes,  # int
-                 edge_net_init_scale=0.1,
-                 node_update_type='residual',
-                 use_reverse_direction=True,
-                 reverse_dir_param_different=True,
-                 layer_norm=False,
-                 prop_type='embedding',
-                 name='graph-net'):
-        """Constructor.
-
-        Args:
-          node_state_dim: int, dimensionality of node states.
-          edge_hidden_sizes: list of ints, hidden sizes for the edge message
-            net, the last element in the list is the size of the message vectors.
-          node_hidden_sizes: list of ints, hidden sizes for the node update
-            net.
-          edge_net_init_scale: initialization scale for the edge networks.  This
-            is typically set to a small value such that the gradient does not blow
-            up.
-          node_update_type: type of node updates, one of {mlp, gru, residual}.
-          use_reverse_direction: set to True to also propagate messages in the
-            reverse direction.
-          reverse_dir_param_different: set to True to have the messages computed
-            using a different set of parameters than for the forward direction.
-          layer_norm: set to True to use layer normalization in a few places.
-          name: name of this module.
-        """
-        super(GraphPropLayer, self).__init__()
-
-        self._node_state_dim = node_state_dim
-        self._edge_state_dim = edge_state_dim
-        self._edge_hidden_sizes = edge_hidden_sizes[:]
-
-        # output size is node_state_dim
-        self._node_hidden_sizes = node_hidden_sizes[:] + [node_state_dim]
-        self._edge_net_init_scale = edge_net_init_scale
-        self._node_update_type = node_update_type
-
-        self._use_reverse_direction = use_reverse_direction
-        self._reverse_dir_param_different = reverse_dir_param_different
-
-        self._layer_norm = layer_norm
-        self._prop_type = prop_type
-        self.build_model()
-
-        if self._layer_norm:
-            self.layer_norm1 = nn.LayerNorm()
-            self.layer_norm2 = nn.LayerNorm()
-
-    def build_model(self):
-        layer = []
-        layer.append(nn.Linear(self._node_state_dim*2 + self._edge_state_dim, self._edge_hidden_sizes[0]))
-        for i in range(1, len(self._edge_hidden_sizes)):
-            layer.append(nn.ReLU())
-            layer.append(nn.Linear(self._edge_hidden_sizes[i - 1], self._edge_hidden_sizes[i]))
-        self._message_net = nn.Sequential(*layer)
-
-        # optionally compute message vectors in the reverse direction
-        if self._use_reverse_direction:
-            if self._reverse_dir_param_different:
-                layer = []
-                layer.append(nn.Linear(self._node_state_dim*2 + self._edge_state_dim, self._edge_hidden_sizes[0]))
-                for i in range(1, len(self._edge_hidden_sizes)):
-                    layer.append(nn.ReLU())
-                    layer.append(nn.Linear(self._edge_hidden_sizes[i - 1], self._edge_hidden_sizes[i]))
-                self._reverse_message_net = nn.Sequential(*layer)
-            else:
-                self._reverse_message_net = self._message_net
-
-        if self._node_update_type == 'gru':
-            if self._prop_type == 'embedding':
-                self.GRU = torch.nn.GRU(self._node_state_dim * 2, self._node_state_dim)
-            elif self._prop_type == 'matching':
-                self.GRU = torch.nn.GRU(self._node_state_dim * 3, self._node_state_dim)
-        else:
-            layer = []
-            if self._prop_type == 'embedding':
-                layer.append(nn.Linear(self._node_state_dim * 3, self._node_hidden_sizes[0]))
-            elif self._prop_type == 'matching':
-                layer.append(nn.Linear(self._node_state_dim * 4, self._node_hidden_sizes[0]))
-            for i in range(1, len(self._node_hidden_sizes)):
-                layer.append(nn.ReLU())
-                layer.append(nn.Linear(self._node_hidden_sizes[i - 1], self._node_hidden_sizes[i]))
-            self.MLP = nn.Sequential(*layer)
-
-    def _compute_aggregated_messages(
-            self, node_states, from_idx, to_idx, edge_features=None):
-        """Compute aggregated messages for each node.
-
-        Args:
-          node_states: [n_nodes, input_node_state_dim] float tensor, node states.
-          from_idx: [n_edges] int tensor, from node indices for each edge.
-          to_idx: [n_edges] int tensor, to node indices for each edge.
-          edge_features: if not None, should be [n_edges, edge_embedding_dim]
-            tensor, edge features.
-
-        Returns:
-          aggregated_messages: [n_nodes, aggregated_message_dim] float tensor, the
-            aggregated messages for each node.
-        """
-
-        aggregated_messages = graph_prop_once(
-            node_states,
-            from_idx,
-            to_idx,
-            self._message_net,
-            aggregation_module=None,
-            edge_features=edge_features)
-
-        # optionally compute message vectors in the reverse direction
-        if self._use_reverse_direction:
-            reverse_aggregated_messages = graph_prop_once(
-                node_states,
-                to_idx,
-                from_idx,
-                self._reverse_message_net,
-                aggregation_module=None,
-                edge_features=edge_features)
-
-            aggregated_messages += reverse_aggregated_messages
-
-        if self._layer_norm:
-            aggregated_messages = self.layer_norm1(aggregated_messages)
-
-        return aggregated_messages
-
-    def _compute_node_update(self,
-                             node_states,
-                             node_state_inputs,
-                             node_features=None):
-        """Compute node updates.
-
-        Args:
-          node_states: [n_nodes, node_state_dim] float tensor, the input node
-            states.
-          node_state_inputs: a list of tensors used to compute node updates.  Each
-            element tensor should have shape [n_nodes, feat_dim], where feat_dim can
-            be different.  These tensors will be concatenated along the feature
-            dimension.
-          node_features: extra node features if provided, should be of size
-            [n_nodes, extra_node_feat_dim] float tensor, can be used to implement
-            different types of skip connections.
-
-        Returns:
-          new_node_states: [n_nodes, node_state_dim] float tensor, the new node
-            state tensor.
-
-        Raises:
-          ValueError: if node update type is not supported.
-        """
-        if self._node_update_type in ('mlp', 'residual'):
-            node_state_inputs.append(node_states)
-        if node_features is not None:
-            node_state_inputs.append(node_features)
-
-        if len(node_state_inputs) == 1:
-            node_state_inputs = node_state_inputs[0]
-        else:
-            node_state_inputs = torch.cat(node_state_inputs, dim=-1)
-
-        if self._node_update_type == 'gru':
-            node_state_inputs = torch.unsqueeze(node_state_inputs, 0)
-            node_states = torch.unsqueeze(node_states, 0)
-            _, new_node_states = self.GRU(node_state_inputs, node_states)
-            new_node_states = torch.squeeze(new_node_states)
-            return new_node_states
-        else:
-            mlp_output = self.MLP(node_state_inputs)
-            if self._layer_norm:
-                mlp_output = nn.self.layer_norm2(mlp_output)
-            if self._node_update_type == 'mlp':
-                return mlp_output
-            elif self._node_update_type == 'residual':
-                return node_states + mlp_output
-            else:
-                raise ValueError('Unknown node update type %s' % self._node_update_type)
-
-    def forward(self,
-                node_states,
-                from_idx,
-                to_idx,
-                edge_features=None,
-                node_features=None):
-        """Run one propagation step.
-
-        Args:
-          node_states: [n_nodes, input_node_state_dim] float tensor, node states.
-          from_idx: [n_edges] int tensor, from node indices for each edge.
-          to_idx: [n_edges] int tensor, to node indices for each edge.
-          edge_features: if not None, should be [n_edges, edge_embedding_dim]
-            tensor, edge features.
-          node_features: extra node features if provided, should be of size
-            [n_nodes, extra_node_feat_dim] float tensor, can be used to implement
-            different types of skip connections.
-
-        Returns:
-          node_states: [n_nodes, node_state_dim] float tensor, new node states.
-        """
-        aggregated_messages = self._compute_aggregated_messages(
-            node_states, from_idx, to_idx, edge_features=edge_features)
-
-        return self._compute_node_update(node_states,
-                                         [aggregated_messages],
-                                         node_features=node_features)
-
-
-class GraphAggregator(nn.Module):
-    """This module computes graph representations by aggregating from parts."""
-
-    def __init__(self,
-                 node_hidden_sizes,
-                 graph_transform_sizes=None,
-                 input_size=None,
-                 gated=True,
-                 aggregation_type='sum',
-                 name='graph-aggregator'):
-        """Constructor.
-
-        Args:
-          node_hidden_sizes: the hidden layer sizes of the node transformation nets.
-            The last element is the size of the aggregated graph representation.
-
-          graph_transform_sizes: sizes of the transformation layers on top of the
-            graph representations.  The last element of this list is the final
-            dimensionality of the output graph representations.
-
-          gated: set to True to do gated aggregation, False not to.
-
-          aggregation_type: one of {sum, max, mean, sqrt_n}.
-          name: name of this module.
-        """
-        super(GraphAggregator, self).__init__()
-
-        self._node_hidden_sizes = node_hidden_sizes
-        self._graph_transform_sizes = graph_transform_sizes
-        self._graph_state_dim = node_hidden_sizes[-1]
-        self._input_size = input_size
-        #  The last element is the size of the aggregated graph representation.
-        self._gated = gated
-        self._aggregation_type = aggregation_type
-        self._aggregation_op = None
-        self.MLP1, self.MLP2 = self.build_model()
-
-    def build_model(self):
-        node_hidden_sizes = self._node_hidden_sizes
-        if self._gated:
-            node_hidden_sizes[-1] = self._graph_state_dim * 2
-
-        layer = []
-        layer.append(nn.Linear(self._input_size[0], node_hidden_sizes[0]))
-        for i in range(1, len(node_hidden_sizes)):
-            layer.append(nn.ReLU())
-            layer.append(nn.Linear(node_hidden_sizes[i - 1], node_hidden_sizes[i]))
-        MLP1 = nn.Sequential(*layer)
-
-        if (self._graph_transform_sizes is not None and
-                len(self._graph_transform_sizes) > 0):
-            layer = []
-            layer.append(nn.Linear(self._graph_state_dim, self._graph_transform_sizes[0]))
-            for i in range(1, len(self._graph_transform_sizes)):
-                layer.append(nn.ReLU())
-                layer.append(nn.Linear(self._graph_transform_sizes[i - 1], self._graph_transform_sizes[i]))
-            MLP2 = nn.Sequential(*layer)
-
-        return MLP1, MLP2
-
-    def forward(self, node_states, graph_idx, n_graphs):
-        """Compute aggregated graph representations.
-
-        Args:
-          node_states: [n_nodes, node_state_dim] float tensor, node states of a
-            batch of graphs concatenated together along the first dimension.
-          graph_idx: [n_nodes] int tensor, graph ID for each node.
-          n_graphs: integer, number of graphs in this batch.
-
-        Returns:
-          graph_states: [n_graphs, graph_state_dim] float tensor, graph
-            representations, one row for each graph.
-        """
-
-        node_states_g = self.MLP1(node_states)
-
-        if self._gated:
-            gates = torch.sigmoid(node_states_g[:, :self._graph_state_dim])
-            node_states_g = node_states_g[:, self._graph_state_dim:] * gates
-
-        graph_states = unsorted_segment_sum(node_states_g, graph_idx, n_graphs)
-
-        if self._aggregation_type == 'max':
-            # reset everything that's smaller than -1e5 to 0.
-            graph_states *= torch.FloatTensor(graph_states > -1e5)
-        # transform the reduced graph states further
-
-
-        if (self._graph_transform_sizes is not None and
-                len(self._graph_transform_sizes) > 0):
-            graph_states = self.MLP2(graph_states)
-
-        return graph_states
-
-class GraphEmbeddingNet(nn.Module):
-    """A graph to embedding mapping network."""
-
-    def __init__(self,
-                 encoder,
-                 aggregator,
-                 node_state_dim,
-                 edge_state_dim,
-                 edge_hidden_sizes,
-                 node_hidden_sizes,
-                 n_prop_layers,
-                 share_prop_params=False,
-                 edge_net_init_scale=0.1,
-                 node_update_type='residual',
-                 use_reverse_direction=True,
-                 reverse_dir_param_different=True,
-                 layer_norm=False,
-                 layer_class=GraphPropLayer,
-                 prop_type='embedding',
-                 name='graph-embedding-net'):
-        """Constructor.
-
-        Args:
-          encoder: GraphEncoder, encoder that maps features to embeddings.
-          aggregator: GraphAggregator, aggregator that produces graph
-            representations.
-
-          node_state_dim: dimensionality of node states.
-          edge_hidden_sizes: sizes of the hidden layers of the edge message nets.
-          node_hidden_sizes: sizes of the hidden layers of the node update nets.
-
-          n_prop_layers: number of graph propagation layers.
-
-          share_prop_params: set to True to share propagation parameters across all
-            graph propagation layers, False not to.
-          edge_net_init_scale: scale of initialization for the edge message nets.
-          node_update_type: type of node updates, one of {mlp, gru, residual}.
-          use_reverse_direction: set to True to also propagate messages in the
-            reverse direction.
-          reverse_dir_param_different: set to True to have the messages computed
-            using a different set of parameters than for the forward direction.
-
-          layer_norm: set to True to use layer normalization in a few places.
-          name: name of this module.
-        """
-        super(GraphEmbeddingNet, self).__init__()
-
-        self._encoder = encoder
-        self._aggregator = aggregator
-        self._node_state_dim = node_state_dim
-        self._edge_state_dim = edge_state_dim
-        self._edge_hidden_sizes = edge_hidden_sizes
-        self._node_hidden_sizes = node_hidden_sizes
-        self._n_prop_layers = n_prop_layers
-        self._share_prop_params = share_prop_params
-        self._edge_net_init_scale = edge_net_init_scale
-        self._node_update_type = node_update_type
-        self._use_reverse_direction = use_reverse_direction
-        self._reverse_dir_param_different = reverse_dir_param_different
-        self._layer_norm = layer_norm
-        self._prop_layers = []
-        self._prop_layers = nn.ModuleList()
-        self._layer_class = layer_class
-        self._prop_type = prop_type
-        self.build_model()
-
-    def _build_layer(self, layer_id):
-        """Build one layer in the network."""
-        return self._layer_class(
-            self._node_state_dim,
-            self._edge_state_dim,
-            self._edge_hidden_sizes,
-            self._node_hidden_sizes,
-            edge_net_init_scale=self._edge_net_init_scale,
-            node_update_type=self._node_update_type,
-            use_reverse_direction=self._use_reverse_direction,
-            reverse_dir_param_different=self._reverse_dir_param_different,
-            layer_norm=self._layer_norm,
-            prop_type=self._prop_type)
-        # name='graph-prop-%d' % layer_id)
-
-    def _apply_layer(self,
-                     layer,
-                     node_states,
-                     from_idx,
-                     to_idx,
-                     graph_idx,
-                     n_graphs,
-                     edge_features):
-        """Apply one layer on the given inputs."""
-        del graph_idx, n_graphs
-        return layer(node_states, from_idx, to_idx, edge_features=edge_features)
-
-    def build_model(self):
-        if len(self._prop_layers) < self._n_prop_layers:
-            # build the layers
-            for i in range(self._n_prop_layers):
-                if i == 0 or not self._share_prop_params:
-                    layer = self._build_layer(i)
-                else:
-                    layer = self._prop_layers[0]
-                self._prop_layers.append(layer)
-
-    def forward(self,
-                node_features,
-                edge_features,
-                from_idx,
-                to_idx,
-                graph_idx,
-                n_graphs):
-        """Compute graph representations.
-
-        Args:
-          node_features: [n_nodes, node_feat_dim] float tensor.
-          edge_features: [n_edges, edge_feat_dim] float tensor.
-          from_idx: [n_edges] int tensor, index of the from node for each edge.
-          to_idx: [n_edges] int tensor, index of the to node for each edge.
-          graph_idx: [n_nodes] int tensor, graph id for each node.
-          n_graphs: int, number of graphs in the batch.
-
-        Returns:
-          graph_representations: [n_graphs, graph_representation_dim] float tensor,
-            graph representations.
-        """
-
-        node_features, edge_features = self._encoder(node_features, edge_features)
-        node_states = node_features
-
-        layer_outputs = [node_states]
-
-        for layer in self._prop_layers:
-            # node_features could be wired in here as well, leaving it out for now as
-            # it is already in the inputs
-            node_states = self._apply_layer(
-                layer,
-                node_states,
-                from_idx,
-                to_idx,
-                graph_idx,
-                n_graphs,
-                edge_features)
-            layer_outputs.append(node_states)
-
-        # these tensors may be used e.g. for visualization
-        self._layer_outputs = layer_outputs
-        return self._aggregator(node_states, graph_idx, n_graphs)
-
-    def reset_n_prop_layers(self, n_prop_layers):
-        """Set n_prop_layers to the provided new value.
-
-        This allows us to train with certain number of propagation layers and
-        evaluate with a different number of propagation layers.
-
-        This only works if n_prop_layers is smaller than the number used for
-        training, or when share_prop_params is set to True, in which case this can
-        be arbitrarily large.
-
-        Args:
-          n_prop_layers: the new number of propagation layers to set.
-        """
-        self._n_prop_layers = n_prop_layers
-
-    @property
-    def n_prop_layers(self):
-        return self._n_prop_layers
-
-    def get_layer_outputs(self):
-        """Get the outputs at each layer."""
-        if hasattr(self, '_layer_outputs'):
-            return self._layer_outputs
-        else:
-            raise ValueError('No layer outputs available.')
diff --git a/GMN/graphmatchingnetwork.py b/GMN/graphmatchingnetwork.py
deleted file mode 100644
index f173b0b..0000000
--- a/GMN/graphmatchingnetwork.py
+++ /dev/null
@@ -1,281 +0,0 @@
-try:
-    from graphembeddingnetwork import GraphEmbeddingNet
-    from graphembeddingnetwork import GraphPropLayer
-except:
-    from .graphembeddingnetwork import GraphEmbeddingNet
-    from .graphembeddingnetwork import GraphPropLayer
-import torch
-
-
-def pairwise_euclidean_similarity(x, y):
-    """Compute the pairwise Euclidean similarity between x and y.
-
-    This function computes the following similarity value between each pair of x_i
-    and y_j: s(x_i, y_j) = -|x_i - y_j|^2.
-
-    Args:
-      x: NxD float tensor.
-      y: MxD float tensor.
-
-    Returns:
-      s: NxM float tensor, the pairwise euclidean similarity.
-    """
-    s = 2 * torch.mm(x, torch.transpose(y, 1, 0))
-    diag_x = torch.sum(x * x, dim=-1)
-    diag_x = torch.unsqueeze(diag_x, 0)
-    diag_y = torch.reshape(torch.sum(y * y, dim=-1), (1, -1))
-
-    return s - diag_x - diag_y
-
-
-def pairwise_dot_product_similarity(x, y):
-    """Compute the dot product similarity between x and y.
-
-    This function computes the following similarity value between each pair of x_i
-    and y_j: s(x_i, y_j) = x_i^T y_j.
-
-    Args:
-      x: NxD float tensor.
-      y: MxD float tensor.
-
-    Returns:
-      s: NxM float tensor, the pairwise dot product similarity.
-    """
-    return torch.mm(x, torch.transpose(y, 1, 0))
-
-
-def pairwise_cosine_similarity(x, y):
-    """Compute the cosine similarity between x and y.
-
-    This function computes the following similarity value between each pair of x_i
-    and y_j: s(x_i, y_j) = x_i^T y_j / (|x_i||y_j|).
-
-    Args:
-      x: NxD float tensor.
-      y: MxD float tensor.
-
-    Returns:
-      s: NxM float tensor, the pairwise cosine similarity.
-    """
-    x = torch.div(x, torch.sqrt(torch.max(torch.sum(x ** 2), 1e-12)))
-    y = torch.div(y, torch.sqrt(torch.max(torch.sum(y ** 2), 1e-12)))
-    return torch.mm(x, torch.transpose(y, 1, 0))
-
-
-PAIRWISE_SIMILARITY_FUNCTION = {
-    'euclidean': pairwise_euclidean_similarity,
-    'dotproduct': pairwise_dot_product_similarity,
-    'cosine': pairwise_cosine_similarity,
-}
-
-
-def get_pairwise_similarity(name):
-    """Get pairwise similarity metric by name.
-
-    Args:
-      name: string, name of the similarity metric, one of {dot-product, cosine,
-        euclidean}.
-
-    Returns:
-      similarity: a (x, y) -> sim function.
-
-    Raises:
-      ValueError: if name is not supported.
-    """
-    if name not in PAIRWISE_SIMILARITY_FUNCTION:
-        raise ValueError('Similarity metric name "%s" not supported.' % name)
-    else:
-        return PAIRWISE_SIMILARITY_FUNCTION[name]
-
-
-def compute_cross_attention(x, y, sim):
-    """Compute cross attention.
-
-    x_i attend to y_j:
-    a_{i->j} = exp(sim(x_i, y_j)) / sum_j exp(sim(x_i, y_j))
-    y_j attend to x_i:
-    a_{j->i} = exp(sim(x_i, y_j)) / sum_i exp(sim(x_i, y_j))
-    attention_x = sum_j a_{i->j} y_j
-    attention_y = sum_i a_{j->i} x_i
-
-    Args:
-      x: NxD float tensor.
-      y: MxD float tensor.
-      sim: a (x, y) -> similarity function.
-
-    Returns:
-      attention_x: NxD float tensor.
-      attention_y: NxD float tensor.
-    """
-    a = sim(x, y)
-    a_x = torch.softmax(a, dim=1)  # i->j
-    a_y = torch.softmax(a, dim=0)  # j->i
-    attention_x = torch.mm(a_x, y)
-    attention_y = torch.mm(torch.transpose(a_y, 1, 0), x)
-    return attention_x, attention_y
-
-
-def batch_block_pair_attention(data,
-                               block_idx,
-                               n_blocks,
-                               similarity='dotproduct'):
-    """Compute batched attention between pairs of blocks.
-
-    This function partitions the batch data into blocks according to block_idx.
-    For each pair of blocks, x = data[block_idx == 2i], and
-    y = data[block_idx == 2i+1], we compute
-
-    x_i attend to y_j:
-    a_{i->j} = exp(sim(x_i, y_j)) / sum_j exp(sim(x_i, y_j))
-    y_j attend to x_i:
-    a_{j->i} = exp(sim(x_i, y_j)) / sum_i exp(sim(x_i, y_j))
-
-    and
-
-    attention_x = sum_j a_{i->j} y_j
-    attention_y = sum_i a_{j->i} x_i.
-
-    Args:
-      data: NxD float tensor.
-      block_idx: N-dim int tensor.
-      n_blocks: integer.
-      similarity: a string, the similarity metric.
-
-    Returns:
-      attention_output: NxD float tensor, each x_i replaced by attention_x_i.
-
-    Raises:
-      ValueError: if n_blocks is not an integer or not a multiple of 2.
-    """
-    if not isinstance(n_blocks, int):
-        raise ValueError('n_blocks (%s) has to be an integer.' % str(n_blocks))
-
-    if n_blocks % 2 != 0:
-        raise ValueError('n_blocks (%d) must be a multiple of 2.' % n_blocks)
-
-    sim = get_pairwise_similarity(similarity)
-
-    results = []
-
-    # This is probably better than doing boolean_mask for each i
-    partitions = []
-    for i in range(n_blocks):
-        partitions.append(data[block_idx == i, :])
-
-    for i in range(0, n_blocks, 2):
-        x = partitions[i]
-        y = partitions[i + 1]
-        attention_x, attention_y = compute_cross_attention(x, y, sim)
-        results.append(attention_x)
-        results.append(attention_y)
-    results = torch.cat(results, dim=0)
-
-    return results
-
-
-class GraphPropMatchingLayer(GraphPropLayer):
-    """A graph propagation layer that also does cross graph matching.
-
-    It assumes the incoming graph data is batched and paired, i.e. graph 0 and 1
-    forms the first pair and graph 2 and 3 are the second pair etc., and computes
-    cross-graph attention-based matching for each pair.
-    """
-
-    def forward(self,
-                node_states,
-                from_idx,
-                to_idx,
-                graph_idx,
-                n_graphs,
-                similarity='dotproduct',
-                edge_features=None,
-                node_features=None):
-        """Run one propagation step with cross-graph matching.
-
-        Args:
-          node_states: [n_nodes, node_state_dim] float tensor, node states.
-          from_idx: [n_edges] int tensor, from node indices for each edge.
-          to_idx: [n_edges] int tensor, to node indices for each edge.
-          graph_idx: [n_onodes] int tensor, graph id for each node.
-          n_graphs: integer, number of graphs in the batch.
-          similarity: type of similarity to use for the cross graph attention.
-          edge_features: if not None, should be [n_edges, edge_feat_dim] tensor,
-            extra edge features.
-          node_features: if not None, should be [n_nodes, node_feat_dim] tensor,
-            extra node features.
-
-        Returns:
-          node_states: [n_nodes, node_state_dim] float tensor, new node states.
-
-        Raises:
-          ValueError: if some options are not provided correctly.
-        """
-        aggregated_messages = self._compute_aggregated_messages(
-            node_states, from_idx, to_idx, edge_features=edge_features)
-
-        cross_graph_attention = batch_block_pair_attention(
-            node_states, graph_idx, n_graphs, similarity=similarity)
-        attention_input = node_states - cross_graph_attention
-
-        return self._compute_node_update(node_states,
-                                         [aggregated_messages, attention_input],
-                                         node_features=node_features)
-
-
-class GraphMatchingNet(GraphEmbeddingNet):
-    """Graph matching net.
-
-    This class uses graph matching layers instead of the simple graph prop layers.
-
-    It assumes the incoming graph data is batched and paired, i.e. graph 0 and 1
-    forms the first pair and graph 2 and 3 are the second pair etc., and computes
-    cross-graph attention-based matching for each pair.
-    """
-
-    def __init__(self,
-                 encoder,
-                 aggregator,
-                 node_state_dim,
-                 edge_state_dim,
-                 edge_hidden_sizes,
-                 node_hidden_sizes,
-                 n_prop_layers,
-                 share_prop_params=False,
-                 edge_net_init_scale=0.1,
-                 node_update_type='residual',
-                 use_reverse_direction=True,
-                 reverse_dir_param_different=True,
-                 layer_norm=False,
-                 layer_class=GraphPropLayer,
-                 similarity='dotproduct',
-                 prop_type='embedding'):
-        super(GraphMatchingNet, self).__init__(
-            encoder,
-            aggregator,
-            node_state_dim,
-            edge_state_dim,
-            edge_hidden_sizes,
-            node_hidden_sizes,
-            n_prop_layers,
-            share_prop_params=share_prop_params,
-            edge_net_init_scale=edge_net_init_scale,
-            node_update_type=node_update_type,
-            use_reverse_direction=use_reverse_direction,
-            reverse_dir_param_different=reverse_dir_param_different,
-            layer_norm=layer_norm,
-            layer_class=GraphPropMatchingLayer,
-            prop_type=prop_type,
-        )
-        self._similarity = similarity
-
-    def _apply_layer(self,
-                     layer,
-                     node_states,
-                     from_idx,
-                     to_idx,
-                     graph_idx,
-                     n_graphs,
-                     edge_features):
-        """Apply one layer on the given inputs."""
-        return layer(node_states, from_idx, to_idx, graph_idx, n_graphs,
-                     similarity=self._similarity, edge_features=edge_features)
diff --git a/GMN/loss.py b/GMN/loss.py
deleted file mode 100644
index 53819bf..0000000
--- a/GMN/loss.py
+++ /dev/null
@@ -1,66 +0,0 @@
-import torch
-
-
-def euclidean_distance(x, y):
-    """This is the squared Euclidean distance."""
-    return torch.sum((x - y) ** 2, dim=-1)
-
-
-def approximate_hamming_similarity(x, y):
-    """Approximate Hamming similarity."""
-    return torch.mean(torch.tanh(x) * torch.tanh(y), dim=1)
-
-
-def pairwise_loss(x, y, labels, loss_type='margin', margin=1.0):
-    """Compute pairwise loss.
-
-    Args:
-      x: [N, D] float tensor, representations for N examples.
-      y: [N, D] float tensor, representations for another N examples.
-      labels: [N] int tensor, with values in -1 or +1.  labels[i] = +1 if x[i]
-        and y[i] are similar, and -1 otherwise.
-      loss_type: margin or hamming.
-      margin: float scalar, margin for the margin loss.
-
-    Returns:
-      loss: [N] float tensor.  Loss for each pair of representations.
-    """
-
-    labels = labels.float()
-
-    if loss_type == 'margin':
-        return torch.relu(margin - labels * (1 - euclidean_distance(x, y)))
-    elif loss_type == 'hamming':
-        return 0.25 * (labels - approximate_hamming_similarity(x, y)) ** 2
-    else:
-        raise ValueError('Unknown loss_type %s' % loss_type)
-
-
-def triplet_loss(x_1, y, x_2, z, loss_type='margin', margin=1.0):
-    """Compute triplet loss.
-
-    This function computes loss on a triplet of inputs (x, y, z).  A similarity or
-    distance value is computed for each pair of (x, y) and (x, z).  Since the
-    representations for x can be different in the two pairs (like our matching
-    model) we distinguish the two x representations by x_1 and x_2.
-
-    Args:
-      x_1: [N, D] float tensor.
-      y: [N, D] float tensor.
-      x_2: [N, D] float tensor.
-      z: [N, D] float tensor.
-      loss_type: margin or hamming.
-      margin: float scalar, margin for the margin loss.
-
-    Returns:
-      loss: [N] float tensor.  Loss for each pair of representations.
-    """
-    if loss_type == 'margin':
-        return torch.relu(margin +
-                          euclidean_distance(x_1, y) -
-                          euclidean_distance(x_2, z))
-    elif loss_type == 'hamming':
-        return 0.125 * ((approximate_hamming_similarity(x_1, y) - 1) ** 2 +
-                        (approximate_hamming_similarity(x_2, z) + 1) ** 2)
-    else:
-        raise ValueError('Unknown loss_type %s' % loss_type)
diff --git a/GMN/run.sh b/GMN/run.sh
deleted file mode 100644
index a60a94f..0000000
--- a/GMN/run.sh
+++ /dev/null
@@ -1 +0,0 @@
-python -W ignore train.py
diff --git a/GMN/segment.py b/GMN/segment.py
deleted file mode 100644
index 4c48ad5..0000000
--- a/GMN/segment.py
+++ /dev/null
@@ -1,59 +0,0 @@
-from __future__ import division
-from __future__ import print_function
-from __future__ import unicode_literals
-
-import torch
-
-
-def segment_sum(data, segment_ids):
-    """
-    Analogous to tf.segment_sum (https://www.tensorflow.org/api_docs/python/tf/math/segment_sum).
-
-    :param data: A pytorch tensor of the data for segmented summation.
-    :param segment_ids: A 1-D tensor containing the indices for the segmentation.
-    :return: a tensor of the same type as data containing the results of the segmented summation.
-    """
-    if not all(segment_ids[i] <= segment_ids[i + 1] for i in range(len(segment_ids) - 1)):
-        raise AssertionError("elements of segment_ids must be sorted")
-
-    if len(segment_ids.shape) != 1:
-        raise AssertionError("segment_ids have be a 1-D tensor")
-
-    if data.shape[0] != segment_ids.shape[0]:
-        raise AssertionError("segment_ids should be the same size as dimension 0 of input.")
-
-    num_segments = len(torch.unique(segment_ids))
-    return unsorted_segment_sum(data, segment_ids, num_segments)
-
-
-def unsorted_segment_sum(data, segment_ids, num_segments):
-    """
-    Computes the sum along segments of a tensor. Analogous to tf.unsorted_segment_sum.
-
-    :param data: A tensor whose segments are to be summed.
-    :param segment_ids: The segment indices tensor.
-    :param num_segments: The number of segments.
-    :return: A tensor of same data type as the data argument.
-    """
-
-    assert all([i in data.shape for i in segment_ids.shape]), "segment_ids.shape should be a prefix of data.shape"
-
-    # Encourage to use the below code when a deterministic result is
-    # needed (reproducibility). However, the code below is with low efficiency.
-
-    # tensor = torch.zeros(num_segments, data.shape[1], device=data.device)
-    # for index in range(num_segments):
-    #     tensor[index, :] = torch.sum(data[segment_ids == index, :], dim=0)
-    # return tensor
-
-    if len(segment_ids.shape) == 1:
-        s = torch.prod(torch.tensor(data.shape[1:], device=data.device)).long()
-        segment_ids = segment_ids.repeat_interleave(s).view(segment_ids.shape[0], *data.shape[1:])
-
-    assert data.shape == segment_ids.shape, "data.shape and segment_ids.shape should be equal"
-
-    shape = [num_segments] + list(data.shape[1:])
-    tensor = torch.zeros(*shape, device=data.device).scatter_add(0, segment_ids, data)
-    tensor = tensor.type(data.dtype)
-    return tensor
-
diff --git a/GMN/train.py b/GMN/train.py
deleted file mode 100644
index 713466a..0000000
--- a/GMN/train.py
+++ /dev/null
@@ -1,155 +0,0 @@
-from evaluation import compute_similarity, auc
-from loss import pairwise_loss, triplet_loss
-from utils import *
-from configure import *
-import numpy as np
-import torch.nn as nn
-import collections
-import time
-import os
-
-# Set GPU
-os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
-os.environ["CUDA_VISIBLE_DEVICES"] = "1"
-use_cuda = torch.cuda.is_available()
-device = torch.device('cuda:0' if use_cuda else 'cpu')
-
-# Print configure
-config = get_default_config()
-for (k, v) in config.items():
-    print("%s= %s" % (k, v))
-
-# Set random seeds
-seed = config['seed']
-random.seed(seed)
-np.random.seed(seed + 1)
-torch.manual_seed(seed + 2)
-torch.backends.cudnn.deterministic = False
-torch.backends.cudnn.benchmark = True
-
-
-training_set, validation_set = build_datasets(config)
-
-if config['training']['mode'] == 'pair':
-    training_data_iter = training_set.pairs(config['training']['batch_size'])
-    first_batch_graphs, _ = next(training_data_iter)
-else:
-    training_data_iter = training_set.triplets(config['training']['batch_size'])
-    first_batch_graphs = next(training_data_iter)
-
-node_feature_dim = first_batch_graphs.node_features.shape[-1]
-edge_feature_dim = first_batch_graphs.edge_features.shape[-1]
-
-model, optimizer = build_model(config, node_feature_dim, edge_feature_dim)
-model.to(device)
-
-accumulated_metrics = collections.defaultdict(list)
-
-
-training_n_graphs_in_batch = config['training']['batch_size']
-if config['training']['mode'] == 'pair':
-    training_n_graphs_in_batch *= 2
-elif config['training']['mode'] == 'triplet':
-    training_n_graphs_in_batch *= 4
-else:
-    raise ValueError('Unknown training mode: %s' % config['training']['mode'])
-
-t_start = time.time()
-for i_iter in range(config['training']['n_training_steps']):
-    model.train(mode=True)
-    batch = next(training_data_iter)
-    if config['training']['mode'] == 'pair':
-        node_features, edge_features, from_idx, to_idx, graph_idx, labels = get_graph(batch)
-        labels = labels.to(device)
-    else:
-        node_features, edge_features, from_idx, to_idx, graph_idx = get_graph(batch)
-    graph_vectors = model(node_features.to(device), edge_features.to(device), from_idx.to(device), to_idx.to(device),
-                          graph_idx.to(device), training_n_graphs_in_batch)
-
-    if config['training']['mode'] == 'pair':
-        x, y = reshape_and_split_tensor(graph_vectors, 2)
-        loss = pairwise_loss(x, y, labels,
-                             loss_type=config['training']['loss'],
-                             margin=config['training']['margin'])
-
-        is_pos = (labels == torch.ones(labels.shape).long().to(device)).float()
-        is_neg = 1 - is_pos
-        n_pos = torch.sum(is_pos)
-        n_neg = torch.sum(is_neg)
-        sim = compute_similarity(config, x, y)
-        sim_pos = torch.sum(sim * is_pos) / (n_pos + 1e-8)
-        sim_neg = torch.sum(sim * is_neg) / (n_neg + 1e-8)
-    else:
-        x_1, y, x_2, z = reshape_and_split_tensor(graph_vectors, 4)
-        loss = triplet_loss(x_1, y, x_2, z,
-                            loss_type=config['training']['loss'],
-                            margin=config['training']['margin'])
-
-        sim_pos = torch.mean(compute_similarity(config, x_1, y))
-        sim_neg = torch.mean(compute_similarity(config, x_2, z))
-
-    graph_vec_scale = torch.mean(graph_vectors ** 2)
-    if config['training']['graph_vec_regularizer_weight'] > 0:
-        loss = loss.add(config['training']['graph_vec_regularizer_weight'] *
-                0.5 * graph_vec_scale)
-
-    optimizer.zero_grad()
-    loss.backward(torch.ones_like(loss))  #
-    nn.utils.clip_grad_value_(model.parameters(), config['training']['clip_value'])
-    optimizer.step()
-
-    sim_diff = sim_pos - sim_neg
-    accumulated_metrics['loss'].append(loss)
-    accumulated_metrics['sim_pos'].append(sim_pos)
-    accumulated_metrics['sim_neg'].append(sim_neg)
-    accumulated_metrics['sim_diff'].append(sim_diff)
-
-
-    # evaluation
-    if (i_iter + 1) % config['training']['print_after'] == 0:
-        metrics_to_print = {
-            k: torch.mean(v[0]) for k, v in accumulated_metrics.items()}
-        info_str = ', '.join(
-            ['%s %.4f' % (k, v) for k, v in metrics_to_print.items()])
-        # reset the metrics
-        accumulated_metrics = collections.defaultdict(list)
-
-        if ((i_iter + 1) // config['training']['print_after'] %
-                config['training']['eval_after'] == 0):
-            model.eval()
-            with torch.no_grad():
-                accumulated_pair_auc = []
-                for batch in validation_set.pairs(config['evaluation']['batch_size']):
-                    node_features, edge_features, from_idx, to_idx, graph_idx, labels = get_graph(batch)
-                    labels = labels.to(device)
-                    eval_pairs = model(node_features.to(device), edge_features.to(device), from_idx.to(device),
-                                       to_idx.to(device),
-                                       graph_idx.to(device), config['evaluation']['batch_size'] * 2)
-
-                    x, y = reshape_and_split_tensor(eval_pairs, 2)
-                    similarity = compute_similarity(config, x, y)
-                    pair_auc = auc(similarity, labels)
-                    accumulated_pair_auc.append(pair_auc)
-
-                accumulated_triplet_acc = []
-                for batch in validation_set.triplets(config['evaluation']['batch_size']):
-                    node_features, edge_features, from_idx, to_idx, graph_idx = get_graph(batch)
-                    eval_triplets = model(node_features.to(device), edge_features.to(device), from_idx.to(device),
-                                          to_idx.to(device),
-                                          graph_idx.to(device),
-                                          config['evaluation']['batch_size'] * 4)
-                    x_1, y, x_2, z = reshape_and_split_tensor(eval_triplets, 4)
-                    sim_1 = compute_similarity(config, x_1, y)
-                    sim_2 = compute_similarity(config, x_2, z)
-                    triplet_acc = torch.mean((sim_1 > sim_2).float())
-                    accumulated_triplet_acc.append(triplet_acc.cpu().numpy())
-
-                eval_metrics = {
-                    'pair_auc': np.mean(accumulated_pair_auc),
-                    'triplet_acc': np.mean(accumulated_triplet_acc)}
-                info_str += ', ' + ', '.join(
-                    ['%s %.4f' % ('val/' + k, v) for k, v in eval_metrics.items()])
-            model.train()
-        print('iter %d, %s, time %.2fs' % (
-            i_iter + 1, info_str, time.time() - t_start))
-        t_start = time.time()
diff --git a/GMN/utils.py b/GMN/utils.py
deleted file mode 100644
index f175df9..0000000
--- a/GMN/utils.py
+++ /dev/null
@@ -1,110 +0,0 @@
-import collections
-from dataset import GraphEditDistanceDataset, FixedGraphEditDistanceDataset
-from graphembeddingnetwork import GraphEmbeddingNet, GraphEncoder, GraphAggregator
-from graphmatchingnetwork import GraphMatchingNet
-import copy
-import torch
-import random
-
-GraphData = collections.namedtuple('GraphData', [
-    'from_idx',
-    'to_idx',
-    'node_features',
-    'edge_features',
-    'graph_idx',
-    'n_graphs'])
-
-
-def reshape_and_split_tensor(tensor, n_splits):
-    """Reshape and split a 2D tensor along the last dimension.
-
-    Args:
-      tensor: a [num_examples, feature_dim] tensor.  num_examples must be a
-        multiple of `n_splits`.
-      n_splits: int, number of splits to split the tensor into.
-
-    Returns:
-      splits: a list of `n_splits` tensors.  The first split is [tensor[0],
-        tensor[n_splits], tensor[n_splits * 2], ...], the second split is
-        [tensor[1], tensor[n_splits + 1], tensor[n_splits * 2 + 1], ...], etc..
-    """
-    feature_dim = tensor.shape[-1]
-    tensor = torch.reshape(tensor, [-1, feature_dim * n_splits])
-    tensor_split = []
-    for i in range(n_splits):
-        tensor_split.append(tensor[:, feature_dim * i: feature_dim * (i + 1)])
-    return tensor_split
-
-
-def build_model(config, node_feature_dim, edge_feature_dim):
-    """Create model for training and evaluation.
-
-    Args:
-      config: a dictionary of configs, like the one created by the
-        `get_default_config` function.
-      node_feature_dim: int, dimensionality of node features.
-      edge_feature_dim: int, dimensionality of edge features.
-
-    Returns:
-      tensors: a (potentially nested) name => tensor dict.
-      placeholders: a (potentially nested) name => tensor dict.
-      AE_model: a GraphEmbeddingNet or GraphMatchingNet instance.
-
-    Raises:
-      ValueError: if the specified model or training settings are not supported.
-    """
-    config['encoder']['node_feature_dim'] = node_feature_dim
-    config['encoder']['edge_feature_dim'] = edge_feature_dim
-
-    encoder = GraphEncoder(**config['encoder'])
-    aggregator = GraphAggregator(**config['aggregator'])
-    if config['model_type'] == 'embedding':
-        model = GraphEmbeddingNet(
-            encoder, aggregator, **config['graph_embedding_net'])
-    elif config['model_type'] == 'matching':
-        model = GraphMatchingNet(
-            encoder, aggregator, **config['graph_matching_net'])
-    else:
-        raise ValueError('Unknown model type: %s' % config['model_type'])
-
-    optimizer = torch.optim.Adam((model.parameters()),
-                                 lr=config['training']['learning_rate'], weight_decay=1e-5)
-
-    return model, optimizer
-
-
-def build_datasets(config):
-    """Build the training and evaluation datasets."""
-    config = copy.deepcopy(config)
-
-    if config['data']['problem'] == 'graph_edit_distance':
-        dataset_params = config['data']['dataset_params']
-        validation_dataset_size = dataset_params['validation_dataset_size']
-        del dataset_params['validation_dataset_size']
-        training_set = GraphEditDistanceDataset(**dataset_params)
-        dataset_params['dataset_size'] = validation_dataset_size
-        validation_set = FixedGraphEditDistanceDataset(**dataset_params)
-    else:
-        raise ValueError('Unknown problem type: %s' % config['data']['problem'])
-    return training_set, validation_set
-
-
-def get_graph(batch):
-    if len(batch) != 2:
-        # if isinstance(batch, GraphData):
-        graph = batch
-        node_features = torch.from_numpy(graph.node_features)
-        edge_features = torch.from_numpy(graph.edge_features)
-        from_idx = torch.from_numpy(graph.from_idx).long()
-        to_idx = torch.from_numpy(graph.to_idx).long()
-        graph_idx = torch.from_numpy(graph.graph_idx).long()
-        return node_features, edge_features, from_idx, to_idx, graph_idx
-    else:
-        graph, labels = batch
-        node_features = torch.from_numpy(graph.node_features)
-        edge_features = torch.from_numpy(graph.edge_features)
-        from_idx = torch.from_numpy(graph.from_idx).long()
-        to_idx = torch.from_numpy(graph.to_idx).long()
-        graph_idx = torch.from_numpy(graph.graph_idx).long()
-        labels = torch.from_numpy(labels).long()
-    return node_features, edge_features, from_idx, to_idx, graph_idx, labels
diff --git a/LinguisticTrees/README.md b/LinguisticTrees/README.md
deleted file mode 100644
index c58bd70..0000000
--- a/LinguisticTrees/README.md
+++ /dev/null
@@ -1,86 +0,0 @@
-# Linguistic Tree Matching Networks
-
-This directory contains an adaptation of Graph Matching Networks (GMN) for linguistic dependency trees, specifically focused on natural language inference tasks. It leverages the TMN_DataGen package for preprocessing dependency trees into a GMN-compatible format.
-
-## Setup
-
-1. Install requirements:
-```bash
-pip install wandb torch numpy sklearn
-```
-
-2. Configure WandB:
-```bash
-wandb login
-```
-
-3. Download and preprocess data:
-```bash
-# Download SNLI dataset (if not already done)
-wget https://nlp.stanford.edu/projects/snli/snli_1.0.zip
-unzip snli_1.0.zip
-
-# Generate tree data using TMN_DataGen
-python -m TMN_DataGen.run process \
-    -if data/snli_1.0/snli_1.0_dev.jsonl \
-    -od data/processed_data/dev \
-    -sm en_core_web_trf \
-    -v normal
-```
-
-## Project Structure
-
-```
-LinguisticTrees/
-├── configs/           # Model and training configurations
-├── data/             # Data loading and processing
-├── models/           # Model architectures 
-├── training/         # Training utilities
-└── experiments/      # Training and evaluation scripts
-```
-
-## Quick Start
-
-1. Test training with dev dataset:
-```bash
-python -m LinguisticTrees.experiments.train_tree_matching \
-    --config configs/experiment_configs/tree_matching.yaml \
-    --data.train_path data/processed_data/dev/final_dataset.json \
-    --wandb.tags dev,test-run
-```
-
-2. Full training:
-```bash
-python -m LinguisticTrees.experiments.train_tree_matching \
-    --config configs/experiment_configs/tree_matching.yaml
-```
-
-## Key Components
-
-- **TreeMatchingNet**: Extends GMN for linguistic tree structures
-- **TreeEncoder**: Specialized encoder for linguistic features
-- **TreeMatchingDataset**: Handles TMN_DataGen output format
-
-## Implementation Notes
-
-- Tree directionality is preserved through attention mechanisms
-- Node features include word embeddings and linguistic features
-- Edge features represent dependency relationships
-- Labels: -1 (contradiction), 0 (neutral), 1 (entailment)
-
-## Configuration
-
-Key configuration options in `configs/experiment_configs/tree_matching.yaml`:
-
-- `MODEL.node_feature_dim`: Dimension of node features (default: 768 for BERT embeddings)
-- `MODEL.edge_feature_dim`: Dimension of edge features
-- `MODEL.n_prop_layers`: Number of graph propagation layers
-- `TRAIN.learning_rate`: Learning rate
-- `TRAIN.batch_size`: Batch size
-
-See configuration files for complete options.
-
-## References
-
-Based on the following papers:
-- Li et al. "Graph Matching Networks for Learning the Similarity of Graph Structured Objects" (ICML 2019)
diff --git a/LinguisticTrees/__init__.py b/LinguisticTrees/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/LinguisticTrees/__pycache__/__init__.cpython-312.pyc b/LinguisticTrees/__pycache__/__init__.cpython-312.pyc
deleted file mode 100644
index 09ca1ea..0000000
Binary files a/LinguisticTrees/__pycache__/__init__.cpython-312.pyc and /dev/null differ
diff --git a/LinguisticTrees/configs/__init__.py b/LinguisticTrees/configs/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/LinguisticTrees/configs/__pycache__/__init__.cpython-312.pyc b/LinguisticTrees/configs/__pycache__/__init__.cpython-312.pyc
deleted file mode 100644
index 4145a6e..0000000
Binary files a/LinguisticTrees/configs/__pycache__/__init__.cpython-312.pyc and /dev/null differ
diff --git a/LinguisticTrees/configs/__pycache__/default_tree_config.cpython-312.pyc b/LinguisticTrees/configs/__pycache__/default_tree_config.cpython-312.pyc
deleted file mode 100644
index 83d219b..0000000
Binary files a/LinguisticTrees/configs/__pycache__/default_tree_config.cpython-312.pyc and /dev/null differ
diff --git a/LinguisticTrees/configs/__pycache__/tree_data_config.cpython-312.pyc b/LinguisticTrees/configs/__pycache__/tree_data_config.cpython-312.pyc
deleted file mode 100644
index f62c786..0000000
Binary files a/LinguisticTrees/configs/__pycache__/tree_data_config.cpython-312.pyc and /dev/null differ
diff --git a/LinguisticTrees/configs/__pycache__/tree_data_config.cpython-38.pyc b/LinguisticTrees/configs/__pycache__/tree_data_config.cpython-38.pyc
deleted file mode 100644
index 5665ecb..0000000
Binary files a/LinguisticTrees/configs/__pycache__/tree_data_config.cpython-38.pyc and /dev/null differ
diff --git a/LinguisticTrees/configs/default_tree_config.py b/LinguisticTrees/configs/default_tree_config.py
deleted file mode 100644
index c00accc..0000000
--- a/LinguisticTrees/configs/default_tree_config.py
+++ /dev/null
@@ -1,51 +0,0 @@
-from GMN.configure import get_default_config
-import yaml
-from pathlib import Path
-import torch
-
-def get_tree_config(config_path=None):
-    """Get configuration for tree matching"""
-    # Start with GMN base config
-    config = get_default_config()
-    
-    # Add tree-specific defaults
-    tree_config = {
-        'model': {
-            'name': 'tree_matching',
-            'node_feature_dim': 768,  # BERT embedding size
-            'edge_feature_dim': 64,   # Dependency feature size
-            'node_hidden_dim': 256,
-            'edge_hidden_dim': 128,
-            'n_prop_layers': 5,
-            'dropout': 0.1,
-        },
-        'data': {
-            'spacy_variant': 'trf',
-            'loading_pattern': 'sequential',
-            'batch_size': 32,
-            'use_worker_sharding': False,
-            'max_partitions_in_memory': 2
-        },
-        'train': {
-            'learning_rate': 1e-4,
-            'weight_decay': 1e-5,
-            'n_epochs': 100,
-            'patience': 10,
-            'warmup_steps': 1000
-        },
-        'device': 'cuda' if torch.cuda.is_available() else 'cpu',
-        'wandb': {
-            'project': 'tree-matching',
-            'tags': ['linguistic-trees'],
-            'log_interval': 100
-        }
-    }
-    config.update(tree_config)
-    
-    # Override with user config if provided
-    if config_path:
-        with open(config_path) as f:
-            user_config = yaml.safe_load(f)
-            config.update(user_config)
-    
-    return config
diff --git a/LinguisticTrees/configs/experiment_configs/tree_embedding.yaml b/LinguisticTrees/configs/experiment_configs/tree_embedding.yaml
deleted file mode 100644
index 09cba0f..0000000
--- a/LinguisticTrees/configs/experiment_configs/tree_embedding.yaml
+++ /dev/null
@@ -1,33 +0,0 @@
-#configs/experiment_configs/tree_embedding.yaml
-MODEL:
-  name: 'tree_embedding'
-  node_feature_dim: 768
-  edge_feature_dim: 64
-  node_hidden_dim: 256
-  edge_hidden_dim: 128
-  n_prop_layers: 5
-  dropout: 0.1
-  projection_dim: 128
-  temperature: 0.07  # For contrastive learning
-
-DATA:
-  train_path: 'data/snli_train.json'
-  val_path: 'data/snli_val.json'
-  test_path: 'data/snli_test.json'
-  max_tree_size: 100
-  batch_size: 32
-  num_workers: 4
-
-TRAIN:
-  learning_rate: 0.0001
-  weight_decay: 0.00001
-  n_epochs: 100
-  patience: 10
-  warmup_steps: 1000
-  gradient_clip: 1.0
-  log_interval: 100
-  
-WANDB:
-  project_name: 'tree-embedding'
-  entity: 'your-entity'
-  tags: ['tree-embedding', 'entailment']
diff --git a/LinguisticTrees/configs/experiment_configs/tree_matching.yaml b/LinguisticTrees/configs/experiment_configs/tree_matching.yaml
deleted file mode 100644
index 40607dd..0000000
--- a/LinguisticTrees/configs/experiment_configs/tree_matching.yaml
+++ /dev/null
@@ -1,32 +0,0 @@
-#configs/experiment_configs/tree_matching.yaml
-MODEL:
-  name: 'tree_matching'
-  node_feature_dim: 768
-  edge_feature_dim: 64
-  node_hidden_dim: 256
-  edge_hidden_dim: 128
-  n_prop_layers: 5
-  dropout: 0.1
-  projection_dim: 128
-
-DATA:
-  train_path: 'data/snli_train.json'
-  val_path: 'data/snli_val.json'
-  test_path: 'data/snli_test.json'
-  max_tree_size: 100
-  batch_size: 32
-  num_workers: 4
-
-TRAIN:
-  learning_rate: 0.0001
-  weight_decay: 0.00001
-  n_epochs: 100
-  patience: 10
-  warmup_steps: 1000
-  gradient_clip: 1.0
-  log_interval: 100
-
-WANDB:
-  project_name: 'tree-matching'
-  entity: 'your-entity'
-  tags: ['tree-matching', 'entailment']
diff --git a/LinguisticTrees/configs/tree_data_config.py b/LinguisticTrees/configs/tree_data_config.py
deleted file mode 100644
index a0a34c3..0000000
--- a/LinguisticTrees/configs/tree_data_config.py
+++ /dev/null
@@ -1,42 +0,0 @@
-from dataclasses import dataclass
-from typing import Literal
-from pathlib import Path
-
-@dataclass
-class TreeDataConfig:
-    """Configuration for tree data paths and variants"""
-    
-    # Root data directory - should be absolute path to processed_data directory
-    data_root: str = '/home/jlunder/research/Tree-Matching-Networks/data/processed_data'
-    
-    # SpaCy model variant (trf, lg, sm)
-    spacy_variant: Literal['trf', 'lg', 'sm'] = 'trf'
-    
-    def __post_init__(self):
-        """Convert data_root to absolute path if needed"""
-        self.data_root = Path(self.data_root).resolve()
-        
-    def _get_split_path(self, split: str) -> Path:
-        """Internal helper to construct split path"""
-        return self.data_root / split / f'snli_1.0_{split}_converted_{self.spacy_variant}'
-    
-    @property
-    def train_path(self) -> Path:
-        return self._get_split_path('train')
-    
-    @property
-    def dev_path(self) -> Path:
-        return self._get_split_path('dev')
-        
-    @property
-    def test_path(self) -> Path:
-        return self._get_split_path('test')
-    
-    def validate_paths(self):
-        """Verify data paths exist"""
-        for split in ['train', 'dev', 'test']:
-            path = self._get_split_path(split)
-            print(f"Checking path: {path}")
-            if not path.exists():
-                raise ValueError(f"Data path does not exist: {path}")
-
diff --git a/LinguisticTrees/data/__init__.py b/LinguisticTrees/data/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/LinguisticTrees/data/__pycache__/__init__.cpython-312.pyc b/LinguisticTrees/data/__pycache__/__init__.cpython-312.pyc
deleted file mode 100644
index e877ae8..0000000
Binary files a/LinguisticTrees/data/__pycache__/__init__.cpython-312.pyc and /dev/null differ
diff --git a/LinguisticTrees/data/__pycache__/data_utils.cpython-312.pyc b/LinguisticTrees/data/__pycache__/data_utils.cpython-312.pyc
deleted file mode 100644
index b31dedc..0000000
Binary files a/LinguisticTrees/data/__pycache__/data_utils.cpython-312.pyc and /dev/null differ
diff --git a/LinguisticTrees/data/__pycache__/loading_patterns.cpython-312.pyc b/LinguisticTrees/data/__pycache__/loading_patterns.cpython-312.pyc
deleted file mode 100644
index ce6824c..0000000
Binary files a/LinguisticTrees/data/__pycache__/loading_patterns.cpython-312.pyc and /dev/null differ
diff --git a/LinguisticTrees/data/__pycache__/partition_datasets.cpython-312.pyc b/LinguisticTrees/data/__pycache__/partition_datasets.cpython-312.pyc
deleted file mode 100644
index 0b0ea53..0000000
Binary files a/LinguisticTrees/data/__pycache__/partition_datasets.cpython-312.pyc and /dev/null differ
diff --git a/LinguisticTrees/data/__pycache__/tree_dataset.cpython-312.pyc b/LinguisticTrees/data/__pycache__/tree_dataset.cpython-312.pyc
deleted file mode 100644
index 8e581a8..0000000
Binary files a/LinguisticTrees/data/__pycache__/tree_dataset.cpython-312.pyc and /dev/null differ
diff --git a/LinguisticTrees/data/batch_utils.py b/LinguisticTrees/data/batch_utils.py
deleted file mode 100644
index 7a4d922..0000000
--- a/LinguisticTrees/data/batch_utils.py
+++ /dev/null
@@ -1,86 +0,0 @@
-#data/batch_utils.py
-import torch
-from typing import List, Dict
-import numpy as np
-
-def pad_sequences(sequences: List[torch.Tensor], 
-                 max_len: int = None, 
-                 padding_value: float = 0.0) -> torch.Tensor:
-    """Pad sequence of tensors to same length"""
-    max_len = max_len or max(len(s) for s in sequences)
-    padded = []
-    
-    for seq in sequences:
-        pad_size = max_len - len(seq)
-        if pad_size > 0:
-            padded.append(
-                torch.nn.functional.pad(
-                    seq, 
-                    (0, 0, 0, pad_size),
-                    value=padding_value
-                )
-            )
-        else:
-            padded.append(seq)
-            
-    return torch.stack(padded)
-
-def create_attention_mask(lengths: List[int], max_len: int = None) -> torch.Tensor:
-    """Create attention mask for variable length sequences"""
-    max_len = max_len or max(lengths)
-    batch_size = len(lengths)
-    
-    mask = torch.zeros((batch_size, max_len))
-    for i, length in enumerate(lengths):
-        mask[i, :length] = 1
-    
-    return mask
-
-def batch_trees(trees: List[Dict], config) -> Dict:
-    """Batch multiple trees together"""
-    batch_size = len(trees)
-    max_nodes = max(len(tree['node_features']) for tree in trees)
-    
-    # Initialize tensors
-    node_features = []
-    edge_features = []
-    from_idx = []
-    to_idx = []
-    graph_idx = []
-    masks = []
-    
-    node_offset = 0
-    for i, tree in enumerate(trees):
-        n_nodes = len(tree['node_features'])
-        
-        # Node features
-        node_features.append(
-            pad_sequences([torch.tensor(tree['node_features'])], max_nodes)[0]
-        )
-        
-        # Edge indices
-        from_idx.extend([x + node_offset for x in tree['from_idx']])
-        to_idx.extend([x + node_offset for x in tree['to_idx']])
-        
-        # Edge features
-        edge_features.extend(tree['edge_features'])
-        
-        # Graph index
-        graph_idx.extend([i] * n_nodes)
-        
-        # Mask
-        mask = torch.zeros(max_nodes)
-        mask[:n_nodes] = 1
-        masks.append(mask)
-        
-        node_offset += max_nodes
-        
-    return {
-        'node_features': torch.stack(node_features),
-        'edge_features': torch.tensor(edge_features),
-        'from_idx': torch.tensor(from_idx),
-        'to_idx': torch.tensor(to_idx),
-        'graph_idx': torch.tensor(graph_idx),
-        'masks': torch.stack(masks),
-        'n_graphs': batch_size
-    }
diff --git a/LinguisticTrees/data/data_utils.py b/LinguisticTrees/data/data_utils.py
deleted file mode 100644
index f536894..0000000
--- a/LinguisticTrees/data/data_utils.py
+++ /dev/null
@@ -1,61 +0,0 @@
-#data/data_utils.py
-import torch
-from collections import namedtuple
-from typing import List, Dict
-
-GraphData = namedtuple('GraphData', [
-    'from_idx', 'to_idx', 'node_features', 'edge_features',
-    'graph_idx', 'n_graphs'
-])
-
-def convert_tree_to_graph_data(tree_pairs: List[Dict], config) -> GraphData:
-    """Convert TMN_DataGen tree pairs to GraphData format"""
-    batch_size = len(tree_pairs)
-    
-    # Initialize lists for batch
-    all_node_features = []
-    all_edge_features = []
-    all_from_idx = []
-    all_to_idx = []
-    all_graph_idx = []
-    
-    node_offset = 0
-    for batch_idx, (tree1, tree2) in enumerate(tree_pairs):
-        # Process first tree
-        n_nodes1 = len(tree1['node_features'])
-        all_node_features.extend(tree1['node_features'])
-        all_edge_features.extend(tree1['edge_features'])
-        
-        # Adjust indices for batch
-        all_from_idx.extend(
-            [x + node_offset for x in tree1['from_idx']]
-        )
-        all_to_idx.extend(
-            [x + node_offset for x in tree1['to_idx']]
-        )
-        all_graph_idx.extend([batch_idx * 2] * n_nodes1)
-        
-        # Process second tree
-        node_offset += n_nodes1
-        n_nodes2 = len(tree2['node_features'])
-        all_node_features.extend(tree2['node_features'])
-        all_edge_features.extend(tree2['edge_features'])
-        
-        all_from_idx.extend(
-            [x + node_offset for x in tree2['from_idx']]
-        )
-        all_to_idx.extend(
-            [x + node_offset for x in tree2['to_idx']]
-        )
-        all_graph_idx.extend([batch_idx * 2 + 1] * n_nodes2)
-        
-        node_offset += n_nodes2
-    
-    return GraphData(
-        from_idx=torch.tensor(all_from_idx),
-        to_idx=torch.tensor(all_to_idx),
-        node_features=torch.tensor(all_node_features),
-        edge_features=torch.tensor(all_edge_features),
-        graph_idx=torch.tensor(all_graph_idx),
-        n_graphs=batch_size * 2
-    )
diff --git a/LinguisticTrees/data/loading_patterns.py b/LinguisticTrees/data/loading_patterns.py
deleted file mode 100644
index 6acf5dc..0000000
--- a/LinguisticTrees/data/loading_patterns.py
+++ /dev/null
@@ -1,56 +0,0 @@
-from enum import Enum
-from typing import List, Iterator
-from pathlib import Path
-import random
-
-class PartitionLoadingPattern(Enum):
-    SEQUENTIAL = "sequential"  # Load partitions in order
-    RANDOM = "random"         # Load partitions randomly
-    ROUND_ROBIN = "round_robin"  # Cycle through partitions evenly
-    WEIGHTED = "weighted"     # Load partitions based on size
-
-class PartitionLoader:
-    """Handles different partition loading patterns"""
-    
-    def __init__(self, 
-                 partition_files: List[Path],
-                 pattern: PartitionLoadingPattern,
-                 partition_sizes: dict = None):
-        self.partition_files = partition_files
-        self.pattern = pattern
-        self.partition_sizes = partition_sizes
-        self._current_idx = 0
-        
-    def __iter__(self) -> Iterator[Path]:
-        if self.pattern == PartitionLoadingPattern.SEQUENTIAL:
-            yield from self._sequential_loading()
-        elif self.pattern == PartitionLoadingPattern.RANDOM:
-            yield from self._random_loading()
-        elif self.pattern == PartitionLoadingPattern.ROUND_ROBIN:
-            yield from self._round_robin_loading()
-        elif self.pattern == PartitionLoadingPattern.WEIGHTED:
-            yield from self._weighted_loading()
-            
-    def _sequential_loading(self) -> Iterator[Path]:
-        yield from self.partition_files
-        
-    def _random_loading(self) -> Iterator[Path]:
-        files = list(self.partition_files)
-        random.shuffle(files)
-        yield from files
-        
-    def _round_robin_loading(self) -> Iterator[Path]:
-        while True:
-            yield self.partition_files[self._current_idx]
-            self._current_idx = (self._current_idx + 1) % len(self.partition_files)
-            
-    def _weighted_loading(self) -> Iterator[Path]:
-        if not self.partition_sizes:
-            raise ValueError("Partition sizes required for weighted loading")
-            
-        # Convert counts to probabilities
-        total = sum(self.partition_sizes.values())
-        weights = [self.partition_sizes[f]/total for f in self.partition_files]
-        
-        while True:
-            yield random.choices(self.partition_files, weights=weights, k=1)[0]
diff --git a/LinguisticTrees/data/partition_datasets.py b/LinguisticTrees/data/partition_datasets.py
deleted file mode 100644
index 719d7db..0000000
--- a/LinguisticTrees/data/partition_datasets.py
+++ /dev/null
@@ -1,191 +0,0 @@
-from typing import Iterator, Tuple
-from pathlib import Path
-import json
-import torch
-import logging
-from collections import deque
-import gc
-from .tree_dataset import TreeMatchingDataset
-from .loading_patterns import PartitionLoader, PartitionLoadingPattern
-from .data_utils import convert_tree_to_graph_data, GraphData
-from ..utils.memory_utils import MemoryMonitor
-from torch.utils.data import DataLoader
-import multiprocessing as mp
-from functools import partial
-
-logger = logging.getLogger(__name__)
-
-
-class MultiPartitionTreeDataset(TreeMatchingDataset):
-    def __init__(self, 
-                 data_dir: str, 
-                 config,
-                 loading_pattern: str = "sequential",
-                 num_workers: int = None,
-                 prefetch_factor: int = 2):
-        super().__init__(config)
-        self.data_dir = Path(data_dir)
-        self.num_workers = num_workers or mp.cpu_count() - 1
-        self.prefetch_factor = prefetch_factor
-        
-        # Initialize partition loader with multiprocessing
-        self.partition_loader = DataLoader(
-            self._get_partition_paths(),
-            batch_size=None,  # Load one partition at a time
-            num_workers=self.num_workers,
-            prefetch_factor=self.prefetch_factor,
-            persistent_workers=True
-        )
-        
-    def _get_partition_paths(self):
-        """Get sorted list of partition files"""
-        return sorted(
-            self.data_dir.glob("part_*.json"),
-            key=lambda x: int(x.stem.split('_')[1])
-        )
-        
-    @staticmethod
-    def _load_partition(file_path):
-        """Worker function to load partition"""
-        with open(file_path) as f:
-            return json.load(f)
-            
-    def pairs(self, batch_size: int):
-        """Generate batches using multiprocessing"""
-        # Create process pool
-        with mp.Pool(self.num_workers) as pool:
-            for partition_file in self.partition_loader:
-                # Load partition in parallel
-                partition_data = pool.apply_async(
-                    self._load_partition,
-                    (partition_file,)
-                ).get()
-                
-                # Create batches
-                pairs = partition_data['graph_pairs']
-                labels = torch.tensor(partition_data['labels'])
-                
-                for start_idx in range(0, len(labels), batch_size):
-                    end_idx = min(start_idx + batch_size, len(labels))
-                    batch_pairs = pairs[start_idx:end_idx]
-                    batch_labels = labels[start_idx:end_idx]
-                    
-                    # Convert batch to GraphData in parallel
-                    graph_data = pool.apply_async(
-                        convert_tree_to_graph_data,
-                        (batch_pairs, self.config)
-                    ).get()
-                    
-                    yield graph_data, batch_labels
-
-
-class DynamicPartitionTreeDataset(TreeMatchingDataset):
-    """Dataset that dynamically loads/unloads partitions to manage memory"""
-    
-    def __init__(self, 
-                 data_dir: str, 
-                 config, 
-                 max_partitions_in_memory: int = 2,
-                 loading_pattern: str = "sequential"):
-        """Initialize dataset
-        
-        Args:
-            data_dir: Directory containing partition files
-            config: Dataset configuration
-            max_partitions_in_memory: Maximum number of partitions to keep in memory
-            loading_pattern: One of "sequential", "random", "round_robin", "weighted"
-        """
-        super().__init__()
-        self.data_dir = Path(data_dir)
-        self.config = config
-        self.max_partitions = max_partitions_in_memory
-        
-        try:
-            self.loading_pattern = PartitionLoadingPattern(loading_pattern)
-        except ValueError:
-            raise ValueError(f"Invalid loading pattern: {loading_pattern}")
-        
-        # Get all partition files
-        self.partition_files = sorted(
-            self.data_dir.glob("part_*.json"),
-            key=lambda x: int(x.stem.split('_')[1])
-        )
-        
-        if not self.partition_files:
-            raise ValueError(f"No partition files found in {data_dir}")
-            
-        # Initialize partition cache
-        self.partition_cache = {}  # file -> data
-        self.partition_queue = deque()  # Track loaded partitions
-        
-        # Read sizes
-        self.partition_sizes = {}
-        total_examples = 0
-        for pf in self.partition_files:
-            with open(pf) as f:
-                size = len(json.load(f)['labels'])
-                self.partition_sizes[pf] = size
-                total_examples += size
-                
-        logger.info(f"Found {len(self.partition_files)} partitions "
-                   f"with {total_examples} total examples")
-        
-        # Create partition loader
-        self.partition_loader = PartitionLoader(
-            self.partition_files,
-            self.loading_pattern,
-            self.partition_sizes
-        )
-                   
-    def _load_partition(self, partition_file: Path) -> None:
-        """Load a partition into memory"""
-        if partition_file in self.partition_cache:
-            return
-            
-        # If cache is full, remove oldest partition
-        while (len(self.partition_cache) >= self.max_partitions and 
-               self.partition_queue):
-            old_file = self.partition_queue.popleft()
-            del self.partition_cache[old_file]
-            gc.collect()  # Help free memory
-            
-        # Load new partition
-        with open(partition_file) as f:
-            self.partition_cache[partition_file] = json.load(f)
-        self.partition_queue.append(partition_file)
-        
-        logger.debug(f"Loaded partition {partition_file.name}, "
-                    f"cache size: {len(self.partition_cache)}")
-        MemoryMonitor.log_memory(prefix=f'After loading {partition_file.name}: ')
-
-    def pairs(self, batch_size: int) -> Iterator[Tuple[GraphData, torch.Tensor]]:
-        """Generate batches of tree pairs"""
-        while True:
-            for partition_file in self.partition_loader:
-                try:
-                    # Load partition if needed
-                    self._load_partition(partition_file)
-                    partition_data = self.partition_cache[partition_file]
-                    
-                    pairs = partition_data['graph_pairs']
-                    labels = torch.tensor(partition_data['labels'])
-                    
-                    # Create batches
-                    indices = list(range(0, len(labels), batch_size))
-                    for start_idx in indices:
-                        end_idx = min(start_idx + batch_size, len(labels))
-                        batch_pairs = [pairs[i] for i in range(start_idx, end_idx)]
-                        batch_labels = labels[start_idx:end_idx]
-                        
-                        graph_data = convert_tree_to_graph_data(
-                            batch_pairs,
-                            self.config
-                        )
-                        yield graph_data, batch_labels
-                        
-                except Exception as e:
-                    logger.error(f"Error processing partition {partition_file}: {e}")
-                    continue
-
-    def __len__(self) -> int:
-        return sum(self.partition_sizes.values())
diff --git a/LinguisticTrees/data/tree_dataset.py b/LinguisticTrees/data/tree_dataset.py
deleted file mode 100644
index 14d5961..0000000
--- a/LinguisticTrees/data/tree_dataset.py
+++ /dev/null
@@ -1,17 +0,0 @@
-#data/tree_dataset.py
-from GMN.dataset import GraphSimilarityDataset
-from .data_utils import convert_tree_to_graph_data
-import json
-import torch
-
-class TreeMatchingDataset:
-    """Base dataset class for tree matching"""
-    
-    def __init__(self, config):
-        self.config = config
-        self.data = None
-        self.labels = None
-
-    def pairs(self, batch_size):
-        raise NotImplementedError("Derived classes must implement pairs()")
-
diff --git a/LinguisticTrees/experiments/__init__.py b/LinguisticTrees/experiments/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/LinguisticTrees/experiments/__pycache__/__init__.cpython-312.pyc b/LinguisticTrees/experiments/__pycache__/__init__.cpython-312.pyc
deleted file mode 100644
index 8d03720..0000000
Binary files a/LinguisticTrees/experiments/__pycache__/__init__.cpython-312.pyc and /dev/null differ
diff --git a/LinguisticTrees/experiments/__pycache__/test_data_loading.cpython-312.pyc b/LinguisticTrees/experiments/__pycache__/test_data_loading.cpython-312.pyc
deleted file mode 100644
index 1c3a515..0000000
Binary files a/LinguisticTrees/experiments/__pycache__/test_data_loading.cpython-312.pyc and /dev/null differ
diff --git a/LinguisticTrees/experiments/__pycache__/test_data_loading.cpython-38.pyc b/LinguisticTrees/experiments/__pycache__/test_data_loading.cpython-38.pyc
deleted file mode 100644
index 361c958..0000000
Binary files a/LinguisticTrees/experiments/__pycache__/test_data_loading.cpython-38.pyc and /dev/null differ
diff --git a/LinguisticTrees/experiments/__pycache__/test_partition_loading.cpython-312.pyc b/LinguisticTrees/experiments/__pycache__/test_partition_loading.cpython-312.pyc
deleted file mode 100644
index 6c85288..0000000
Binary files a/LinguisticTrees/experiments/__pycache__/test_partition_loading.cpython-312.pyc and /dev/null differ
diff --git a/LinguisticTrees/experiments/__pycache__/test_training.cpython-312.pyc b/LinguisticTrees/experiments/__pycache__/test_training.cpython-312.pyc
deleted file mode 100644
index ac078aa..0000000
Binary files a/LinguisticTrees/experiments/__pycache__/test_training.cpython-312.pyc and /dev/null differ
diff --git a/LinguisticTrees/experiments/eval_tree_matching.py b/LinguisticTrees/experiments/eval_tree_matching.py
deleted file mode 100644
index 37e6997..0000000
--- a/LinguisticTrees/experiments/eval_tree_matching.py
+++ /dev/null
@@ -1,86 +0,0 @@
-#experiments/eval_tree_matching.py
-import torch
-from pathlib import Path
-from ..models.tree_matching import TreeMatchingNet
-from ..data.tree_dataset import TreeMatchingDataset
-from ..training.metrics import TreeMatchingMetrics
-import json
-import wandb
-
-def evaluate_model(model, test_loader, config):
-    """Evaluate model on test set"""
-    model.eval()
-    all_similarities = []
-    all_labels = []
-    
-    with torch.no_grad():
-        for batch_idx, (graphs, labels) in enumerate(test_loader):
-            # Move to device
-            graphs = graphs.to(config.device)
-            labels = labels.to(config.device)
-            
-            # Forward pass
-            outputs = model(
-                graphs.node_features,
-                graphs.edge_features,
-                graphs.from_idx,
-                graphs.to_idx,
-                graphs.graph_idx,
-                graphs.n_graphs
-            )
-            
-            all_similarities.append(outputs)
-            all_labels.append(labels)
-    
-    # Concatenate results
-    similarities = torch.cat(all_similarities)
-    labels = torch.cat(all_labels)
-    
-    # Compute metrics
-    metrics = TreeMatchingMetrics.compute_all_metrics(
-        similarities, 
-        labels
-    )
-    
-    return metrics
-
-def main():
-    # Load config
-    config = load_config()
-    
-    # Initialize WandB
-    wandb.init(
-        project=config.wandb.project_name,
-        config=config,
-        tags=['evaluation']
-    )
-    
-    # Load model
-    model = TreeMatchingNet(config)
-    checkpoint = torch.load(config.checkpoint_path)
-    model.load_state_dict(checkpoint['model_state_dict'])
-    model = model.to(config.device)
-    
-    # Create test dataset
-    test_dataset = TreeMatchingDataset(
-        config.data.test_path,
-        config
-    )
-    
-    # Evaluate
-    metrics = evaluate_model(model, test_dataset, config)
-    
-    # Log results
-    wandb.log(metrics)
-    
-    # Save results
-    results_path = Path(config.results_dir) / 'test_results.json'
-    with open(results_path, 'w') as f:
-        json.dump(metrics, f, indent=2)
-        
-    print("Evaluation Results:")
-    for k, v in metrics.items():
-        print(f"{k}: {v:.4f}")
-
-if __name__ == '__main__':
-    main()
diff --git a/LinguisticTrees/experiments/test_data_loading.py b/LinguisticTrees/experiments/test_data_loading.py
deleted file mode 100644
index 4a68932..0000000
--- a/LinguisticTrees/experiments/test_data_loading.py
+++ /dev/null
@@ -1,49 +0,0 @@
-import logging
-from pathlib import Path
-from ..configs.tree_data_config import TreeDataConfig
-from ..data.partition_datasets import MultiPartitionTreeDataset
-from ..utils.memory_utils import MemoryMonitor
-
-logger = logging.getLogger(__name__)
-
-def test_data_loading():
-    """Test data loading with memory monitoring"""
-    
-    data_config = TreeDataConfig(
-        spacy_variant='trf'  # Change if using different model
-    )
-    
-    # This will print the paths it's checking
-    data_config.validate_paths()
-    
-    # Create dataset using dev data first
-    dataset = MultiPartitionTreeDataset(
-        data_config.dev_path,  # Start with dev data
-        config=data_config,
-        num_workers=4
-    )
-    
-    # Test batch iteration
-    batch_size = 32
-    logger.info("Testing batch iteration...")
-    
-    for i, (graphs, labels) in enumerate(dataset.pairs(batch_size)):
-        if i == 0:
-            logger.info(f"First batch shapes:")
-            logger.info(f"Node features: {graphs.node_features.shape}")
-            logger.info(f"Edge features: {graphs.edge_features.shape}")
-            logger.info(f"Labels: {labels.shape}")
-            
-        MemoryMonitor.log_memory(step=i, prefix=f'Batch {i}: ')
-        
-        if i >= 5:  # Test first few batches
-            break
-            
-    logger.info("Data loading test complete!")
-
-if __name__ == '__main__':
-    logging.basicConfig(
-        level=logging.INFO,
-        format='%(asctime)s - %(levelname)s - %(message)s'
-    )
-    test_data_loading()
diff --git a/LinguisticTrees/experiments/test_partition_loading.py b/LinguisticTrees/experiments/test_partition_loading.py
deleted file mode 100644
index 70aac41..0000000
--- a/LinguisticTrees/experiments/test_partition_loading.py
+++ /dev/null
@@ -1,83 +0,0 @@
-import logging
-from pathlib import Path
-import time
-from ..configs.tree_data_config import TreeDataConfig
-from ..data.partition_datasets import MultiPartitionTreeDataset
-from ..utils.memory_utils import MemoryMonitor
-
-logger = logging.getLogger(__name__)
-
-def test_loading_patterns():
-    """Test different partition loading patterns"""
-    
-    data_config = TreeDataConfig(
-        data_root='data/processed_data',
-        spacy_variant='trf'  # Change to match your data
-    )
-    
-    patterns = ["sequential", "random", "round_robin", "weighted"]
-    batch_size = 32
-    
-    for pattern in patterns:
-        logger.info(f"\nTesting {pattern} loading pattern:")
-        
-        dataset = MultiPartitionTreeDataset(
-            data_config.dev_path,
-            config=data_config,
-            loading_pattern=pattern,
-            num_workers=12
-        )
-        
-        # Track partition order
-        loaded_partitions = []
-        start_time = time.time()
-        
-        # Test loading a few batches
-        for i, (graphs, labels) in enumerate(dataset.pairs(batch_size)):
-            if i == 0:
-                logger.info(f"First batch shapes:")
-                logger.info(f"Nodes: {graphs.node_features.shape}")
-                logger.info(f"Labels: {labels.shape}")
-            
-            MemoryMonitor.log_memory(step=i)
-            
-            if i >= 10:  # Test first 10 batches
-                break
-                
-        duration = time.time() - start_time
-        logger.info(f"{pattern} loading took {duration:.2f}s for 10 batches")
-
-def test_memory_clearing():
-    """Test memory clearing between partitions"""
-    data_config = TreeDataConfig(
-        data_root='data/processed_data',
-        spacy_variant='trf'
-    )
-    
-    dataset = MultiPartitionTreeDataset(
-        data_config.dev_path,
-        config=data_config,
-        loading_pattern='sequential',
-        num_workers=12
-    )
-    
-    logger.info("\nTesting memory clearing:")
-    initial_mem = MemoryMonitor.get_memory_usage()
-    
-    for i, (graphs, labels) in enumerate(dataset.pairs(32)):
-        if i % 10 == 0:
-            current_mem = MemoryMonitor.get_memory_usage()
-            logger.info(f"Batch {i} memory delta: "
-                       f"{current_mem['ram_used_gb'] - initial_mem['ram_used_gb']:.2f}GB")
-        
-        if i >= 30:  # Test a few partition transitions
-            break
-
-if __name__ == '__main__':
-    logging.basicConfig(
-        level=logging.INFO,
-        format='%(asctime)s - %(levelname)s - %(message)s'
-    )
-    
-    test_loading_patterns()
-    test_memory_clearing()
diff --git a/LinguisticTrees/experiments/test_training.py b/LinguisticTrees/experiments/test_training.py
deleted file mode 100644
index dc764fb..0000000
--- a/LinguisticTrees/experiments/test_training.py
+++ /dev/null
@@ -1,51 +0,0 @@
-import wandb
-import torch
-from pathlib import Path
-from ..configs.default_tree_config import get_tree_config
-from ..data.tree_dataset import TreeMatchingDataset
-from ..models.tree_matching import TreeMatchingNet
-from ..training.train import train_epoch
-from ..training.metrics import TreeMatchingMetrics
-
-def test_training():
-    """Test training loop with dev dataset"""
-    # Load config
-    config = get_tree_config()
-    config.data.train_path = 'data/processed_data/dev/final_dataset.json'
-    config.train.n_epochs = 2  # Short test run
-    
-    # Initialize wandb
-    wandb.init(
-        project=config.wandb.project,
-        config=config,
-        tags=[*config.wandb.tags, 'dev-test']
-    )
-    
-    # Create dataset
-    dataset = TreeMatchingDataset(config.data.train_path, config)
-    
-    # Create model and optimizer
-    model = TreeMatchingNet(config).to(config.device)
-    optimizer = torch.optim.Adam(
-        model.parameters(),
-        lr=config.train.learning_rate,
-        weight_decay=config.train.weight_decay
-    )
-    
-    # Test training loop
-    print("Starting test training...")
-    for epoch in range(config.train.n_epochs):
-        train_loss = train_epoch(model, dataset, optimizer, config)
-        print(f"Epoch {epoch}: Loss = {train_loss:.4f}")
-        
-        # Log metrics
-        wandb.log({
-            'epoch': epoch,
-            'train_loss': train_loss
-        })
-    
-    print("Test training completed!")
-    wandb.finish()
-
-if __name__ == '__main__':
-    test_training()
diff --git a/LinguisticTrees/experiments/train_tree_matching.py b/LinguisticTrees/experiments/train_tree_matching.py
deleted file mode 100644
index 2c94c8f..0000000
--- a/LinguisticTrees/experiments/train_tree_matching.py
+++ /dev/null
@@ -1,54 +0,0 @@
-#experiments/train_tree_matching.py
-import wandb
-from ..configs.default_tree_config import get_tree_config
-from ..data.tree_dataset import TreeMatchingDataset
-from ..models.tree_matching import TreeMatchingNet
-from ..training.train import train_epoch
-
-def main():
-    # Initialize config
-    config = get_tree_config()
-    
-    # Initialize WandB
-    wandb.init(
-        project="tree-matching",
-        config=config
-    )
-    
-    # Create datasets
-    train_dataset = TreeMatchingDataset(
-        config.data.train_path,
-        config
-    )
-    val_dataset = TreeMatchingDataset(
-        config.data.val_path,
-        config
-    )
-    
-    # Create model
-    model = TreeMatchingNet(config)
-    
-    # Training loop
-    for epoch in range(config.training.n_epochs):
-        train_loss = train_epoch(
-            model, 
-            train_dataset,
-            optimizer,
-            config
-        )
-        
-        val_metrics = evaluate_model(
-            model,
-            val_dataset,
-            config
-        )
-        
-        # Log metrics
-        wandb.log({
-            'epoch': epoch,
-            'train_loss': train_loss,
-            **val_metrics
-        })
-
-if __name__ == '__main__':
-    main()
diff --git a/LinguisticTrees/models/__init__.py b/LinguisticTrees/models/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/LinguisticTrees/models/__pycache__/__init__.cpython-312.pyc b/LinguisticTrees/models/__pycache__/__init__.cpython-312.pyc
deleted file mode 100644
index d0c6cc3..0000000
Binary files a/LinguisticTrees/models/__pycache__/__init__.cpython-312.pyc and /dev/null differ
diff --git a/LinguisticTrees/models/__pycache__/tree_matching.cpython-312.pyc b/LinguisticTrees/models/__pycache__/tree_matching.cpython-312.pyc
deleted file mode 100644
index 8382c5e..0000000
Binary files a/LinguisticTrees/models/__pycache__/tree_matching.cpython-312.pyc and /dev/null differ
diff --git a/LinguisticTrees/models/tree_embedding.py b/LinguisticTrees/models/tree_embedding.py
deleted file mode 100644
index a549aea..0000000
--- a/LinguisticTrees/models/tree_embedding.py
+++ /dev/null
@@ -1,42 +0,0 @@
-#models/tree_embedding.py
-import torch
-import torch.nn as nn
-from GMN.graphembeddingnetwork import GraphEncoder
-
-class TreeEncoder(GraphEncoder):
-    """Tree-specific encoder for linguistic features"""
-    
-    def __init__(self, node_feature_dim, edge_feature_dim, hidden_dim):
-        super().__init__(
-            node_feature_dim=node_feature_dim,
-            edge_feature_dim=edge_feature_dim,
-            node_hidden_sizes=[hidden_dim],
-            edge_hidden_sizes=[hidden_dim]
-        )
-        
-        # Additional tree-specific layers
-        self.node_transform = nn.Sequential(
-            nn.Linear(node_feature_dim, hidden_dim),
-            nn.LayerNorm(hidden_dim),
-            nn.ReLU(),
-            nn.Dropout(0.1)
-        )
-        
-        self.edge_transform = nn.Sequential(
-            nn.Linear(edge_feature_dim, hidden_dim),
-            nn.LayerNorm(hidden_dim),
-            nn.ReLU(),
-            nn.Dropout(0.1)
-        )
-
-    def forward(self, node_features, edge_features=None):
-        """Enhanced encoding for linguistic features"""
-        # Initial encoding from base class
-        node_outputs, edge_outputs = super().forward(node_features, edge_features)
-        
-        # Additional tree-specific transformations
-        node_outputs = self.node_transform(node_outputs)
-        if edge_outputs is not None:
-            edge_outputs = self.edge_transform(edge_outputs)
-            
-        return node_outputs, edge_outputs
diff --git a/LinguisticTrees/models/tree_encoder.py b/LinguisticTrees/models/tree_encoder.py
deleted file mode 100644
index 17bea1b..0000000
--- a/LinguisticTrees/models/tree_encoder.py
+++ /dev/null
@@ -1,42 +0,0 @@
-#models/tree_encoder.py
-import torch
-import torch.nn as nn
-from GMN.graphembeddingnetwork import GraphEncoder
-
-class TreeEncoder(GraphEncoder):
-    """Tree-specific encoder for linguistic features"""
-    
-    def __init__(self, node_feature_dim, edge_feature_dim, hidden_dim):
-        super().__init__(
-            node_feature_dim=node_feature_dim,
-            edge_feature_dim=edge_feature_dim,
-            node_hidden_sizes=[hidden_dim],
-            edge_hidden_sizes=[hidden_dim]
-        )
-        
-        # Additional tree-specific layers
-        self.node_transform = nn.Sequential(
-            nn.Linear(node_feature_dim, hidden_dim),
-            nn.LayerNorm(hidden_dim),
-            nn.ReLU(),
-            nn.Dropout(0.1)
-        )
-        
-        self.edge_transform = nn.Sequential(
-            nn.Linear(edge_feature_dim, hidden_dim),
-            nn.LayerNorm(hidden_dim),
-            nn.ReLU(),
-            nn.Dropout(0.1)
-        )
-
-    def forward(self, node_features, edge_features=None):
-        """Enhanced encoding for linguistic features"""
-        # Initial encoding from base class
-        node_outputs, edge_outputs = super().forward(node_features, edge_features)
-        
-        # Additional tree-specific transformations
-        node_outputs = self.node_transform(node_outputs)
-        if edge_outputs is not None:
-            edge_outputs = self.edge_transform(edge_outputs)
-            
-        return node_outputs, edge_outputs
diff --git a/LinguisticTrees/models/tree_matching.py b/LinguisticTrees/models/tree_matching.py
deleted file mode 100644
index bc4d1a4..0000000
--- a/LinguisticTrees/models/tree_matching.py
+++ /dev/null
@@ -1,36 +0,0 @@
-#models/tree_matching.py
-from ...GMN.graphmatchingnetwork import GraphMatchingNet  # Use relative import
-from ...GMN.graphembeddingnetwork import GraphEncoder, GraphAggregator
-from .tree_encoder import TreeEncoder
-
-class TreeMatchingNet(GraphMatchingNet):
-    """Tree-specific matching network"""
-    
-    def __init__(self, config):
-        encoder = TreeEncoder(
-            node_feature_dim=config.model.node_feature_dim,
-            edge_feature_dim=config.model.edge_feature_dim,
-            hidden_dim=config.model.node_hidden_dim
-        )
-        
-        aggregator = GraphAggregator(
-            node_hidden_sizes=[config.model.node_hidden_dim],
-            graph_transform_sizes=[config.model.node_hidden_dim],
-            gated=True
-        )
-        
-        super().__init__(
-            encoder=encoder,
-            aggregator=aggregator,
-            node_state_dim=config.model.node_hidden_dim,
-            edge_state_dim=config.model.edge_hidden_dim,
-            n_prop_layers=config.model.n_prop_layers
-        )
-
-    def _build_aggregator(self, config):
-        """Build tree-aware aggregator"""
-        return GraphAggregator(
-            node_hidden_sizes=[config.model.node_hidden_dim],
-            graph_transform_sizes=[config.model.node_hidden_dim],
-            gated=True
-        )
diff --git a/LinguisticTrees/requirements.txt b/LinguisticTrees/requirements.txt
deleted file mode 100644
index a4d92cc..0000000
--- a/LinguisticTrees/requirements.txt
+++ /dev/null
@@ -1 +0,0 @@
-psutil
diff --git a/LinguisticTrees/training/__init__.py b/LinguisticTrees/training/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/LinguisticTrees/training/logger.py b/LinguisticTrees/training/logger.py
deleted file mode 100644
index 3e34740..0000000
--- a/LinguisticTrees/training/logger.py
+++ /dev/null
@@ -1,51 +0,0 @@
-#training/logger.py
-import wandb
-from typing import Dict, Any
-import torch
-from pathlib import Path
-
-class WandbLogger:
-    """WandB logger wrapper"""
-    
-    def __init__(self, config):
-        self.config = config
-        self.run = wandb.init(
-            project=config.project_name,
-            config=config,
-            name=config.run_name
-        )
-        
-        # Create checkpoint directory
-        self.checkpoint_dir = Path(config.checkpoint_dir)
-        self.checkpoint_dir.mkdir(parents=True, exist_ok=True)
-        
-    def log_metrics(self, metrics: Dict[str, Any], step: int = None):
-        """Log metrics to WandB"""
-        wandb.log(metrics, step=step)
-        
-    def log_batch(self, batch_metrics: Dict[str, torch.Tensor], step: int):
-        """Log batch-level metrics"""
-        metrics = {
-            k: v.item() if isinstance(v, torch.Tensor) else v
-            for k, v in batch_metrics.items()
-        }
-        self.log_metrics(metrics, step)
-        
-    def save_checkpoint(self, model, optimizer, epoch, metrics):
-        """Save model checkpoint"""
-        checkpoint = {
-            'epoch': epoch,
-            'model_state_dict': model.state_dict(),
-            'optimizer_state_dict': optimizer.state_dict(),
-            'metrics': metrics
-        }
-        
-        path = self.checkpoint_dir / f'checkpoint_epoch_{epoch}.pt'
-        torch.save(checkpoint, path)
-        
-        # Log to WandB
-        wandb.save(str(path))
-        
-    def finish(self):
-        """Clean up logging"""
-        wandb.finish()
diff --git a/LinguisticTrees/training/metrics.py b/LinguisticTrees/training/metrics.py
deleted file mode 100644
index 097080e..0000000
--- a/LinguisticTrees/training/metrics.py
+++ /dev/null
@@ -1,60 +0,0 @@
-#training/metrics.py
-import torch
-from sklearn.metrics import precision_recall_fscore_support
-import numpy as np
-
-class TreeMatchingMetrics:
-    """Metrics for tree matching evaluation"""
-    
-    @staticmethod
-    def compute_accuracy(similarities, labels):
-        """Compute matching accuracy"""
-        predictions = (similarities > 0).float()
-        return (predictions == labels).float().mean()
-    
-    @staticmethod
-    def compute_f1(similarities, labels):
-        """Compute F1 score"""
-        predictions = (similarities > 0).cpu().numpy()
-        labels = labels.cpu().numpy()
-        precision, recall, f1, _ = precision_recall_fscore_support(
-            labels, 
-            predictions, 
-            average='binary'
-        )
-        return precision, recall, f1
-    
-    @staticmethod
-    def compute_entailment_metrics(similarities, labels):
-        """Compute metrics specific to entailment"""
-        # Convert -1,0,1 to class indices
-        label_indices = labels + 1  # Convert to 0,1,2
-        
-        # Compute per-class accuracy
-        accuracies = []
-        for i in range(3):
-            mask = (label_indices == i)
-            if mask.sum() > 0:
-                acc = ((similarities[mask] > 0).float() == (labels[mask] > 0).float()).mean()
-                accuracies.append(acc)
-                
-        return {
-            'contradiction_acc': accuracies[0],
-            'neutral_acc': accuracies[1],
-            'entailment_acc': accuracies[2]
-        }
-
-    @classmethod
-    def compute_all_metrics(cls, similarities, labels):
-        """Compute all metrics"""
-        accuracy = cls.compute_accuracy(similarities, labels)
-        precision, recall, f1 = cls.compute_f1(similarities, labels)
-        entailment_metrics = cls.compute_entailment_metrics(similarities, labels)
-        
-        return {
-            'accuracy': accuracy,
-            'precision': precision,
-            'recall': recall,
-            'f1': f1,
-            **entailment_metrics
-        }
diff --git a/LinguisticTrees/training/train.py b/LinguisticTrees/training/train.py
deleted file mode 100644
index 7b8568d..0000000
--- a/LinguisticTrees/training/train.py
+++ /dev/null
@@ -1,43 +0,0 @@
-#training/train.py
-import wandb
-from GMN.evaluation import compute_similarity, auc
-import torch
-
-def train_epoch(model, train_loader, optimizer, config):
-    """Train for one epoch"""
-    model.train()
-    total_loss = 0
-    
-    for batch_idx, (graphs, labels) in enumerate(train_loader):
-        # Move to device
-        graphs = graphs.to(config.device)
-        labels = labels.to(config.device)
-        
-        # Forward pass
-        optimizer.zero_grad()
-        outputs = model(
-            graphs.node_features,
-            graphs.edge_features,
-            graphs.from_idx,
-            graphs.to_idx,
-            graphs.graph_idx,
-            graphs.n_graphs
-        )
-        
-        # Compute loss
-        loss = compute_tree_matching_loss(outputs, labels, config)
-        
-        # Backward pass
-        loss.backward()
-        optimizer.step()
-        
-        total_loss += loss.item()
-        
-        # Log to WandB
-        if batch_idx % config.log_interval == 0:
-            wandb.log({
-                'train_loss': loss.item(),
-                'step': batch_idx
-            })
-    
-    return total_loss / len(train_loader)
diff --git a/LinguisticTrees/utils/__init__.py b/LinguisticTrees/utils/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/LinguisticTrees/utils/__pycache__/__init__.cpython-312.pyc b/LinguisticTrees/utils/__pycache__/__init__.cpython-312.pyc
deleted file mode 100644
index 0354c44..0000000
Binary files a/LinguisticTrees/utils/__pycache__/__init__.cpython-312.pyc and /dev/null differ
diff --git a/LinguisticTrees/utils/__pycache__/memory_utils.cpython-312.pyc b/LinguisticTrees/utils/__pycache__/memory_utils.cpython-312.pyc
deleted file mode 100644
index 228e9e5..0000000
Binary files a/LinguisticTrees/utils/__pycache__/memory_utils.cpython-312.pyc and /dev/null differ
diff --git a/LinguisticTrees/utils/memory_utils.py b/LinguisticTrees/utils/memory_utils.py
deleted file mode 100644
index 1568273..0000000
--- a/LinguisticTrees/utils/memory_utils.py
+++ /dev/null
@@ -1,46 +0,0 @@
-import psutil
-import os
-import logging
-from pathlib import Path
-import torch
-import gc
-
-logger = logging.getLogger(__name__)
-
-class MemoryMonitor:
-    """Monitor memory usage during training"""
-    
-    @staticmethod
-    def get_memory_usage():
-        """Get current memory usage"""
-        process = psutil.Process(os.getpid())
-        mem_info = process.memory_info()
-        
-        return {
-            'ram_used_gb': mem_info.rss / (1024 ** 3),  # GB
-            'ram_percent': process.memory_percent(),
-            'gpu_used_gb': torch.cuda.memory_allocated() / (1024 ** 3) if torch.cuda.is_available() else 0,
-            'gpu_cached_gb': torch.cuda.memory_reserved() / (1024 ** 3) if torch.cuda.is_available() else 0
-        }
-    
-    @staticmethod
-    def log_memory(step: int = None, prefix: str = ''):
-        """Log current memory usage"""
-        mem_stats = MemoryMonitor.get_memory_usage()
-        
-        msg = [f"{prefix}Memory usage:"]
-        msg.append(f"RAM: {mem_stats['ram_used_gb']:.2f}GB ({mem_stats['ram_percent']:.1f}%)")
-        
-        if torch.cuda.is_available():
-            msg.append(f"GPU: {mem_stats['gpu_used_gb']:.2f}GB used, "
-                      f"{mem_stats['gpu_cached_gb']:.2f}GB cached")
-            
-        logger.info(' '.join(msg))
-        return mem_stats
-
-    @staticmethod
-    def clear_memory():
-        """Attempt to clear unused memory"""
-        gc.collect()
-        if torch.cuda.is_available():
-            torch.cuda.empty_cache()
diff --git a/__init__.py b/__init__.py
deleted file mode 100644
index e69de29..0000000
